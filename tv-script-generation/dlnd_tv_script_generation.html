<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>dlnd_tv_script_generation</title><script src="https://unpkg.com/jupyter-js-widgets@2.0.*/dist/embed.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}

@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="TV-Script-Generation">TV Script Generation<a class="anchor-link" href="#TV-Script-Generation">&#182;</a></h1><p>In this project, you'll generate your own <a href="https://en.wikipedia.org/wiki/The_Simpsons">Simpsons</a> TV scripts using RNNs.  You'll be using part of the <a href="https://www.kaggle.com/wcukierski/the-simpsons-by-the-data">Simpsons dataset</a> of scripts from 27 seasons.  The Neural Network you'll build will generate a new TV script for a scene at <a href="https://simpsonswiki.com/wiki/Moe&#39;s_Tavern">Moe's Tavern</a>.</p>
<h2 id="Get-the-Data">Get the Data<a class="anchor-link" href="#Get-the-Data">&#182;</a></h2><p>The data is already provided for you.  You'll be using a subset of the original dataset.  It consists of only the scenes in Moe's Tavern.  This doesn't include other versions of the tavern, like "Moe's Cavern", "Flaming Moe's", "Uncle Moe's Family Feed-Bag", etc..</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">helper</span>

<span class="n">data_dir</span> <span class="o">=</span> <span class="s1">&#39;./data/simpsons/moes_tavern_lines.txt&#39;</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">data_dir</span><span class="p">)</span>
<span class="c1"># Ignore notice, since we don&#39;t use it for analysing the data</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="mi">81</span><span class="p">:]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Explore-the-Data">Explore the Data<a class="anchor-link" href="#Explore-the-Data">&#182;</a></h2><p>Play around with <code>view_sentence_range</code> to view different parts of the data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">view_sentence_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Dataset Stats&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Roughly the number of unique words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">({</span><span class="n">word</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()})))</span>
<span class="n">scenes</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of scenes: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">scenes</span><span class="p">)))</span>
<span class="n">sentence_count_scene</span> <span class="o">=</span> <span class="p">[</span><span class="n">scene</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">scene</span> <span class="ow">in</span> <span class="n">scenes</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average number of sentences in each scene: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">sentence_count_scene</span><span class="p">)))</span>

<span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">sentence</span> <span class="k">for</span> <span class="n">scene</span> <span class="ow">in</span> <span class="n">scenes</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">scene</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of lines: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">)))</span>
<span class="n">word_count_sentence</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average number of words in each line: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">word_count_sentence</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The sentences </span><span class="si">{}</span><span class="s1"> to </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Dataset Stats
Roughly the number of unique words: 11492
Number of scenes: 262
Average number of sentences in each scene: 15.248091603053435
Number of lines: 4257
Average number of words in each line: 11.50434578341555

The sentences 0 to 10:
Moe_Szyslak: (INTO PHONE) Moe&#39;s Tavern. Where the elite meet to drink.
Bart_Simpson: Eh, yeah, hello, is Mike there? Last name, Rotch.
Moe_Szyslak: (INTO PHONE) Hold on, I&#39;ll check. (TO BARFLIES) Mike Rotch. Mike Rotch. Hey, has anybody seen Mike Rotch, lately?
Moe_Szyslak: (INTO PHONE) Listen you little puke. One of these days I&#39;m gonna catch you, and I&#39;m gonna carve my name on your back with an ice pick.
Moe_Szyslak: What&#39;s the matter Homer? You&#39;re not your normal effervescent self.
Homer_Simpson: I got my problems, Moe. Give me another one.
Moe_Szyslak: Homer, hey, you should not drink to forget your problems.
Barney_Gumble: Yeah, you should only drink to enhance your social skills.


</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implement-Preprocessing-Functions">Implement Preprocessing Functions<a class="anchor-link" href="#Implement-Preprocessing-Functions">&#182;</a></h2><p>The first thing to do to any dataset is preprocessing.  Implement the following preprocessing functions below:</p>
<ul>
<li>Lookup Table</li>
<li>Tokenize Punctuation</li>
</ul>
<h3 id="Lookup-Table">Lookup Table<a class="anchor-link" href="#Lookup-Table">&#182;</a></h3><p>To create a word embedding, you first need to transform the words to ids.  In this function, create two dictionaries:</p>
<ul>
<li>Dictionary to go from the words to an id, we'll call <code>vocab_to_int</code></li>
<li>Dictionary to go from the id to word, we'll call <code>int_to_vocab</code></li>
</ul>
<p>Return these dictionaries in the following tuple <code>(vocab_to_int, int_to_vocab)</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">Counter</span>

<span class="k">def</span> <span class="nf">create_lookup_tables</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create lookup tables for vocabulary</span>
<span class="sd">    :param text: The text of tv scripts split into words</span>
<span class="sd">    :return: A tuple of dicts (vocab_to_int, int_to_vocab)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    I&#39;ll sort the words by their frequency, so the smallest integer is assigned to</span>
<span class="sd">    the most frequent word.  I&#39;ll start the indices at 1 in case I need 0 to represent</span>
<span class="sd">    a special case.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">vocab_counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">vocab_sorted_by_counts</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">vocab_counts</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">vocab_counts</span><span class="o">.</span><span class="n">get</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">vocab_to_int</span> <span class="o">=</span> <span class="p">{</span><span class="n">word</span><span class="p">:</span> <span class="n">ii</span> <span class="k">for</span> <span class="n">ii</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab_sorted_by_counts</span><span class="p">)}</span>
    <span class="n">int_to_vocab</span> <span class="o">=</span> <span class="p">{</span><span class="n">ii</span><span class="p">:</span> <span class="n">word</span> <span class="k">for</span> <span class="n">ii</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab_sorted_by_counts</span><span class="p">)}</span>
    
    <span class="k">return</span> <span class="n">vocab_to_int</span><span class="p">,</span> <span class="n">int_to_vocab</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_create_lookup_tables</span><span class="p">(</span><span class="n">create_lookup_tables</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Tokenize-Punctuation">Tokenize Punctuation<a class="anchor-link" href="#Tokenize-Punctuation">&#182;</a></h3><p>We'll be splitting the script into a word array using spaces as delimiters.  However, punctuations like periods and exclamation marks make it hard for the neural network to distinguish between the word "bye" and "bye!".</p>
<p>Implement the function <code>token_lookup</code> to return a dict that will be used to tokenize symbols like "!" into "||Exclamation_Mark||".  Create a dictionary for the following symbols where the symbol is the key and value is the token:</p>
<ul>
<li>Period ( . )</li>
<li>Comma ( , )</li>
<li>Quotation Mark ( " )</li>
<li>Semicolon ( ; )</li>
<li>Exclamation mark ( ! )</li>
<li>Question mark ( ? )</li>
<li>Left Parentheses ( ( )</li>
<li>Right Parentheses ( ) )</li>
<li>Dash ( -- )</li>
<li>Return ( \n )</li>
</ul>
<p>This dictionary will be used to token the symbols and add the delimiter (space) around it.  This separates the symbols as it's own word, making it easier for the neural network to predict on the next word. Make sure you don't use a token that could be confused as a word. Instead of using the token "dash", try using something like "||dash||".</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">token_lookup</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate a dict to turn punctuation into a token.</span>
<span class="sd">    :return: Tokenize dictionary where the key is the punctuation and the value is the token</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">punct</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;.&#39;</span><span class="p">:</span> <span class="s1">&#39;||PERIOD||&#39;</span><span class="p">,</span>
        <span class="s1">&#39;,&#39;</span><span class="p">:</span> <span class="s1">&#39;||COMMA||&#39;</span><span class="p">,</span>
        <span class="s1">&#39;&quot;&#39;</span><span class="p">:</span> <span class="s1">&#39;||QUOTATION_MARK||&#39;</span><span class="p">,</span>
        <span class="s1">&#39;;&#39;</span><span class="p">:</span> <span class="s1">&#39;||SEMICOLON||&#39;</span><span class="p">,</span>
        <span class="s1">&#39;!&#39;</span><span class="p">:</span> <span class="s1">&#39;||EXCLAMATION_MARK||&#39;</span><span class="p">,</span>
        <span class="s1">&#39;?&#39;</span><span class="p">:</span> <span class="s1">&#39;||QUESTION_MARK||&#39;</span><span class="p">,</span>
        <span class="s1">&#39;(&#39;</span><span class="p">:</span> <span class="s1">&#39;||LEFT_PAREN||&#39;</span><span class="p">,</span>
        <span class="s1">&#39;)&#39;</span><span class="p">:</span> <span class="s1">&#39;||RIGHT_PAREN||&#39;</span><span class="p">,</span>
        <span class="s1">&#39;--&#39;</span><span class="p">:</span> <span class="s1">&#39;||DASH||&#39;</span><span class="p">,</span>
        <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">:</span> <span class="s1">&#39;||RETURN||&#39;</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">punct</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_tokenize</span><span class="p">(</span><span class="n">token_lookup</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preprocess-all-the-data-and-save-it">Preprocess all the data and save it<a class="anchor-link" href="#Preprocess-all-the-data-and-save-it">&#182;</a></h2><p>Running the code cell below will preprocess all the data and save it to file.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Preprocess Training, Validation, and Testing Data</span>
<span class="n">helper</span><span class="o">.</span><span class="n">preprocess_and_save_data</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">token_lookup</span><span class="p">,</span> <span class="n">create_lookup_tables</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Check-Point">Check Point<a class="anchor-link" href="#Check-Point">&#182;</a></h1><p>This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">int_text</span><span class="p">,</span> <span class="n">vocab_to_int</span><span class="p">,</span> <span class="n">int_to_vocab</span><span class="p">,</span> <span class="n">token_dict</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h2><p>You'll build the components necessary to build a RNN by implementing the following functions below:</p>
<ul>
<li>get_inputs</li>
<li>get_init_cell</li>
<li>get_embed</li>
<li>build_rnn</li>
<li>build_nn</li>
<li>get_batches</li>
</ul>
<h3 id="Check-the-Version-of-TensorFlow-and-Access-to-GPU">Check the Version of TensorFlow and Access to GPU<a class="anchor-link" href="#Check-the-Version-of-TensorFlow-and-Access-to-GPU">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">distutils.version</span> <span class="k">import</span> <span class="n">LooseVersion</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Check TensorFlow Version</span>
<span class="k">assert</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s1">&#39;1.0&#39;</span><span class="p">),</span> <span class="s1">&#39;Please use TensorFlow version 1.0 or newer&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TensorFlow Version: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">))</span>

<span class="c1"># Check for a GPU</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;No GPU found. Please use a GPU to train your neural network.&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Default GPU Device: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">()))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>TensorFlow Version: 1.0.0
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/__main__.py:14: UserWarning: No GPU found. Please use a GPU to train your neural network.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Input">Input<a class="anchor-link" href="#Input">&#182;</a></h3><p>Implement the <code>get_inputs()</code> function to create TF Placeholders for the Neural Network.  It should create the following placeholders:</p>
<ul>
<li>Input text placeholder named "input" using the <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a> <code>name</code> parameter.</li>
<li>Targets placeholder</li>
<li>Learning Rate placeholder</li>
</ul>
<p>Return the placeholders in the following the tuple <code>(Input, Targets, LearingRate)</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_inputs</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create TF Placeholders for input, targets, and learning rate.</span>
<span class="sd">    :return: Tuple (input, targets, learning rate)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">input_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;input&#39;</span><span class="p">)</span>
    <span class="n">target_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">)</span>
    <span class="n">learn_rate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;learn_rate&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_</span><span class="p">,</span><span class="n">target_</span><span class="p">,</span><span class="n">learn_rate</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_get_inputs</span><span class="p">(</span><span class="n">get_inputs</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-RNN-Cell-and-Initialize">Build RNN Cell and Initialize<a class="anchor-link" href="#Build-RNN-Cell-and-Initialize">&#182;</a></h3><p>Stack one or more <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell"><code>BasicLSTMCells</code></a> in a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/MultiRNNCell"><code>MultiRNNCell</code></a>.</p>
<ul>
<li>The Rnn size should be set using <code>rnn_size</code></li>
<li>Initalize Cell State using the MultiRNNCell's <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/MultiRNNCell#zero_state"><code>zero_state()</code></a> function<ul>
<li>Apply the name "initial_state" to the initial state using <a href="https://www.tensorflow.org/api_docs/python/tf/identity"><code>tf.identity()</code></a></li>
</ul>
</li>
</ul>
<p>Return the cell and initial state in the following tuple <code>(Cell, InitialState)</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_init_cell</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create an RNN Cell and initialize it.</span>
<span class="sd">    :param batch_size: Size of batches</span>
<span class="sd">    :param rnn_size: Size of RNNs</span>
<span class="sd">    :return: Tuple (cell, initialize state)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">lstm_layers</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">lstm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicLSTMCell</span><span class="p">(</span><span class="n">num_units</span><span class="o">=</span><span class="n">rnn_size</span><span class="p">)</span>
    <span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">lstm</span><span class="p">]</span> <span class="o">*</span> <span class="n">lstm_layers</span><span class="p">)</span>
    <span class="n">initial_state</span> <span class="o">=</span> <span class="n">cell</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">initial_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">initial_state</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;initial_state&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cell</span><span class="p">,</span> <span class="n">initial_state</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_get_init_cell</span><span class="p">(</span><span class="n">get_init_cell</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Word-Embedding">Word Embedding<a class="anchor-link" href="#Word-Embedding">&#182;</a></h3><p>Apply embedding to <code>input_data</code> using TensorFlow.  Return the embedded sequence.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_embed</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create embedding for &lt;input_data&gt;.</span>
<span class="sd">    :param input_data: TF placeholder for text input.</span>
<span class="sd">    :param vocab_size: Number of words in vocabulary.</span>
<span class="sd">    :param embed_dim: Number of embedding dimensions</span>
<span class="sd">    :return: Embedded input.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span><span class="n">embed_dim</span><span class="p">),</span> <span class="n">minval</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">maxval</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">embed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">embedding</span><span class="p">,</span> <span class="n">ids</span><span class="o">=</span><span class="n">input_data</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">embed</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_get_embed</span><span class="p">(</span><span class="n">get_embed</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-RNN">Build RNN<a class="anchor-link" href="#Build-RNN">&#182;</a></h3><p>You created a RNN Cell in the <code>get_init_cell()</code> function.  Time to use the cell to create a RNN.</p>
<ul>
<li>Build the RNN using the <a href="https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"><code>tf.nn.dynamic_rnn()</code></a><ul>
<li>Apply the name "final_state" to the final state using <a href="https://www.tensorflow.org/api_docs/python/tf/identity"><code>tf.identity()</code></a></li>
</ul>
</li>
</ul>
<p>Return the outputs and final_state state in the following tuple <code>(Outputs, FinalState)</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">build_rnn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a RNN using a RNN Cell</span>
<span class="sd">    :param cell: RNN Cell</span>
<span class="sd">    :param inputs: Input text data</span>
<span class="sd">    :return: Tuple (Outputs, Final State)</span>
<span class="sd">    </span>
<span class="sd">    Note, if initial_state is not defined, then must specify dtype</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">outputs</span><span class="p">,</span> <span class="n">final_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">cell</span><span class="o">=</span><span class="n">cell</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">final_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">final_state</span><span class="p">,</span> <span class="s1">&#39;final_state&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">final_state</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_build_rnn</span><span class="p">(</span><span class="n">build_rnn</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h3><p>Apply the functions you implemented above to:</p>
<ul>
<li>Apply embedding to <code>input_data</code> using your <code>get_embed(input_data, vocab_size, embed_dim)</code> function.</li>
<li>Build RNN using <code>cell</code> and your <code>build_rnn(cell, inputs)</code> function.</li>
<li>Apply a fully connected layer with a linear activation and <code>vocab_size</code> as the number of outputs.</li>
</ul>
<p>Return the logits and final state in the following tuple (Logits, FinalState)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">build_nn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">input_data</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Build part of the neural network</span>
<span class="sd">    :param cell: RNN cell</span>
<span class="sd">    :param rnn_size: Size of rnns</span>
<span class="sd">    :param input_data: Input data</span>
<span class="sd">    :param vocab_size: Vocabulary size</span>
<span class="sd">    :return: Tuple (Logits, FinalState)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">embed</span> <span class="o">=</span> <span class="n">get_embed</span><span class="p">(</span><span class="n">input_data</span><span class="o">=</span><span class="n">input_data</span><span class="p">,</span> <span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
    <span class="n">outputs</span><span class="p">,</span> <span class="n">final_state</span> <span class="o">=</span> <span class="n">build_rnn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">embed</span><span class="p">)</span>
    
    <span class="c1">#see if we can use this but initialize weights to have a stdev of 0.1</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span>
                                               <span class="n">num_outputs</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>
                                               <span class="n">activation_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">logits</span><span class="p">,</span><span class="n">final_state</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_build_nn</span><span class="p">(</span><span class="n">build_nn</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Batches">Batches<a class="anchor-link" href="#Batches">&#182;</a></h3><p>Implement <code>get_batches</code> to create batches of input and targets using <code>int_text</code>.  The batches should be a Numpy array with the shape <code>(number of batches, 2, batch size, sequence length)</code>. Each batch contains two elements:</p>
<ul>
<li>The first element is a single batch of <strong>input</strong> with the shape <code>[batch size, sequence length]</code></li>
<li>The second element is a single batch of <strong>targets</strong> with the shape <code>[batch size, sequence length]</code></li>
</ul>
<p>If you can't fill the last batch with enough data, drop the last batch.</p>
<p>For exmple, <code>get_batches([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 2, 3)</code> would return a Numpy array of the following:</p>

<pre><code>[
  # First Batch
  [
    # Batch of Input
    [[ 1  2  3], [ 7  8  9]],
    # Batch of targets
    [[ 2  3  4], [ 8  9 10]]
  ],

  # Second Batch
  [
    # Batch of Input
    [[ 4  5  6], [10 11 12]],
    # Batch of targets
    [[ 5  6  7], [11 12 13]]
  ]
]</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_batches</span><span class="p">(</span><span class="n">int_text</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return batches of input and target</span>
<span class="sd">    :param int_text: Text with the words replaced by their ids</span>
<span class="sd">    :param batch_size: The size of batch</span>
<span class="sd">    :param seq_length: The length of sequence</span>
<span class="sd">    :return: Batches as a Numpy array</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Divide into length of text - 1 in case the division perfectly divides with remainder 0.</span>
<span class="sd">    This is because targets will be one word offset, and we want targets to have full batches too.</span>
<span class="sd">    They won&#39;t have full batches if the last word of the raw data is used as input (there&#39;s no target word to follow </span>
<span class="sd">    the last word of the raw data).</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">batch_seq_length</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">seq_length</span>
    
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">int_text</span><span class="p">)</span> <span class="o">%</span> <span class="p">(</span><span class="n">batch_seq_length</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">n_batches</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">int_text</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="p">(</span><span class="n">batch_seq_length</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">n_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">int_text</span><span class="p">)</span> <span class="o">//</span> <span class="p">(</span><span class="n">batch_seq_length</span><span class="p">)</span>

    <span class="n">input_idx_left</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">input_idx_right</span> <span class="o">=</span> <span class="n">n_batches</span> <span class="o">*</span> <span class="n">batch_seq_length</span>
    <span class="n">target_offset</span> <span class="o">=</span> <span class="mi">1</span>
    
    <span class="n">batch</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">input_idx_left</span><span class="p">,</span> <span class="n">input_idx_right</span><span class="p">,</span> <span class="n">batch_seq_length</span><span class="p">):</span>
        <span class="n">input_single_batch</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">target_single_batch</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">batch_seq_length</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">):</span>
            <span class="n">input_single_batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">int_text</span><span class="p">[</span><span class="n">ii</span><span class="o">+</span><span class="n">jj</span><span class="p">:</span><span class="n">ii</span><span class="o">+</span><span class="n">jj</span><span class="o">+</span><span class="n">seq_length</span><span class="p">])</span>
            <span class="n">target_single_batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">int_text</span><span class="p">[</span><span class="n">ii</span><span class="o">+</span><span class="n">jj</span><span class="o">+</span><span class="n">target_offset</span><span class="p">:</span><span class="n">ii</span><span class="o">+</span><span class="n">jj</span><span class="o">+</span><span class="n">target_offset</span><span class="o">+</span><span class="n">seq_length</span><span class="p">])</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">input_single_batch</span><span class="p">,</span> <span class="n">target_single_batch</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_get_batches</span><span class="p">(</span><span class="n">get_batches</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[51]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">int_text</span><span class="p">)</span><span class="o">%</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[51]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>100</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Neural-Network-Training">Neural Network Training<a class="anchor-link" href="#Neural-Network-Training">&#182;</a></h2><h3 id="Hyperparameters">Hyperparameters<a class="anchor-link" href="#Hyperparameters">&#182;</a></h3><p>Tune the following parameters:</p>
<ul>
<li>Set <code>num_epochs</code> to the number of epochs.</li>
<li>Set <code>batch_size</code> to the batch size.</li>
<li>Set <code>rnn_size</code> to the size of the RNNs.</li>
<li>Set <code>seq_length</code> to the length of sequence.</li>
<li>Set <code>learning_rate</code> to the learning rate.</li>
<li>Set <code>show_every_n_batches</code> to the number of batches the neural network should print progress.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[52]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Number of Epochs</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">150</span>
<span class="c1"># Batch Size</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10</span>
<span class="c1"># RNN Size</span>
<span class="n">rnn_size</span> <span class="o">=</span> <span class="mi">256</span>
<span class="c1"># Sequence Length</span>
<span class="n">seq_length</span> <span class="o">=</span> <span class="mi">100</span>
<span class="c1"># Learning Rate</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="o">.</span><span class="mi">001</span>
<span class="c1"># Show stats for every n number of batches</span>
<span class="n">show_every_n_batches</span> <span class="o">=</span> <span class="mi">2</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">save_dir</span> <span class="o">=</span> <span class="s1">&#39;./save&#39;</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Graph">Build the Graph<a class="anchor-link" href="#Build-the-Graph">&#182;</a></h3><p>Build the graph using the neural network you implemented.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[53]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">tensorflow.contrib</span> <span class="k">import</span> <span class="n">seq2seq</span>

<span class="n">train_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">train_graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">int_to_vocab</span><span class="p">)</span>
    <span class="n">input_text</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">get_inputs</span><span class="p">()</span>
    <span class="n">input_data_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">input_text</span><span class="p">)</span>
    <span class="n">cell</span><span class="p">,</span> <span class="n">initial_state</span> <span class="o">=</span> <span class="n">get_init_cell</span><span class="p">(</span><span class="n">input_data_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">rnn_size</span><span class="p">)</span>
    <span class="n">logits</span><span class="p">,</span> <span class="n">final_state</span> <span class="o">=</span> <span class="n">build_nn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">input_text</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

    <span class="c1"># Probabilities for generating words</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;probs&#39;</span><span class="p">)</span>

    <span class="c1"># Loss function</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">seq2seq</span><span class="o">.</span><span class="n">sequence_loss</span><span class="p">(</span>
        <span class="n">logits</span><span class="p">,</span>
        <span class="n">targets</span><span class="p">,</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">input_data_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_data_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>

    <span class="c1"># Optimizer</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>

    <span class="c1"># Gradient Clipping</span>
    <span class="n">gradients</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
    <span class="n">capped_gradients</span> <span class="o">=</span> <span class="p">[(</span><span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span> <span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">grad</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">gradients</span><span class="p">]</span>
    <span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">capped_gradients</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Train">Train<a class="anchor-link" href="#Train">&#182;</a></h2><p>Train the neural network on the preprocessed data.  If you have a hard time getting a good loss, check the <a href="https://discussions.udacity.com/">forms</a> to see if anyone is having the same problem.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[54]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">batches</span> <span class="o">=</span> <span class="n">get_batches</span><span class="p">(</span><span class="n">int_text</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">train_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">initial_state</span><span class="p">,</span> <span class="p">{</span><span class="n">input_text</span><span class="p">:</span> <span class="n">batches</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]})</span>

        <span class="k">for</span> <span class="n">batch_i</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batches</span><span class="p">):</span>
            <span class="n">feed</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">input_text</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span>
                <span class="n">targets</span><span class="p">:</span> <span class="n">y</span><span class="p">,</span>
                <span class="n">initial_state</span><span class="p">:</span> <span class="n">state</span><span class="p">,</span>
                <span class="n">lr</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">}</span>
            <span class="n">train_loss</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">cost</span><span class="p">,</span> <span class="n">final_state</span><span class="p">,</span> <span class="n">train_op</span><span class="p">],</span> <span class="n">feed</span><span class="p">)</span>

            <span class="c1"># Show every &lt;show_every_n_batches&gt; batches</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">epoch_i</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">batches</span><span class="p">)</span> <span class="o">+</span> <span class="n">batch_i</span><span class="p">)</span> <span class="o">%</span> <span class="n">show_every_n_batches</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{:&gt;3}</span><span class="s1"> Batch </span><span class="si">{:&gt;4}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">   train_loss = </span><span class="si">{:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">epoch_i</span><span class="p">,</span>
                    <span class="n">batch_i</span><span class="p">,</span>
                    <span class="nb">len</span><span class="p">(</span><span class="n">batches</span><span class="p">),</span>
                    <span class="n">train_loss</span><span class="p">))</span>

    <span class="c1"># Save Model</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
    <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_dir</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model Trained and Saved&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch   0 Batch    0/69   train_loss = 8.822
Epoch   0 Batch    2/69   train_loss = 8.767
Epoch   0 Batch    4/69   train_loss = 8.588
Epoch   0 Batch    6/69   train_loss = 8.194
Epoch   0 Batch    8/69   train_loss = 7.722
Epoch   0 Batch   10/69   train_loss = 7.202
Epoch   0 Batch   12/69   train_loss = 6.755
Epoch   0 Batch   14/69   train_loss = 6.574
Epoch   0 Batch   16/69   train_loss = 6.512
Epoch   0 Batch   18/69   train_loss = 5.980
Epoch   0 Batch   20/69   train_loss = 6.213
Epoch   0 Batch   22/69   train_loss = 6.116
Epoch   0 Batch   24/69   train_loss = 5.929
Epoch   0 Batch   26/69   train_loss = 6.136
Epoch   0 Batch   28/69   train_loss = 6.114
Epoch   0 Batch   30/69   train_loss = 6.247
Epoch   0 Batch   32/69   train_loss = 6.253
Epoch   0 Batch   34/69   train_loss = 6.472
Epoch   0 Batch   36/69   train_loss = 6.121
Epoch   0 Batch   38/69   train_loss = 6.065
Epoch   0 Batch   40/69   train_loss = 6.195
Epoch   0 Batch   42/69   train_loss = 6.298
Epoch   0 Batch   44/69   train_loss = 6.293
Epoch   0 Batch   46/69   train_loss = 6.048
Epoch   0 Batch   48/69   train_loss = 6.108
Epoch   0 Batch   50/69   train_loss = 6.266
Epoch   0 Batch   52/69   train_loss = 6.214
Epoch   0 Batch   54/69   train_loss = 6.422
Epoch   0 Batch   56/69   train_loss = 6.133
Epoch   0 Batch   58/69   train_loss = 6.259
Epoch   0 Batch   60/69   train_loss = 5.994
Epoch   0 Batch   62/69   train_loss = 6.140
Epoch   0 Batch   64/69   train_loss = 6.027
Epoch   0 Batch   66/69   train_loss = 5.963
Epoch   0 Batch   68/69   train_loss = 5.606
Epoch   1 Batch    1/69   train_loss = 5.805
Epoch   1 Batch    3/69   train_loss = 6.072
Epoch   1 Batch    5/69   train_loss = 5.693
Epoch   1 Batch    7/69   train_loss = 5.620
Epoch   1 Batch    9/69   train_loss = 5.745
Epoch   1 Batch   11/69   train_loss = 5.797
Epoch   1 Batch   13/69   train_loss = 5.618
Epoch   1 Batch   15/69   train_loss = 5.486
Epoch   1 Batch   17/69   train_loss = 5.687
Epoch   1 Batch   19/69   train_loss = 5.697
Epoch   1 Batch   21/69   train_loss = 5.666
Epoch   1 Batch   23/69   train_loss = 5.628
Epoch   1 Batch   25/69   train_loss = 5.464
Epoch   1 Batch   27/69   train_loss = 5.501
Epoch   1 Batch   29/69   train_loss = 5.626
Epoch   1 Batch   31/69   train_loss = 5.360
Epoch   1 Batch   33/69   train_loss = 5.514
Epoch   1 Batch   35/69   train_loss = 5.807
Epoch   1 Batch   37/69   train_loss = 5.793
Epoch   1 Batch   39/69   train_loss = 5.807
Epoch   1 Batch   41/69   train_loss = 5.503
Epoch   1 Batch   43/69   train_loss = 5.599
Epoch   1 Batch   45/69   train_loss = 5.609
Epoch   1 Batch   47/69   train_loss = 5.602
Epoch   1 Batch   49/69   train_loss = 5.802
Epoch   1 Batch   51/69   train_loss = 5.647
Epoch   1 Batch   53/69   train_loss = 5.626
Epoch   1 Batch   55/69   train_loss = 5.669
Epoch   1 Batch   57/69   train_loss = 5.767
Epoch   1 Batch   59/69   train_loss = 5.390
Epoch   1 Batch   61/69   train_loss = 5.607
Epoch   1 Batch   63/69   train_loss = 5.535
Epoch   1 Batch   65/69   train_loss = 5.752
Epoch   1 Batch   67/69   train_loss = 5.269
Epoch   2 Batch    0/69   train_loss = 5.252
Epoch   2 Batch    2/69   train_loss = 5.452
Epoch   2 Batch    4/69   train_loss = 5.357
Epoch   2 Batch    6/69   train_loss = 5.291
Epoch   2 Batch    8/69   train_loss = 5.233
Epoch   2 Batch   10/69   train_loss = 5.299
Epoch   2 Batch   12/69   train_loss = 5.319
Epoch   2 Batch   14/69   train_loss = 5.542
Epoch   2 Batch   16/69   train_loss = 5.654
Epoch   2 Batch   18/69   train_loss = 5.137
Epoch   2 Batch   20/69   train_loss = 5.376
Epoch   2 Batch   22/69   train_loss = 5.257
Epoch   2 Batch   24/69   train_loss = 5.040
Epoch   2 Batch   26/69   train_loss = 5.144
Epoch   2 Batch   28/69   train_loss = 5.118
Epoch   2 Batch   30/69   train_loss = 5.292
Epoch   2 Batch   32/69   train_loss = 5.328
Epoch   2 Batch   34/69   train_loss = 5.445
Epoch   2 Batch   36/69   train_loss = 5.309
Epoch   2 Batch   38/69   train_loss = 5.154
Epoch   2 Batch   40/69   train_loss = 5.225
Epoch   2 Batch   42/69   train_loss = 5.460
Epoch   2 Batch   44/69   train_loss = 5.415
Epoch   2 Batch   46/69   train_loss = 5.275
Epoch   2 Batch   48/69   train_loss = 5.309
Epoch   2 Batch   50/69   train_loss = 5.445
Epoch   2 Batch   52/69   train_loss = 5.448
Epoch   2 Batch   54/69   train_loss = 5.672
Epoch   2 Batch   56/69   train_loss = 5.338
Epoch   2 Batch   58/69   train_loss = 5.533
Epoch   2 Batch   60/69   train_loss = 5.247
Epoch   2 Batch   62/69   train_loss = 5.364
Epoch   2 Batch   64/69   train_loss = 5.224
Epoch   2 Batch   66/69   train_loss = 5.225
Epoch   2 Batch   68/69   train_loss = 4.925
Epoch   3 Batch    1/69   train_loss = 5.158
Epoch   3 Batch    3/69   train_loss = 5.414
Epoch   3 Batch    5/69   train_loss = 5.087
Epoch   3 Batch    7/69   train_loss = 5.043
Epoch   3 Batch    9/69   train_loss = 5.194
Epoch   3 Batch   11/69   train_loss = 5.230
Epoch   3 Batch   13/69   train_loss = 5.007
Epoch   3 Batch   15/69   train_loss = 4.925
Epoch   3 Batch   17/69   train_loss = 5.137
Epoch   3 Batch   19/69   train_loss = 5.178
Epoch   3 Batch   21/69   train_loss = 5.126
Epoch   3 Batch   23/69   train_loss = 5.077
Epoch   3 Batch   25/69   train_loss = 4.919
Epoch   3 Batch   27/69   train_loss = 4.941
Epoch   3 Batch   29/69   train_loss = 5.081
Epoch   3 Batch   31/69   train_loss = 4.799
Epoch   3 Batch   33/69   train_loss = 4.992
Epoch   3 Batch   35/69   train_loss = 5.276
Epoch   3 Batch   37/69   train_loss = 5.307
Epoch   3 Batch   39/69   train_loss = 5.292
Epoch   3 Batch   41/69   train_loss = 4.967
Epoch   3 Batch   43/69   train_loss = 5.050
Epoch   3 Batch   45/69   train_loss = 5.071
Epoch   3 Batch   47/69   train_loss = 5.146
Epoch   3 Batch   49/69   train_loss = 5.262
Epoch   3 Batch   51/69   train_loss = 5.130
Epoch   3 Batch   53/69   train_loss = 5.107
Epoch   3 Batch   55/69   train_loss = 5.107
Epoch   3 Batch   57/69   train_loss = 5.250
Epoch   3 Batch   59/69   train_loss = 4.886
Epoch   3 Batch   61/69   train_loss = 5.103
Epoch   3 Batch   63/69   train_loss = 5.044
Epoch   3 Batch   65/69   train_loss = 5.181
Epoch   3 Batch   67/69   train_loss = 4.772
Epoch   4 Batch    0/69   train_loss = 4.750
Epoch   4 Batch    2/69   train_loss = 4.930
Epoch   4 Batch    4/69   train_loss = 4.884
Epoch   4 Batch    6/69   train_loss = 4.779
Epoch   4 Batch    8/69   train_loss = 4.768
Epoch   4 Batch   10/69   train_loss = 4.848
Epoch   4 Batch   12/69   train_loss = 4.835
Epoch   4 Batch   14/69   train_loss = 5.089
Epoch   4 Batch   16/69   train_loss = 5.188
Epoch   4 Batch   18/69   train_loss = 4.696
Epoch   4 Batch   20/69   train_loss = 4.932
Epoch   4 Batch   22/69   train_loss = 4.816
Epoch   4 Batch   24/69   train_loss = 4.589
Epoch   4 Batch   26/69   train_loss = 4.720
Epoch   4 Batch   28/69   train_loss = 4.715
Epoch   4 Batch   30/69   train_loss = 4.883
Epoch   4 Batch   32/69   train_loss = 4.919
Epoch   4 Batch   34/69   train_loss = 5.003
Epoch   4 Batch   36/69   train_loss = 4.870
Epoch   4 Batch   38/69   train_loss = 4.744
Epoch   4 Batch   40/69   train_loss = 4.804
Epoch   4 Batch   42/69   train_loss = 5.085
Epoch   4 Batch   44/69   train_loss = 5.020
Epoch   4 Batch   46/69   train_loss = 4.872
Epoch   4 Batch   48/69   train_loss = 4.903
Epoch   4 Batch   50/69   train_loss = 5.060
Epoch   4 Batch   52/69   train_loss = 5.029
Epoch   4 Batch   54/69   train_loss = 5.255
Epoch   4 Batch   56/69   train_loss = 4.923
Epoch   4 Batch   58/69   train_loss = 5.132
Epoch   4 Batch   60/69   train_loss = 4.849
Epoch   4 Batch   62/69   train_loss = 4.944
Epoch   4 Batch   64/69   train_loss = 4.814
Epoch   4 Batch   66/69   train_loss = 4.803
Epoch   4 Batch   68/69   train_loss = 4.542
Epoch   5 Batch    1/69   train_loss = 4.799
Epoch   5 Batch    3/69   train_loss = 5.020
Epoch   5 Batch    5/69   train_loss = 4.709
Epoch   5 Batch    7/69   train_loss = 4.663
Epoch   5 Batch    9/69   train_loss = 4.823
Epoch   5 Batch   11/69   train_loss = 4.867
Epoch   5 Batch   13/69   train_loss = 4.649
Epoch   5 Batch   15/69   train_loss = 4.595
Epoch   5 Batch   17/69   train_loss = 4.767
Epoch   5 Batch   19/69   train_loss = 4.863
Epoch   5 Batch   21/69   train_loss = 4.779
Epoch   5 Batch   23/69   train_loss = 4.756
Epoch   5 Batch   25/69   train_loss = 4.622
Epoch   5 Batch   27/69   train_loss = 4.627
Epoch   5 Batch   29/69   train_loss = 4.740
Epoch   5 Batch   31/69   train_loss = 4.482
Epoch   5 Batch   33/69   train_loss = 4.663
Epoch   5 Batch   35/69   train_loss = 4.928
Epoch   5 Batch   37/69   train_loss = 4.990
Epoch   5 Batch   39/69   train_loss = 4.919
Epoch   5 Batch   41/69   train_loss = 4.651
Epoch   5 Batch   43/69   train_loss = 4.720
Epoch   5 Batch   45/69   train_loss = 4.753
Epoch   5 Batch   47/69   train_loss = 4.850
Epoch   5 Batch   49/69   train_loss = 4.930
Epoch   5 Batch   51/69   train_loss = 4.816
Epoch   5 Batch   53/69   train_loss = 4.795
Epoch   5 Batch   55/69   train_loss = 4.753
Epoch   5 Batch   57/69   train_loss = 4.923
Epoch   5 Batch   59/69   train_loss = 4.574
Epoch   5 Batch   61/69   train_loss = 4.796
Epoch   5 Batch   63/69   train_loss = 4.732
Epoch   5 Batch   65/69   train_loss = 4.825
Epoch   5 Batch   67/69   train_loss = 4.471
Epoch   6 Batch    0/69   train_loss = 4.437
Epoch   6 Batch    2/69   train_loss = 4.614
Epoch   6 Batch    4/69   train_loss = 4.581
Epoch   6 Batch    6/69   train_loss = 4.502
Epoch   6 Batch    8/69   train_loss = 4.484
Epoch   6 Batch   10/69   train_loss = 4.575
Epoch   6 Batch   12/69   train_loss = 4.542
Epoch   6 Batch   14/69   train_loss = 4.801
Epoch   6 Batch   16/69   train_loss = 4.899
Epoch   6 Batch   18/69   train_loss = 4.417
Epoch   6 Batch   20/69   train_loss = 4.656
Epoch   6 Batch   22/69   train_loss = 4.539
Epoch   6 Batch   24/69   train_loss = 4.325
Epoch   6 Batch   26/69   train_loss = 4.438
Epoch   6 Batch   28/69   train_loss = 4.445
Epoch   6 Batch   30/69   train_loss = 4.599
Epoch   6 Batch   32/69   train_loss = 4.654
Epoch   6 Batch   34/69   train_loss = 4.719
Epoch   6 Batch   36/69   train_loss = 4.558
Epoch   6 Batch   38/69   train_loss = 4.486
Epoch   6 Batch   40/69   train_loss = 4.538
Epoch   6 Batch   42/69   train_loss = 4.811
Epoch   6 Batch   44/69   train_loss = 4.744
Epoch   6 Batch   46/69   train_loss = 4.585
Epoch   6 Batch   48/69   train_loss = 4.637
Epoch   6 Batch   50/69   train_loss = 4.776
Epoch   6 Batch   52/69   train_loss = 4.743
Epoch   6 Batch   54/69   train_loss = 4.951
Epoch   6 Batch   56/69   train_loss = 4.659
Epoch   6 Batch   58/69   train_loss = 4.860
Epoch   6 Batch   60/69   train_loss = 4.603
Epoch   6 Batch   62/69   train_loss = 4.670
Epoch   6 Batch   64/69   train_loss = 4.549
Epoch   6 Batch   66/69   train_loss = 4.525
Epoch   6 Batch   68/69   train_loss = 4.296
Epoch   7 Batch    1/69   train_loss = 4.550
Epoch   7 Batch    3/69   train_loss = 4.728
Epoch   7 Batch    5/69   train_loss = 4.455
Epoch   7 Batch    7/69   train_loss = 4.405
Epoch   7 Batch    9/69   train_loss = 4.560
Epoch   7 Batch   11/69   train_loss = 4.613
Epoch   7 Batch   13/69   train_loss = 4.412
Epoch   7 Batch   15/69   train_loss = 4.377
Epoch   7 Batch   17/69   train_loss = 4.510
Epoch   7 Batch   19/69   train_loss = 4.628
Epoch   7 Batch   21/69   train_loss = 4.517
Epoch   7 Batch   23/69   train_loss = 4.527
Epoch   7 Batch   25/69   train_loss = 4.413
Epoch   7 Batch   27/69   train_loss = 4.410
Epoch   7 Batch   29/69   train_loss = 4.495
Epoch   7 Batch   31/69   train_loss = 4.258
Epoch   7 Batch   33/69   train_loss = 4.430
Epoch   7 Batch   35/69   train_loss = 4.677
Epoch   7 Batch   37/69   train_loss = 4.741
Epoch   7 Batch   39/69   train_loss = 4.655
Epoch   7 Batch   41/69   train_loss = 4.415
Epoch   7 Batch   43/69   train_loss = 4.483
Epoch   7 Batch   45/69   train_loss = 4.526
Epoch   7 Batch   47/69   train_loss = 4.617
Epoch   7 Batch   49/69   train_loss = 4.673
Epoch   7 Batch   51/69   train_loss = 4.588
Epoch   7 Batch   53/69   train_loss = 4.564
Epoch   7 Batch   55/69   train_loss = 4.490
Epoch   7 Batch   57/69   train_loss = 4.679
Epoch   7 Batch   59/69   train_loss = 4.363
Epoch   7 Batch   61/69   train_loss = 4.571
Epoch   7 Batch   63/69   train_loss = 4.512
Epoch   7 Batch   65/69   train_loss = 4.588
Epoch   7 Batch   67/69   train_loss = 4.249
Epoch   8 Batch    0/69   train_loss = 4.213
Epoch   8 Batch    2/69   train_loss = 4.388
Epoch   8 Batch    4/69   train_loss = 4.354
Epoch   8 Batch    6/69   train_loss = 4.309
Epoch   8 Batch    8/69   train_loss = 4.273
Epoch   8 Batch   10/69   train_loss = 4.360
Epoch   8 Batch   12/69   train_loss = 4.327
Epoch   8 Batch   14/69   train_loss = 4.584
Epoch   8 Batch   16/69   train_loss = 4.682
Epoch   8 Batch   18/69   train_loss = 4.204
Epoch   8 Batch   20/69   train_loss = 4.442
Epoch   8 Batch   22/69   train_loss = 4.327
Epoch   8 Batch   24/69   train_loss = 4.137
Epoch   8 Batch   26/69   train_loss = 4.227
Epoch   8 Batch   28/69   train_loss = 4.250
Epoch   8 Batch   30/69   train_loss = 4.388
Epoch   8 Batch   32/69   train_loss = 4.449
Epoch   8 Batch   34/69   train_loss = 4.505
Epoch   8 Batch   36/69   train_loss = 4.334
Epoch   8 Batch   38/69   train_loss = 4.293
Epoch   8 Batch   40/69   train_loss = 4.331
Epoch   8 Batch   42/69   train_loss = 4.587
Epoch   8 Batch   44/69   train_loss = 4.515
Epoch   8 Batch   46/69   train_loss = 4.371
Epoch   8 Batch   48/69   train_loss = 4.431
Epoch   8 Batch   50/69   train_loss = 4.535
Epoch   8 Batch   52/69   train_loss = 4.521
Epoch   8 Batch   54/69   train_loss = 4.699
Epoch   8 Batch   56/69   train_loss = 4.452
Epoch   8 Batch   58/69   train_loss = 4.637
Epoch   8 Batch   60/69   train_loss = 4.403
Epoch   8 Batch   62/69   train_loss = 4.456
Epoch   8 Batch   64/69   train_loss = 4.348
Epoch   8 Batch   66/69   train_loss = 4.300
Epoch   8 Batch   68/69   train_loss = 4.117
Epoch   9 Batch    1/69   train_loss = 4.346
Epoch   9 Batch    3/69   train_loss = 4.502
Epoch   9 Batch    5/69   train_loss = 4.266
Epoch   9 Batch    7/69   train_loss = 4.209
Epoch   9 Batch    9/69   train_loss = 4.357
Epoch   9 Batch   11/69   train_loss = 4.403
Epoch   9 Batch   13/69   train_loss = 4.223
Epoch   9 Batch   15/69   train_loss = 4.194
Epoch   9 Batch   17/69   train_loss = 4.304
Epoch   9 Batch   19/69   train_loss = 4.421
Epoch   9 Batch   21/69   train_loss = 4.296
Epoch   9 Batch   23/69   train_loss = 4.334
Epoch   9 Batch   25/69   train_loss = 4.237
Epoch   9 Batch   27/69   train_loss = 4.234
Epoch   9 Batch   29/69   train_loss = 4.300
Epoch   9 Batch   31/69   train_loss = 4.079
Epoch   9 Batch   33/69   train_loss = 4.249
Epoch   9 Batch   35/69   train_loss = 4.479
Epoch   9 Batch   37/69   train_loss = 4.531
Epoch   9 Batch   39/69   train_loss = 4.449
Epoch   9 Batch   41/69   train_loss = 4.222
Epoch   9 Batch   43/69   train_loss = 4.295
Epoch   9 Batch   45/69   train_loss = 4.346
Epoch   9 Batch   47/69   train_loss = 4.419
Epoch   9 Batch   49/69   train_loss = 4.451
Epoch   9 Batch   51/69   train_loss = 4.388
Epoch   9 Batch   53/69   train_loss = 4.364
Epoch   9 Batch   55/69   train_loss = 4.271
Epoch   9 Batch   57/69   train_loss = 4.464
Epoch   9 Batch   59/69   train_loss = 4.185
Epoch   9 Batch   61/69   train_loss = 4.379
Epoch   9 Batch   63/69   train_loss = 4.324
Epoch   9 Batch   65/69   train_loss = 4.400
Epoch   9 Batch   67/69   train_loss = 4.065
Epoch  10 Batch    0/69   train_loss = 4.036
Epoch  10 Batch    2/69   train_loss = 4.208
Epoch  10 Batch    4/69   train_loss = 4.164
Epoch  10 Batch    6/69   train_loss = 4.151
Epoch  10 Batch    8/69   train_loss = 4.099
Epoch  10 Batch   10/69   train_loss = 4.182
Epoch  10 Batch   12/69   train_loss = 4.149
Epoch  10 Batch   14/69   train_loss = 4.400
Epoch  10 Batch   16/69   train_loss = 4.495
Epoch  10 Batch   18/69   train_loss = 4.030
Epoch  10 Batch   20/69   train_loss = 4.258
Epoch  10 Batch   22/69   train_loss = 4.135
Epoch  10 Batch   24/69   train_loss = 3.982
Epoch  10 Batch   26/69   train_loss = 4.049
Epoch  10 Batch   28/69   train_loss = 4.085
Epoch  10 Batch   30/69   train_loss = 4.202
Epoch  10 Batch   32/69   train_loss = 4.269
Epoch  10 Batch   34/69   train_loss = 4.320
Epoch  10 Batch   36/69   train_loss = 4.150
Epoch  10 Batch   38/69   train_loss = 4.125
Epoch  10 Batch   40/69   train_loss = 4.157
Epoch  10 Batch   42/69   train_loss = 4.392
Epoch  10 Batch   44/69   train_loss = 4.319
Epoch  10 Batch   46/69   train_loss = 4.195
Epoch  10 Batch   48/69   train_loss = 4.256
Epoch  10 Batch   50/69   train_loss = 4.323
Epoch  10 Batch   52/69   train_loss = 4.333
Epoch  10 Batch   54/69   train_loss = 4.475
Epoch  10 Batch   56/69   train_loss = 4.265
Epoch  10 Batch   58/69   train_loss = 4.439
Epoch  10 Batch   60/69   train_loss = 4.219
Epoch  10 Batch   62/69   train_loss = 4.263
Epoch  10 Batch   64/69   train_loss = 4.171
Epoch  10 Batch   66/69   train_loss = 4.103
Epoch  10 Batch   68/69   train_loss = 3.968
Epoch  11 Batch    1/69   train_loss = 4.164
Epoch  11 Batch    3/69   train_loss = 4.303
Epoch  11 Batch    5/69   train_loss = 4.106
Epoch  11 Batch    7/69   train_loss = 4.041
Epoch  11 Batch    9/69   train_loss = 4.187
Epoch  11 Batch   11/69   train_loss = 4.224
Epoch  11 Batch   13/69   train_loss = 4.062
Epoch  11 Batch   15/69   train_loss = 4.035
Epoch  11 Batch   17/69   train_loss = 4.128
Epoch  11 Batch   19/69   train_loss = 4.231
Epoch  11 Batch   21/69   train_loss = 4.108
Epoch  11 Batch   23/69   train_loss = 4.163
Epoch  11 Batch   25/69   train_loss = 4.081
Epoch  11 Batch   27/69   train_loss = 4.075
Epoch  11 Batch   29/69   train_loss = 4.125
Epoch  11 Batch   31/69   train_loss = 3.924
Epoch  11 Batch   33/69   train_loss = 4.090
Epoch  11 Batch   35/69   train_loss = 4.302
Epoch  11 Batch   37/69   train_loss = 4.337
Epoch  11 Batch   39/69   train_loss = 4.269
Epoch  11 Batch   41/69   train_loss = 4.050
Epoch  11 Batch   43/69   train_loss = 4.131
Epoch  11 Batch   45/69   train_loss = 4.183
Epoch  11 Batch   47/69   train_loss = 4.242
Epoch  11 Batch   49/69   train_loss = 4.255
Epoch  11 Batch   51/69   train_loss = 4.209
Epoch  11 Batch   53/69   train_loss = 4.186
Epoch  11 Batch   55/69   train_loss = 4.081
Epoch  11 Batch   57/69   train_loss = 4.273
Epoch  11 Batch   59/69   train_loss = 4.029
Epoch  11 Batch   61/69   train_loss = 4.207
Epoch  11 Batch   63/69   train_loss = 4.153
Epoch  11 Batch   65/69   train_loss = 4.235
Epoch  11 Batch   67/69   train_loss = 3.902
Epoch  12 Batch    0/69   train_loss = 3.885
Epoch  12 Batch    2/69   train_loss = 4.050
Epoch  12 Batch    4/69   train_loss = 3.989
Epoch  12 Batch    6/69   train_loss = 4.006
Epoch  12 Batch    8/69   train_loss = 3.948
Epoch  12 Batch   10/69   train_loss = 4.028
Epoch  12 Batch   12/69   train_loss = 3.994
Epoch  12 Batch   14/69   train_loss = 4.233
Epoch  12 Batch   16/69   train_loss = 4.327
Epoch  12 Batch   18/69   train_loss = 3.882
Epoch  12 Batch   20/69   train_loss = 4.094
Epoch  12 Batch   22/69   train_loss = 3.964
Epoch  12 Batch   24/69   train_loss = 3.845
Epoch  12 Batch   26/69   train_loss = 3.892
Epoch  12 Batch   28/69   train_loss = 3.939
Epoch  12 Batch   30/69   train_loss = 4.035
Epoch  12 Batch   32/69   train_loss = 4.107
Epoch  12 Batch   34/69   train_loss = 4.153
Epoch  12 Batch   36/69   train_loss = 3.990
Epoch  12 Batch   38/69   train_loss = 3.974
Epoch  12 Batch   40/69   train_loss = 4.002
Epoch  12 Batch   42/69   train_loss = 4.215
Epoch  12 Batch   44/69   train_loss = 4.141
Epoch  12 Batch   46/69   train_loss = 4.039
Epoch  12 Batch   48/69   train_loss = 4.096
Epoch  12 Batch   50/69   train_loss = 4.134
Epoch  12 Batch   52/69   train_loss = 4.169
Epoch  12 Batch   54/69   train_loss = 4.273
Epoch  12 Batch   56/69   train_loss = 4.092
Epoch  12 Batch   58/69   train_loss = 4.261
Epoch  12 Batch   60/69   train_loss = 4.050
Epoch  12 Batch   62/69   train_loss = 4.084
Epoch  12 Batch   64/69   train_loss = 4.013
Epoch  12 Batch   66/69   train_loss = 3.933
Epoch  12 Batch   68/69   train_loss = 3.840
Epoch  13 Batch    1/69   train_loss = 3.997
Epoch  13 Batch    3/69   train_loss = 4.121
Epoch  13 Batch    5/69   train_loss = 3.963
Epoch  13 Batch    7/69   train_loss = 3.890
Epoch  13 Batch    9/69   train_loss = 4.034
Epoch  13 Batch   11/69   train_loss = 4.064
Epoch  13 Batch   13/69   train_loss = 3.916
Epoch  13 Batch   15/69   train_loss = 3.891
Epoch  13 Batch   17/69   train_loss = 3.972
Epoch  13 Batch   19/69   train_loss = 4.054
Epoch  13 Batch   21/69   train_loss = 3.946
Epoch  13 Batch   23/69   train_loss = 4.007
Epoch  13 Batch   25/69   train_loss = 3.940
Epoch  13 Batch   27/69   train_loss = 3.929
Epoch  13 Batch   29/69   train_loss = 3.965
Epoch  13 Batch   31/69   train_loss = 3.789
Epoch  13 Batch   33/69   train_loss = 3.946
Epoch  13 Batch   35/69   train_loss = 4.140
Epoch  13 Batch   37/69   train_loss = 4.158
Epoch  13 Batch   39/69   train_loss = 4.100
Epoch  13 Batch   41/69   train_loss = 3.897
Epoch  13 Batch   43/69   train_loss = 3.983
Epoch  13 Batch   45/69   train_loss = 4.032
Epoch  13 Batch   47/69   train_loss = 4.079
Epoch  13 Batch   49/69   train_loss = 4.078
Epoch  13 Batch   51/69   train_loss = 4.040
Epoch  13 Batch   53/69   train_loss = 4.025
Epoch  13 Batch   55/69   train_loss = 3.907
Epoch  13 Batch   57/69   train_loss = 4.100
Epoch  13 Batch   59/69   train_loss = 3.889
Epoch  13 Batch   61/69   train_loss = 4.046
Epoch  13 Batch   63/69   train_loss = 3.994
Epoch  13 Batch   65/69   train_loss = 4.083
Epoch  13 Batch   67/69   train_loss = 3.757
Epoch  14 Batch    0/69   train_loss = 3.752
Epoch  14 Batch    2/69   train_loss = 3.908
Epoch  14 Batch    4/69   train_loss = 3.826
Epoch  14 Batch    6/69   train_loss = 3.868
Epoch  14 Batch    8/69   train_loss = 3.809
Epoch  14 Batch   10/69   train_loss = 3.892
Epoch  14 Batch   12/69   train_loss = 3.854
Epoch  14 Batch   14/69   train_loss = 4.076
Epoch  14 Batch   16/69   train_loss = 4.171
Epoch  14 Batch   18/69   train_loss = 3.752
Epoch  14 Batch   20/69   train_loss = 3.946
Epoch  14 Batch   22/69   train_loss = 3.811
Epoch  14 Batch   24/69   train_loss = 3.720
Epoch  14 Batch   26/69   train_loss = 3.751
Epoch  14 Batch   28/69   train_loss = 3.807
Epoch  14 Batch   30/69   train_loss = 3.885
Epoch  14 Batch   32/69   train_loss = 3.959
Epoch  14 Batch   34/69   train_loss = 3.997
Epoch  14 Batch   36/69   train_loss = 3.847
Epoch  14 Batch   38/69   train_loss = 3.835
Epoch  14 Batch   40/69   train_loss = 3.857
Epoch  14 Batch   42/69   train_loss = 4.048
Epoch  14 Batch   44/69   train_loss = 3.976
Epoch  14 Batch   46/69   train_loss = 3.897
Epoch  14 Batch   48/69   train_loss = 3.952
Epoch  14 Batch   50/69   train_loss = 3.959
Epoch  14 Batch   52/69   train_loss = 4.021
Epoch  14 Batch   54/69   train_loss = 4.086
Epoch  14 Batch   56/69   train_loss = 3.929
Epoch  14 Batch   58/69   train_loss = 4.096
Epoch  14 Batch   60/69   train_loss = 3.891
Epoch  14 Batch   62/69   train_loss = 3.918
Epoch  14 Batch   64/69   train_loss = 3.868
Epoch  14 Batch   66/69   train_loss = 3.781
Epoch  14 Batch   68/69   train_loss = 3.725
Epoch  15 Batch    1/69   train_loss = 3.844
Epoch  15 Batch    3/69   train_loss = 3.950
Epoch  15 Batch    5/69   train_loss = 3.829
Epoch  15 Batch    7/69   train_loss = 3.752
Epoch  15 Batch    9/69   train_loss = 3.893
Epoch  15 Batch   11/69   train_loss = 3.919
Epoch  15 Batch   13/69   train_loss = 3.778
Epoch  15 Batch   15/69   train_loss = 3.756
Epoch  15 Batch   17/69   train_loss = 3.829
Epoch  15 Batch   19/69   train_loss = 3.893
Epoch  15 Batch   21/69   train_loss = 3.804
Epoch  15 Batch   23/69   train_loss = 3.864
Epoch  15 Batch   25/69   train_loss = 3.811
Epoch  15 Batch   27/69   train_loss = 3.790
Epoch  15 Batch   29/69   train_loss = 3.819
Epoch  15 Batch   31/69   train_loss = 3.670
Epoch  15 Batch   33/69   train_loss = 3.813
Epoch  15 Batch   35/69   train_loss = 3.990
Epoch  15 Batch   37/69   train_loss = 3.991
Epoch  15 Batch   39/69   train_loss = 3.946
Epoch  15 Batch   41/69   train_loss = 3.756
Epoch  15 Batch   43/69   train_loss = 3.849
Epoch  15 Batch   45/69   train_loss = 3.890
Epoch  15 Batch   47/69   train_loss = 3.929
Epoch  15 Batch   49/69   train_loss = 3.919
Epoch  15 Batch   51/69   train_loss = 3.885
Epoch  15 Batch   53/69   train_loss = 3.874
Epoch  15 Batch   55/69   train_loss = 3.748
Epoch  15 Batch   57/69   train_loss = 3.941
Epoch  15 Batch   59/69   train_loss = 3.757
Epoch  15 Batch   61/69   train_loss = 3.894
Epoch  15 Batch   63/69   train_loss = 3.847
Epoch  15 Batch   65/69   train_loss = 3.941
Epoch  15 Batch   67/69   train_loss = 3.623
Epoch  16 Batch    0/69   train_loss = 3.630
Epoch  16 Batch    2/69   train_loss = 3.778
Epoch  16 Batch    4/69   train_loss = 3.671
Epoch  16 Batch    6/69   train_loss = 3.734
Epoch  16 Batch    8/69   train_loss = 3.682
Epoch  16 Batch   10/69   train_loss = 3.764
Epoch  16 Batch   12/69   train_loss = 3.721
Epoch  16 Batch   14/69   train_loss = 3.924
Epoch  16 Batch   16/69   train_loss = 4.024
Epoch  16 Batch   18/69   train_loss = 3.631
Epoch  16 Batch   20/69   train_loss = 3.811
Epoch  16 Batch   22/69   train_loss = 3.669
Epoch  16 Batch   24/69   train_loss = 3.607
Epoch  16 Batch   26/69   train_loss = 3.622
Epoch  16 Batch   28/69   train_loss = 3.689
Epoch  16 Batch   30/69   train_loss = 3.746
Epoch  16 Batch   32/69   train_loss = 3.821
Epoch  16 Batch   34/69   train_loss = 3.852
Epoch  16 Batch   36/69   train_loss = 3.714
Epoch  16 Batch   38/69   train_loss = 3.705
Epoch  16 Batch   40/69   train_loss = 3.715
Epoch  16 Batch   42/69   train_loss = 3.887
Epoch  16 Batch   44/69   train_loss = 3.828
Epoch  16 Batch   46/69   train_loss = 3.771
Epoch  16 Batch   48/69   train_loss = 3.815
Epoch  16 Batch   50/69   train_loss = 3.804
Epoch  16 Batch   52/69   train_loss = 3.886
Epoch  16 Batch   54/69   train_loss = 3.920
Epoch  16 Batch   56/69   train_loss = 3.777
Epoch  16 Batch   58/69   train_loss = 3.945
Epoch  16 Batch   60/69   train_loss = 3.746
Epoch  16 Batch   62/69   train_loss = 3.763
Epoch  16 Batch   64/69   train_loss = 3.734
Epoch  16 Batch   66/69   train_loss = 3.645
Epoch  16 Batch   68/69   train_loss = 3.622
Epoch  17 Batch    1/69   train_loss = 3.699
Epoch  17 Batch    3/69   train_loss = 3.786
Epoch  17 Batch    5/69   train_loss = 3.703
Epoch  17 Batch    7/69   train_loss = 3.626
Epoch  17 Batch    9/69   train_loss = 3.760
Epoch  17 Batch   11/69   train_loss = 3.783
Epoch  17 Batch   13/69   train_loss = 3.648
Epoch  17 Batch   15/69   train_loss = 3.632
Epoch  17 Batch   17/69   train_loss = 3.695
Epoch  17 Batch   19/69   train_loss = 3.728
Epoch  17 Batch   21/69   train_loss = 3.670
Epoch  17 Batch   23/69   train_loss = 3.729
Epoch  17 Batch   25/69   train_loss = 3.680
Epoch  17 Batch   27/69   train_loss = 3.659
Epoch  17 Batch   29/69   train_loss = 3.686
Epoch  17 Batch   31/69   train_loss = 3.564
Epoch  17 Batch   33/69   train_loss = 3.690
Epoch  17 Batch   35/69   train_loss = 3.854
Epoch  17 Batch   37/69   train_loss = 3.838
Epoch  17 Batch   39/69   train_loss = 3.803
Epoch  17 Batch   41/69   train_loss = 3.622
Epoch  17 Batch   43/69   train_loss = 3.714
Epoch  17 Batch   45/69   train_loss = 3.748
Epoch  17 Batch   47/69   train_loss = 3.782
Epoch  17 Batch   49/69   train_loss = 3.769
Epoch  17 Batch   51/69   train_loss = 3.743
Epoch  17 Batch   53/69   train_loss = 3.740
Epoch  17 Batch   55/69   train_loss = 3.613
Epoch  17 Batch   57/69   train_loss = 3.793
Epoch  17 Batch   59/69   train_loss = 3.635
Epoch  17 Batch   61/69   train_loss = 3.757
Epoch  17 Batch   63/69   train_loss = 3.713
Epoch  17 Batch   65/69   train_loss = 3.805
Epoch  17 Batch   67/69   train_loss = 3.499
Epoch  18 Batch    0/69   train_loss = 3.521
Epoch  18 Batch    2/69   train_loss = 3.657
Epoch  18 Batch    4/69   train_loss = 3.527
Epoch  18 Batch    6/69   train_loss = 3.603
Epoch  18 Batch    8/69   train_loss = 3.564
Epoch  18 Batch   10/69   train_loss = 3.645
Epoch  18 Batch   12/69   train_loss = 3.599
Epoch  18 Batch   14/69   train_loss = 3.783
Epoch  18 Batch   16/69   train_loss = 3.891
Epoch  18 Batch   18/69   train_loss = 3.517
Epoch  18 Batch   20/69   train_loss = 3.680
Epoch  18 Batch   22/69   train_loss = 3.539
Epoch  18 Batch   24/69   train_loss = 3.509
Epoch  18 Batch   26/69   train_loss = 3.504
Epoch  18 Batch   28/69   train_loss = 3.580
Epoch  18 Batch   30/69   train_loss = 3.619
Epoch  18 Batch   32/69   train_loss = 3.700
Epoch  18 Batch   34/69   train_loss = 3.716
Epoch  18 Batch   36/69   train_loss = 3.606
Epoch  18 Batch   38/69   train_loss = 3.588
Epoch  18 Batch   40/69   train_loss = 3.589
Epoch  18 Batch   42/69   train_loss = 3.754
Epoch  18 Batch   44/69   train_loss = 3.685
Epoch  18 Batch   46/69   train_loss = 3.643
Epoch  18 Batch   48/69   train_loss = 3.684
Epoch  18 Batch   50/69   train_loss = 3.651
Epoch  18 Batch   52/69   train_loss = 3.759
Epoch  18 Batch   54/69   train_loss = 3.763
Epoch  18 Batch   56/69   train_loss = 3.643
Epoch  18 Batch   58/69   train_loss = 3.800
Epoch  18 Batch   60/69   train_loss = 3.616
Epoch  18 Batch   62/69   train_loss = 3.621
Epoch  18 Batch   64/69   train_loss = 3.617
Epoch  18 Batch   66/69   train_loss = 3.524
Epoch  18 Batch   68/69   train_loss = 3.520
Epoch  19 Batch    1/69   train_loss = 3.567
Epoch  19 Batch    3/69   train_loss = 3.631
Epoch  19 Batch    5/69   train_loss = 3.584
Epoch  19 Batch    7/69   train_loss = 3.506
Epoch  19 Batch    9/69   train_loss = 3.635
Epoch  19 Batch   11/69   train_loss = 3.653
Epoch  19 Batch   13/69   train_loss = 3.521
Epoch  19 Batch   15/69   train_loss = 3.514
Epoch  19 Batch   17/69   train_loss = 3.565
Epoch  19 Batch   19/69   train_loss = 3.576
Epoch  19 Batch   21/69   train_loss = 3.548
Epoch  19 Batch   23/69   train_loss = 3.598
Epoch  19 Batch   25/69   train_loss = 3.562
Epoch  19 Batch   27/69   train_loss = 3.534
Epoch  19 Batch   29/69   train_loss = 3.562
Epoch  19 Batch   31/69   train_loss = 3.465
Epoch  19 Batch   33/69   train_loss = 3.580
Epoch  19 Batch   35/69   train_loss = 3.733
Epoch  19 Batch   37/69   train_loss = 3.707
Epoch  19 Batch   39/69   train_loss = 3.684
Epoch  19 Batch   41/69   train_loss = 3.505
Epoch  19 Batch   43/69   train_loss = 3.607
Epoch  19 Batch   45/69   train_loss = 3.615
Epoch  19 Batch   47/69   train_loss = 3.639
Epoch  19 Batch   49/69   train_loss = 3.612
Epoch  19 Batch   51/69   train_loss = 3.595
Epoch  19 Batch   53/69   train_loss = 3.592
Epoch  19 Batch   55/69   train_loss = 3.470
Epoch  19 Batch   57/69   train_loss = 3.648
Epoch  19 Batch   59/69   train_loss = 3.507
Epoch  19 Batch   61/69   train_loss = 3.620
Epoch  19 Batch   63/69   train_loss = 3.583
Epoch  19 Batch   65/69   train_loss = 3.687
Epoch  19 Batch   67/69   train_loss = 3.390
Epoch  20 Batch    0/69   train_loss = 3.415
Epoch  20 Batch    2/69   train_loss = 3.540
Epoch  20 Batch    4/69   train_loss = 3.392
Epoch  20 Batch    6/69   train_loss = 3.474
Epoch  20 Batch    8/69   train_loss = 3.453
Epoch  20 Batch   10/69   train_loss = 3.531
Epoch  20 Batch   12/69   train_loss = 3.484
Epoch  20 Batch   14/69   train_loss = 3.647
Epoch  20 Batch   16/69   train_loss = 3.751
Epoch  20 Batch   18/69   train_loss = 3.410
Epoch  20 Batch   20/69   train_loss = 3.557
Epoch  20 Batch   22/69   train_loss = 3.416
Epoch  20 Batch   24/69   train_loss = 3.404
Epoch  20 Batch   26/69   train_loss = 3.391
Epoch  20 Batch   28/69   train_loss = 3.475
Epoch  20 Batch   30/69   train_loss = 3.498
Epoch  20 Batch   32/69   train_loss = 3.573
Epoch  20 Batch   34/69   train_loss = 3.585
Epoch  20 Batch   36/69   train_loss = 3.502
Epoch  20 Batch   38/69   train_loss = 3.473
Epoch  20 Batch   40/69   train_loss = 3.475
Epoch  20 Batch   42/69   train_loss = 3.615
Epoch  20 Batch   44/69   train_loss = 3.553
Epoch  20 Batch   46/69   train_loss = 3.531
Epoch  20 Batch   48/69   train_loss = 3.569
Epoch  20 Batch   50/69   train_loss = 3.507
Epoch  20 Batch   52/69   train_loss = 3.629
Epoch  20 Batch   54/69   train_loss = 3.592
Epoch  20 Batch   56/69   train_loss = 3.507
Epoch  20 Batch   58/69   train_loss = 3.650
Epoch  20 Batch   60/69   train_loss = 3.481
Epoch  20 Batch   62/69   train_loss = 3.472
Epoch  20 Batch   64/69   train_loss = 3.483
Epoch  20 Batch   66/69   train_loss = 3.406
Epoch  20 Batch   68/69   train_loss = 3.430
Epoch  21 Batch    1/69   train_loss = 3.448
Epoch  21 Batch    3/69   train_loss = 3.476
Epoch  21 Batch    5/69   train_loss = 3.463
Epoch  21 Batch    7/69   train_loss = 3.385
Epoch  21 Batch    9/69   train_loss = 3.507
Epoch  21 Batch   11/69   train_loss = 3.532
Epoch  21 Batch   13/69   train_loss = 3.404
Epoch  21 Batch   15/69   train_loss = 3.404
Epoch  21 Batch   17/69   train_loss = 3.442
Epoch  21 Batch   19/69   train_loss = 3.433
Epoch  21 Batch   21/69   train_loss = 3.427
Epoch  21 Batch   23/69   train_loss = 3.474
Epoch  21 Batch   25/69   train_loss = 3.443
Epoch  21 Batch   27/69   train_loss = 3.415
Epoch  21 Batch   29/69   train_loss = 3.443
Epoch  21 Batch   31/69   train_loss = 3.370
Epoch  21 Batch   33/69   train_loss = 3.469
Epoch  21 Batch   35/69   train_loss = 3.607
Epoch  21 Batch   37/69   train_loss = 3.569
Epoch  21 Batch   39/69   train_loss = 3.555
Epoch  21 Batch   41/69   train_loss = 3.392
Epoch  21 Batch   43/69   train_loss = 3.486
Epoch  21 Batch   45/69   train_loss = 3.484
Epoch  21 Batch   47/69   train_loss = 3.506
Epoch  21 Batch   49/69   train_loss = 3.467
Epoch  21 Batch   51/69   train_loss = 3.459
Epoch  21 Batch   53/69   train_loss = 3.454
Epoch  21 Batch   55/69   train_loss = 3.338
Epoch  21 Batch   57/69   train_loss = 3.507
Epoch  21 Batch   59/69   train_loss = 3.387
Epoch  21 Batch   61/69   train_loss = 3.484
Epoch  21 Batch   63/69   train_loss = 3.456
Epoch  21 Batch   65/69   train_loss = 3.556
Epoch  21 Batch   67/69   train_loss = 3.281
Epoch  22 Batch    0/69   train_loss = 3.314
Epoch  22 Batch    2/69   train_loss = 3.430
Epoch  22 Batch    4/69   train_loss = 3.266
Epoch  22 Batch    6/69   train_loss = 3.346
Epoch  22 Batch    8/69   train_loss = 3.344
Epoch  22 Batch   10/69   train_loss = 3.420
Epoch  22 Batch   12/69   train_loss = 3.375
Epoch  22 Batch   14/69   train_loss = 3.512
Epoch  22 Batch   16/69   train_loss = 3.621
Epoch  22 Batch   18/69   train_loss = 3.308
Epoch  22 Batch   20/69   train_loss = 3.440
Epoch  22 Batch   22/69   train_loss = 3.304
Epoch  22 Batch   24/69   train_loss = 3.315
Epoch  22 Batch   26/69   train_loss = 3.283
Epoch  22 Batch   28/69   train_loss = 3.365
Epoch  22 Batch   30/69   train_loss = 3.379
Epoch  22 Batch   32/69   train_loss = 3.454
Epoch  22 Batch   34/69   train_loss = 3.458
Epoch  22 Batch   36/69   train_loss = 3.394
Epoch  22 Batch   38/69   train_loss = 3.356
Epoch  22 Batch   40/69   train_loss = 3.361
Epoch  22 Batch   42/69   train_loss = 3.480
Epoch  22 Batch   44/69   train_loss = 3.420
Epoch  22 Batch   46/69   train_loss = 3.414
Epoch  22 Batch   48/69   train_loss = 3.456
Epoch  22 Batch   50/69   train_loss = 3.373
Epoch  22 Batch   52/69   train_loss = 3.508
Epoch  22 Batch   54/69   train_loss = 3.432
Epoch  22 Batch   56/69   train_loss = 3.374
Epoch  22 Batch   58/69   train_loss = 3.513
Epoch  22 Batch   60/69   train_loss = 3.362
Epoch  22 Batch   62/69   train_loss = 3.333
Epoch  22 Batch   64/69   train_loss = 3.357
Epoch  22 Batch   66/69   train_loss = 3.293
Epoch  22 Batch   68/69   train_loss = 3.344
Epoch  23 Batch    1/69   train_loss = 3.324
Epoch  23 Batch    3/69   train_loss = 3.332
Epoch  23 Batch    5/69   train_loss = 3.358
Epoch  23 Batch    7/69   train_loss = 3.274
Epoch  23 Batch    9/69   train_loss = 3.385
Epoch  23 Batch   11/69   train_loss = 3.417
Epoch  23 Batch   13/69   train_loss = 3.291
Epoch  23 Batch   15/69   train_loss = 3.302
Epoch  23 Batch   17/69   train_loss = 3.325
Epoch  23 Batch   19/69   train_loss = 3.295
Epoch  23 Batch   21/69   train_loss = 3.315
Epoch  23 Batch   23/69   train_loss = 3.357
Epoch  23 Batch   25/69   train_loss = 3.330
Epoch  23 Batch   27/69   train_loss = 3.311
Epoch  23 Batch   29/69   train_loss = 3.329
Epoch  23 Batch   31/69   train_loss = 3.278
Epoch  23 Batch   33/69   train_loss = 3.361
Epoch  23 Batch   35/69   train_loss = 3.494
Epoch  23 Batch   37/69   train_loss = 3.438
Epoch  23 Batch   39/69   train_loss = 3.430
Epoch  23 Batch   41/69   train_loss = 3.281
Epoch  23 Batch   43/69   train_loss = 3.373
Epoch  23 Batch   45/69   train_loss = 3.364
Epoch  23 Batch   47/69   train_loss = 3.383
Epoch  23 Batch   49/69   train_loss = 3.330
Epoch  23 Batch   51/69   train_loss = 3.332
Epoch  23 Batch   53/69   train_loss = 3.327
Epoch  23 Batch   55/69   train_loss = 3.218
Epoch  23 Batch   57/69   train_loss = 3.376
Epoch  23 Batch   59/69   train_loss = 3.280
Epoch  23 Batch   61/69   train_loss = 3.358
Epoch  23 Batch   63/69   train_loss = 3.335
Epoch  23 Batch   65/69   train_loss = 3.425
Epoch  23 Batch   67/69   train_loss = 3.176
Epoch  24 Batch    0/69   train_loss = 3.218
Epoch  24 Batch    2/69   train_loss = 3.325
Epoch  24 Batch    4/69   train_loss = 3.147
Epoch  24 Batch    6/69   train_loss = 3.229
Epoch  24 Batch    8/69   train_loss = 3.249
Epoch  24 Batch   10/69   train_loss = 3.314
Epoch  24 Batch   12/69   train_loss = 3.272
Epoch  24 Batch   14/69   train_loss = 3.389
Epoch  24 Batch   16/69   train_loss = 3.498
Epoch  24 Batch   18/69   train_loss = 3.214
Epoch  24 Batch   20/69   train_loss = 3.335
Epoch  24 Batch   22/69   train_loss = 3.202
Epoch  24 Batch   24/69   train_loss = 3.222
Epoch  24 Batch   26/69   train_loss = 3.183
Epoch  24 Batch   28/69   train_loss = 3.269
Epoch  24 Batch   30/69   train_loss = 3.273
Epoch  24 Batch   32/69   train_loss = 3.342
Epoch  24 Batch   34/69   train_loss = 3.342
Epoch  24 Batch   36/69   train_loss = 3.304
Epoch  24 Batch   38/69   train_loss = 3.251
Epoch  24 Batch   40/69   train_loss = 3.259
Epoch  24 Batch   42/69   train_loss = 3.353
Epoch  24 Batch   44/69   train_loss = 3.294
Epoch  24 Batch   46/69   train_loss = 3.305
Epoch  24 Batch   48/69   train_loss = 3.350
Epoch  24 Batch   50/69   train_loss = 3.255
Epoch  24 Batch   52/69   train_loss = 3.400
Epoch  24 Batch   54/69   train_loss = 3.290
Epoch  24 Batch   56/69   train_loss = 3.256
Epoch  24 Batch   58/69   train_loss = 3.386
Epoch  24 Batch   60/69   train_loss = 3.261
Epoch  24 Batch   62/69   train_loss = 3.211
Epoch  24 Batch   64/69   train_loss = 3.236
Epoch  24 Batch   66/69   train_loss = 3.189
Epoch  24 Batch   68/69   train_loss = 3.270
Epoch  25 Batch    1/69   train_loss = 3.212
Epoch  25 Batch    3/69   train_loss = 3.198
Epoch  25 Batch    5/69   train_loss = 3.255
Epoch  25 Batch    7/69   train_loss = 3.170
Epoch  25 Batch    9/69   train_loss = 3.264
Epoch  25 Batch   11/69   train_loss = 3.311
Epoch  25 Batch   13/69   train_loss = 3.188
Epoch  25 Batch   15/69   train_loss = 3.205
Epoch  25 Batch   17/69   train_loss = 3.227
Epoch  25 Batch   19/69   train_loss = 3.164
Epoch  25 Batch   21/69   train_loss = 3.204
Epoch  25 Batch   23/69   train_loss = 3.241
Epoch  25 Batch   25/69   train_loss = 3.227
Epoch  25 Batch   27/69   train_loss = 3.216
Epoch  25 Batch   29/69   train_loss = 3.218
Epoch  25 Batch   31/69   train_loss = 3.196
Epoch  25 Batch   33/69   train_loss = 3.255
Epoch  25 Batch   35/69   train_loss = 3.383
Epoch  25 Batch   37/69   train_loss = 3.318
Epoch  25 Batch   39/69   train_loss = 3.323
Epoch  25 Batch   41/69   train_loss = 3.187
Epoch  25 Batch   43/69   train_loss = 3.266
Epoch  25 Batch   45/69   train_loss = 3.259
Epoch  25 Batch   47/69   train_loss = 3.270
Epoch  25 Batch   49/69   train_loss = 3.203
Epoch  25 Batch   51/69   train_loss = 3.216
Epoch  25 Batch   53/69   train_loss = 3.218
Epoch  25 Batch   55/69   train_loss = 3.116
Epoch  25 Batch   57/69   train_loss = 3.248
Epoch  25 Batch   59/69   train_loss = 3.171
Epoch  25 Batch   61/69   train_loss = 3.251
Epoch  25 Batch   63/69   train_loss = 3.234
Epoch  25 Batch   65/69   train_loss = 3.311
Epoch  25 Batch   67/69   train_loss = 3.084
Epoch  26 Batch    0/69   train_loss = 3.132
Epoch  26 Batch    2/69   train_loss = 3.242
Epoch  26 Batch    4/69   train_loss = 3.042
Epoch  26 Batch    6/69   train_loss = 3.113
Epoch  26 Batch    8/69   train_loss = 3.167
Epoch  26 Batch   10/69   train_loss = 3.222
Epoch  26 Batch   12/69   train_loss = 3.179
Epoch  26 Batch   14/69   train_loss = 3.275
Epoch  26 Batch   16/69   train_loss = 3.382
Epoch  26 Batch   18/69   train_loss = 3.136
Epoch  26 Batch   20/69   train_loss = 3.239
Epoch  26 Batch   22/69   train_loss = 3.107
Epoch  26 Batch   24/69   train_loss = 3.145
Epoch  26 Batch   26/69   train_loss = 3.085
Epoch  26 Batch   28/69   train_loss = 3.177
Epoch  26 Batch   30/69   train_loss = 3.171
Epoch  26 Batch   32/69   train_loss = 3.239
Epoch  26 Batch   34/69   train_loss = 3.226
Epoch  26 Batch   36/69   train_loss = 3.205
Epoch  26 Batch   38/69   train_loss = 3.150
Epoch  26 Batch   40/69   train_loss = 3.158
Epoch  26 Batch   42/69   train_loss = 3.243
Epoch  26 Batch   44/69   train_loss = 3.179
Epoch  26 Batch   46/69   train_loss = 3.196
Epoch  26 Batch   48/69   train_loss = 3.238
Epoch  26 Batch   50/69   train_loss = 3.124
Epoch  26 Batch   52/69   train_loss = 3.284
Epoch  26 Batch   54/69   train_loss = 3.158
Epoch  26 Batch   56/69   train_loss = 3.150
Epoch  26 Batch   58/69   train_loss = 3.262
Epoch  26 Batch   60/69   train_loss = 3.146
Epoch  26 Batch   62/69   train_loss = 3.094
Epoch  26 Batch   64/69   train_loss = 3.133
Epoch  26 Batch   66/69   train_loss = 3.097
Epoch  26 Batch   68/69   train_loss = 3.188
Epoch  27 Batch    1/69   train_loss = 3.092
Epoch  27 Batch    3/69   train_loss = 3.079
Epoch  27 Batch    5/69   train_loss = 3.166
Epoch  27 Batch    7/69   train_loss = 3.077
Epoch  27 Batch    9/69   train_loss = 3.156
Epoch  27 Batch   11/69   train_loss = 3.214
Epoch  27 Batch   13/69   train_loss = 3.108
Epoch  27 Batch   15/69   train_loss = 3.117
Epoch  27 Batch   17/69   train_loss = 3.129
Epoch  27 Batch   19/69   train_loss = 3.044
Epoch  27 Batch   21/69   train_loss = 3.092
Epoch  27 Batch   23/69   train_loss = 3.138
Epoch  27 Batch   25/69   train_loss = 3.123
Epoch  27 Batch   27/69   train_loss = 3.121
Epoch  27 Batch   29/69   train_loss = 3.119
Epoch  27 Batch   31/69   train_loss = 3.118
Epoch  27 Batch   33/69   train_loss = 3.154
Epoch  27 Batch   35/69   train_loss = 3.274
Epoch  27 Batch   37/69   train_loss = 3.200
Epoch  27 Batch   39/69   train_loss = 3.207
Epoch  27 Batch   41/69   train_loss = 3.089
Epoch  27 Batch   43/69   train_loss = 3.168
Epoch  27 Batch   45/69   train_loss = 3.163
Epoch  27 Batch   47/69   train_loss = 3.167
Epoch  27 Batch   49/69   train_loss = 3.088
Epoch  27 Batch   51/69   train_loss = 3.095
Epoch  27 Batch   53/69   train_loss = 3.097
Epoch  27 Batch   55/69   train_loss = 3.016
Epoch  27 Batch   57/69   train_loss = 3.138
Epoch  27 Batch   59/69   train_loss = 3.087
Epoch  27 Batch   61/69   train_loss = 3.128
Epoch  27 Batch   63/69   train_loss = 3.133
Epoch  27 Batch   65/69   train_loss = 3.214
Epoch  27 Batch   67/69   train_loss = 2.994
Epoch  28 Batch    0/69   train_loss = 3.044
Epoch  28 Batch    2/69   train_loss = 3.133
Epoch  28 Batch    4/69   train_loss = 2.940
Epoch  28 Batch    6/69   train_loss = 3.013
Epoch  28 Batch    8/69   train_loss = 3.081
Epoch  28 Batch   10/69   train_loss = 3.121
Epoch  28 Batch   12/69   train_loss = 3.086
Epoch  28 Batch   14/69   train_loss = 3.171
Epoch  28 Batch   16/69   train_loss = 3.285
Epoch  28 Batch   18/69   train_loss = 3.027
Epoch  28 Batch   20/69   train_loss = 3.135
Epoch  28 Batch   22/69   train_loss = 3.016
Epoch  28 Batch   24/69   train_loss = 3.079
Epoch  28 Batch   26/69   train_loss = 2.995
Epoch  28 Batch   28/69   train_loss = 3.096
Epoch  28 Batch   30/69   train_loss = 3.079
Epoch  28 Batch   32/69   train_loss = 3.143
Epoch  28 Batch   34/69   train_loss = 3.121
Epoch  28 Batch   36/69   train_loss = 3.107
Epoch  28 Batch   38/69   train_loss = 3.050
Epoch  28 Batch   40/69   train_loss = 3.053
Epoch  28 Batch   42/69   train_loss = 3.137
Epoch  28 Batch   44/69   train_loss = 3.080
Epoch  28 Batch   46/69   train_loss = 3.108
Epoch  28 Batch   48/69   train_loss = 3.136
Epoch  28 Batch   50/69   train_loss = 3.009
Epoch  28 Batch   52/69   train_loss = 3.175
Epoch  28 Batch   54/69   train_loss = 3.028
Epoch  28 Batch   56/69   train_loss = 3.035
Epoch  28 Batch   58/69   train_loss = 3.155
Epoch  28 Batch   60/69   train_loss = 3.050
Epoch  28 Batch   62/69   train_loss = 2.982
Epoch  28 Batch   64/69   train_loss = 3.031
Epoch  28 Batch   66/69   train_loss = 3.011
Epoch  28 Batch   68/69   train_loss = 3.118
Epoch  29 Batch    1/69   train_loss = 2.992
Epoch  29 Batch    3/69   train_loss = 2.949
Epoch  29 Batch    5/69   train_loss = 3.062
Epoch  29 Batch    7/69   train_loss = 2.986
Epoch  29 Batch    9/69   train_loss = 3.068
Epoch  29 Batch   11/69   train_loss = 3.099
Epoch  29 Batch   13/69   train_loss = 3.001
Epoch  29 Batch   15/69   train_loss = 3.017
Epoch  29 Batch   17/69   train_loss = 3.025
Epoch  29 Batch   19/69   train_loss = 2.927
Epoch  29 Batch   21/69   train_loss = 2.994
Epoch  29 Batch   23/69   train_loss = 3.029
Epoch  29 Batch   25/69   train_loss = 3.028
Epoch  29 Batch   27/69   train_loss = 3.027
Epoch  29 Batch   29/69   train_loss = 3.026
Epoch  29 Batch   31/69   train_loss = 3.032
Epoch  29 Batch   33/69   train_loss = 3.063
Epoch  29 Batch   35/69   train_loss = 3.171
Epoch  29 Batch   37/69   train_loss = 3.080
Epoch  29 Batch   39/69   train_loss = 3.098
Epoch  29 Batch   41/69   train_loss = 3.001
Epoch  29 Batch   43/69   train_loss = 3.076
Epoch  29 Batch   45/69   train_loss = 3.058
Epoch  29 Batch   47/69   train_loss = 3.068
Epoch  29 Batch   49/69   train_loss = 2.975
Epoch  29 Batch   51/69   train_loss = 2.989
Epoch  29 Batch   53/69   train_loss = 2.989
Epoch  29 Batch   55/69   train_loss = 2.918
Epoch  29 Batch   57/69   train_loss = 3.024
Epoch  29 Batch   59/69   train_loss = 2.999
Epoch  29 Batch   61/69   train_loss = 3.030
Epoch  29 Batch   63/69   train_loss = 3.050
Epoch  29 Batch   65/69   train_loss = 3.104
Epoch  29 Batch   67/69   train_loss = 2.906
Epoch  30 Batch    0/69   train_loss = 2.972
Epoch  30 Batch    2/69   train_loss = 3.046
Epoch  30 Batch    4/69   train_loss = 2.842
Epoch  30 Batch    6/69   train_loss = 2.901
Epoch  30 Batch    8/69   train_loss = 2.982
Epoch  30 Batch   10/69   train_loss = 3.033
Epoch  30 Batch   12/69   train_loss = 2.997
Epoch  30 Batch   14/69   train_loss = 3.047
Epoch  30 Batch   16/69   train_loss = 3.169
Epoch  30 Batch   18/69   train_loss = 2.928
Epoch  30 Batch   20/69   train_loss = 3.028
Epoch  30 Batch   22/69   train_loss = 2.923
Epoch  30 Batch   24/69   train_loss = 2.983
Epoch  30 Batch   26/69   train_loss = 2.893
Epoch  30 Batch   28/69   train_loss = 3.003
Epoch  30 Batch   30/69   train_loss = 2.993
Epoch  30 Batch   32/69   train_loss = 3.041
Epoch  30 Batch   34/69   train_loss = 3.011
Epoch  30 Batch   36/69   train_loss = 3.015
Epoch  30 Batch   38/69   train_loss = 2.957
Epoch  30 Batch   40/69   train_loss = 2.958
Epoch  30 Batch   42/69   train_loss = 3.026
Epoch  30 Batch   44/69   train_loss = 2.974
Epoch  30 Batch   46/69   train_loss = 3.024
Epoch  30 Batch   48/69   train_loss = 3.048
Epoch  30 Batch   50/69   train_loss = 2.907
Epoch  30 Batch   52/69   train_loss = 3.081
Epoch  30 Batch   54/69   train_loss = 2.909
Epoch  30 Batch   56/69   train_loss = 2.932
Epoch  30 Batch   58/69   train_loss = 3.047
Epoch  30 Batch   60/69   train_loss = 2.958
Epoch  30 Batch   62/69   train_loss = 2.880
Epoch  30 Batch   64/69   train_loss = 2.941
Epoch  30 Batch   66/69   train_loss = 2.929
Epoch  30 Batch   68/69   train_loss = 3.049
Epoch  31 Batch    1/69   train_loss = 2.901
Epoch  31 Batch    3/69   train_loss = 2.845
Epoch  31 Batch    5/69   train_loss = 2.982
Epoch  31 Batch    7/69   train_loss = 2.899
Epoch  31 Batch    9/69   train_loss = 2.966
Epoch  31 Batch   11/69   train_loss = 3.008
Epoch  31 Batch   13/69   train_loss = 2.908
Epoch  31 Batch   15/69   train_loss = 2.918
Epoch  31 Batch   17/69   train_loss = 2.921
Epoch  31 Batch   19/69   train_loss = 2.807
Epoch  31 Batch   21/69   train_loss = 2.905
Epoch  31 Batch   23/69   train_loss = 2.929
Epoch  31 Batch   25/69   train_loss = 2.930
Epoch  31 Batch   27/69   train_loss = 2.932
Epoch  31 Batch   29/69   train_loss = 2.924
Epoch  31 Batch   31/69   train_loss = 2.957
Epoch  31 Batch   33/69   train_loss = 2.982
Epoch  31 Batch   35/69   train_loss = 3.078
Epoch  31 Batch   37/69   train_loss = 2.963
Epoch  31 Batch   39/69   train_loss = 2.998
Epoch  31 Batch   41/69   train_loss = 2.921
Epoch  31 Batch   43/69   train_loss = 2.983
Epoch  31 Batch   45/69   train_loss = 2.967
Epoch  31 Batch   47/69   train_loss = 2.979
Epoch  31 Batch   49/69   train_loss = 2.875
Epoch  31 Batch   51/69   train_loss = 2.893
Epoch  31 Batch   53/69   train_loss = 2.897
Epoch  31 Batch   55/69   train_loss = 2.834
Epoch  31 Batch   57/69   train_loss = 2.918
Epoch  31 Batch   59/69   train_loss = 2.914
Epoch  31 Batch   61/69   train_loss = 2.938
Epoch  31 Batch   63/69   train_loss = 2.953
Epoch  31 Batch   65/69   train_loss = 3.006
Epoch  31 Batch   67/69   train_loss = 2.828
Epoch  32 Batch    0/69   train_loss = 2.895
Epoch  32 Batch    2/69   train_loss = 2.969
Epoch  32 Batch    4/69   train_loss = 2.759
Epoch  32 Batch    6/69   train_loss = 2.808
Epoch  32 Batch    8/69   train_loss = 2.912
Epoch  32 Batch   10/69   train_loss = 2.953
Epoch  32 Batch   12/69   train_loss = 2.914
Epoch  32 Batch   14/69   train_loss = 2.943
Epoch  32 Batch   16/69   train_loss = 3.063
Epoch  32 Batch   18/69   train_loss = 2.850
Epoch  32 Batch   20/69   train_loss = 2.923
Epoch  32 Batch   22/69   train_loss = 2.831
Epoch  32 Batch   24/69   train_loss = 2.901
Epoch  32 Batch   26/69   train_loss = 2.800
Epoch  32 Batch   28/69   train_loss = 2.903
Epoch  32 Batch   30/69   train_loss = 2.892
Epoch  32 Batch   32/69   train_loss = 2.949
Epoch  32 Batch   34/69   train_loss = 2.913
Epoch  32 Batch   36/69   train_loss = 2.938
Epoch  32 Batch   38/69   train_loss = 2.869
Epoch  32 Batch   40/69   train_loss = 2.854
Epoch  32 Batch   42/69   train_loss = 2.925
Epoch  32 Batch   44/69   train_loss = 2.871
Epoch  32 Batch   46/69   train_loss = 2.944
Epoch  32 Batch   48/69   train_loss = 2.961
Epoch  32 Batch   50/69   train_loss = 2.812
Epoch  32 Batch   52/69   train_loss = 2.985
Epoch  32 Batch   54/69   train_loss = 2.812
Epoch  32 Batch   56/69   train_loss = 2.847
Epoch  32 Batch   58/69   train_loss = 2.945
Epoch  32 Batch   60/69   train_loss = 2.872
Epoch  32 Batch   62/69   train_loss = 2.790
Epoch  32 Batch   64/69   train_loss = 2.853
Epoch  32 Batch   66/69   train_loss = 2.855
Epoch  32 Batch   68/69   train_loss = 2.984
Epoch  33 Batch    1/69   train_loss = 2.820
Epoch  33 Batch    3/69   train_loss = 2.751
Epoch  33 Batch    5/69   train_loss = 2.905
Epoch  33 Batch    7/69   train_loss = 2.831
Epoch  33 Batch    9/69   train_loss = 2.884
Epoch  33 Batch   11/69   train_loss = 2.928
Epoch  33 Batch   13/69   train_loss = 2.850
Epoch  33 Batch   15/69   train_loss = 2.850
Epoch  33 Batch   17/69   train_loss = 2.841
Epoch  33 Batch   19/69   train_loss = 2.707
Epoch  33 Batch   21/69   train_loss = 2.804
Epoch  33 Batch   23/69   train_loss = 2.834
Epoch  33 Batch   25/69   train_loss = 2.832
Epoch  33 Batch   27/69   train_loss = 2.841
Epoch  33 Batch   29/69   train_loss = 2.827
Epoch  33 Batch   31/69   train_loss = 2.868
Epoch  33 Batch   33/69   train_loss = 2.889
Epoch  33 Batch   35/69   train_loss = 2.986
Epoch  33 Batch   37/69   train_loss = 2.855
Epoch  33 Batch   39/69   train_loss = 2.897
Epoch  33 Batch   41/69   train_loss = 2.824
Epoch  33 Batch   43/69   train_loss = 2.886
Epoch  33 Batch   45/69   train_loss = 2.882
Epoch  33 Batch   47/69   train_loss = 2.894
Epoch  33 Batch   49/69   train_loss = 2.794
Epoch  33 Batch   51/69   train_loss = 2.803
Epoch  33 Batch   53/69   train_loss = 2.808
Epoch  33 Batch   55/69   train_loss = 2.757
Epoch  33 Batch   57/69   train_loss = 2.818
Epoch  33 Batch   59/69   train_loss = 2.851
Epoch  33 Batch   61/69   train_loss = 2.835
Epoch  33 Batch   63/69   train_loss = 2.875
Epoch  33 Batch   65/69   train_loss = 2.926
Epoch  33 Batch   67/69   train_loss = 2.745
Epoch  34 Batch    0/69   train_loss = 2.824
Epoch  34 Batch    2/69   train_loss = 2.878
Epoch  34 Batch    4/69   train_loss = 2.686
Epoch  34 Batch    6/69   train_loss = 2.739
Epoch  34 Batch    8/69   train_loss = 2.850
Epoch  34 Batch   10/69   train_loss = 2.873
Epoch  34 Batch   12/69   train_loss = 2.845
Epoch  34 Batch   14/69   train_loss = 2.872
Epoch  34 Batch   16/69   train_loss = 2.993
Epoch  34 Batch   18/69   train_loss = 2.774
Epoch  34 Batch   20/69   train_loss = 2.838
Epoch  34 Batch   22/69   train_loss = 2.751
Epoch  34 Batch   24/69   train_loss = 2.840
Epoch  34 Batch   26/69   train_loss = 2.729
Epoch  34 Batch   28/69   train_loss = 2.821
Epoch  34 Batch   30/69   train_loss = 2.808
Epoch  34 Batch   32/69   train_loss = 2.864
Epoch  34 Batch   34/69   train_loss = 2.827
Epoch  34 Batch   36/69   train_loss = 2.861
Epoch  34 Batch   38/69   train_loss = 2.788
Epoch  34 Batch   40/69   train_loss = 2.765
Epoch  34 Batch   42/69   train_loss = 2.832
Epoch  34 Batch   44/69   train_loss = 2.775
Epoch  34 Batch   46/69   train_loss = 2.857
Epoch  34 Batch   48/69   train_loss = 2.875
Epoch  34 Batch   50/69   train_loss = 2.734
Epoch  34 Batch   52/69   train_loss = 2.902
Epoch  34 Batch   54/69   train_loss = 2.709
Epoch  34 Batch   56/69   train_loss = 2.761
Epoch  34 Batch   58/69   train_loss = 2.856
Epoch  34 Batch   60/69   train_loss = 2.795
Epoch  34 Batch   62/69   train_loss = 2.695
Epoch  34 Batch   64/69   train_loss = 2.767
Epoch  34 Batch   66/69   train_loss = 2.773
Epoch  34 Batch   68/69   train_loss = 2.922
Epoch  35 Batch    1/69   train_loss = 2.744
Epoch  35 Batch    3/69   train_loss = 2.660
Epoch  35 Batch    5/69   train_loss = 2.829
Epoch  35 Batch    7/69   train_loss = 2.772
Epoch  35 Batch    9/69   train_loss = 2.825
Epoch  35 Batch   11/69   train_loss = 2.840
Epoch  35 Batch   13/69   train_loss = 2.777
Epoch  35 Batch   15/69   train_loss = 2.775
Epoch  35 Batch   17/69   train_loss = 2.770
Epoch  35 Batch   19/69   train_loss = 2.627
Epoch  35 Batch   21/69   train_loss = 2.736
Epoch  35 Batch   23/69   train_loss = 2.759
Epoch  35 Batch   25/69   train_loss = 2.754
Epoch  35 Batch   27/69   train_loss = 2.766
Epoch  35 Batch   29/69   train_loss = 2.756
Epoch  35 Batch   31/69   train_loss = 2.800
Epoch  35 Batch   33/69   train_loss = 2.806
Epoch  35 Batch   35/69   train_loss = 2.900
Epoch  35 Batch   37/69   train_loss = 2.758
Epoch  35 Batch   39/69   train_loss = 2.804
Epoch  35 Batch   41/69   train_loss = 2.743
Epoch  35 Batch   43/69   train_loss = 2.797
Epoch  35 Batch   45/69   train_loss = 2.776
Epoch  35 Batch   47/69   train_loss = 2.796
Epoch  35 Batch   49/69   train_loss = 2.694
Epoch  35 Batch   51/69   train_loss = 2.709
Epoch  35 Batch   53/69   train_loss = 2.727
Epoch  35 Batch   55/69   train_loss = 2.673
Epoch  35 Batch   57/69   train_loss = 2.721
Epoch  35 Batch   59/69   train_loss = 2.788
Epoch  35 Batch   61/69   train_loss = 2.757
Epoch  35 Batch   63/69   train_loss = 2.803
Epoch  35 Batch   65/69   train_loss = 2.835
Epoch  35 Batch   67/69   train_loss = 2.660
Epoch  36 Batch    0/69   train_loss = 2.751
Epoch  36 Batch    2/69   train_loss = 2.798
Epoch  36 Batch    4/69   train_loss = 2.611
Epoch  36 Batch    6/69   train_loss = 2.659
Epoch  36 Batch    8/69   train_loss = 2.788
Epoch  36 Batch   10/69   train_loss = 2.801
Epoch  36 Batch   12/69   train_loss = 2.783
Epoch  36 Batch   14/69   train_loss = 2.776
Epoch  36 Batch   16/69   train_loss = 2.904
Epoch  36 Batch   18/69   train_loss = 2.703
Epoch  36 Batch   20/69   train_loss = 2.760
Epoch  36 Batch   22/69   train_loss = 2.690
Epoch  36 Batch   24/69   train_loss = 2.764
Epoch  36 Batch   26/69   train_loss = 2.655
Epoch  36 Batch   28/69   train_loss = 2.740
Epoch  36 Batch   30/69   train_loss = 2.736
Epoch  36 Batch   32/69   train_loss = 2.778
Epoch  36 Batch   34/69   train_loss = 2.742
Epoch  36 Batch   36/69   train_loss = 2.786
Epoch  36 Batch   38/69   train_loss = 2.710
Epoch  36 Batch   40/69   train_loss = 2.692
Epoch  36 Batch   42/69   train_loss = 2.745
Epoch  36 Batch   44/69   train_loss = 2.683
Epoch  36 Batch   46/69   train_loss = 2.773
Epoch  36 Batch   48/69   train_loss = 2.782
Epoch  36 Batch   50/69   train_loss = 2.628
Epoch  36 Batch   52/69   train_loss = 2.808
Epoch  36 Batch   54/69   train_loss = 2.610
Epoch  36 Batch   56/69   train_loss = 2.663
Epoch  36 Batch   58/69   train_loss = 2.750
Epoch  36 Batch   60/69   train_loss = 2.696
Epoch  36 Batch   62/69   train_loss = 2.605
Epoch  36 Batch   64/69   train_loss = 2.690
Epoch  36 Batch   66/69   train_loss = 2.688
Epoch  36 Batch   68/69   train_loss = 2.846
Epoch  37 Batch    1/69   train_loss = 2.662
Epoch  37 Batch    3/69   train_loss = 2.568
Epoch  37 Batch    5/69   train_loss = 2.749
Epoch  37 Batch    7/69   train_loss = 2.684
Epoch  37 Batch    9/69   train_loss = 2.728
Epoch  37 Batch   11/69   train_loss = 2.744
Epoch  37 Batch   13/69   train_loss = 2.701
Epoch  37 Batch   15/69   train_loss = 2.699
Epoch  37 Batch   17/69   train_loss = 2.684
Epoch  37 Batch   19/69   train_loss = 2.535
Epoch  37 Batch   21/69   train_loss = 2.661
Epoch  37 Batch   23/69   train_loss = 2.687
Epoch  37 Batch   25/69   train_loss = 2.675
Epoch  37 Batch   27/69   train_loss = 2.679
Epoch  37 Batch   29/69   train_loss = 2.675
Epoch  37 Batch   31/69   train_loss = 2.725
Epoch  37 Batch   33/69   train_loss = 2.729
Epoch  37 Batch   35/69   train_loss = 2.811
Epoch  37 Batch   37/69   train_loss = 2.660
Epoch  37 Batch   39/69   train_loss = 2.712
Epoch  37 Batch   41/69   train_loss = 2.672
Epoch  37 Batch   43/69   train_loss = 2.710
Epoch  37 Batch   45/69   train_loss = 2.693
Epoch  37 Batch   47/69   train_loss = 2.713
Epoch  37 Batch   49/69   train_loss = 2.603
Epoch  37 Batch   51/69   train_loss = 2.612
Epoch  37 Batch   53/69   train_loss = 2.634
Epoch  37 Batch   55/69   train_loss = 2.593
Epoch  37 Batch   57/69   train_loss = 2.631
Epoch  37 Batch   59/69   train_loss = 2.704
Epoch  37 Batch   61/69   train_loss = 2.653
Epoch  37 Batch   63/69   train_loss = 2.707
Epoch  37 Batch   65/69   train_loss = 2.742
Epoch  37 Batch   67/69   train_loss = 2.579
Epoch  38 Batch    0/69   train_loss = 2.659
Epoch  38 Batch    2/69   train_loss = 2.711
Epoch  38 Batch    4/69   train_loss = 2.522
Epoch  38 Batch    6/69   train_loss = 2.561
Epoch  38 Batch    8/69   train_loss = 2.704
Epoch  38 Batch   10/69   train_loss = 2.718
Epoch  38 Batch   12/69   train_loss = 2.698
Epoch  38 Batch   14/69   train_loss = 2.679
Epoch  38 Batch   16/69   train_loss = 2.809
Epoch  38 Batch   18/69   train_loss = 2.622
Epoch  38 Batch   20/69   train_loss = 2.666
Epoch  38 Batch   22/69   train_loss = 2.611
Epoch  38 Batch   24/69   train_loss = 2.696
Epoch  38 Batch   26/69   train_loss = 2.577
Epoch  38 Batch   28/69   train_loss = 2.662
Epoch  38 Batch   30/69   train_loss = 2.648
Epoch  38 Batch   32/69   train_loss = 2.683
Epoch  38 Batch   34/69   train_loss = 2.658
Epoch  38 Batch   36/69   train_loss = 2.711
Epoch  38 Batch   38/69   train_loss = 2.629
Epoch  38 Batch   40/69   train_loss = 2.604
Epoch  38 Batch   42/69   train_loss = 2.652
Epoch  38 Batch   44/69   train_loss = 2.596
Epoch  38 Batch   46/69   train_loss = 2.688
Epoch  38 Batch   48/69   train_loss = 2.695
Epoch  38 Batch   50/69   train_loss = 2.534
Epoch  38 Batch   52/69   train_loss = 2.720
Epoch  38 Batch   54/69   train_loss = 2.516
Epoch  38 Batch   56/69   train_loss = 2.582
Epoch  38 Batch   58/69   train_loss = 2.658
Epoch  38 Batch   60/69   train_loss = 2.608
Epoch  38 Batch   62/69   train_loss = 2.508
Epoch  38 Batch   64/69   train_loss = 2.607
Epoch  38 Batch   66/69   train_loss = 2.602
Epoch  38 Batch   68/69   train_loss = 2.772
Epoch  39 Batch    1/69   train_loss = 2.582
Epoch  39 Batch    3/69   train_loss = 2.475
Epoch  39 Batch    5/69   train_loss = 2.660
Epoch  39 Batch    7/69   train_loss = 2.599
Epoch  39 Batch    9/69   train_loss = 2.638
Epoch  39 Batch   11/69   train_loss = 2.648
Epoch  39 Batch   13/69   train_loss = 2.620
Epoch  39 Batch   15/69   train_loss = 2.624
Epoch  39 Batch   17/69   train_loss = 2.607
Epoch  39 Batch   19/69   train_loss = 2.445
Epoch  39 Batch   21/69   train_loss = 2.570
Epoch  39 Batch   23/69   train_loss = 2.598
Epoch  39 Batch   25/69   train_loss = 2.593
Epoch  39 Batch   27/69   train_loss = 2.606
Epoch  39 Batch   29/69   train_loss = 2.598
Epoch  39 Batch   31/69   train_loss = 2.645
Epoch  39 Batch   33/69   train_loss = 2.640
Epoch  39 Batch   35/69   train_loss = 2.723
Epoch  39 Batch   37/69   train_loss = 2.566
Epoch  39 Batch   39/69   train_loss = 2.619
Epoch  39 Batch   41/69   train_loss = 2.584
Epoch  39 Batch   43/69   train_loss = 2.624
Epoch  39 Batch   45/69   train_loss = 2.609
Epoch  39 Batch   47/69   train_loss = 2.640
Epoch  39 Batch   49/69   train_loss = 2.523
Epoch  39 Batch   51/69   train_loss = 2.529
Epoch  39 Batch   53/69   train_loss = 2.553
Epoch  39 Batch   55/69   train_loss = 2.519
Epoch  39 Batch   57/69   train_loss = 2.545
Epoch  39 Batch   59/69   train_loss = 2.637
Epoch  39 Batch   61/69   train_loss = 2.563
Epoch  39 Batch   63/69   train_loss = 2.623
Epoch  39 Batch   65/69   train_loss = 2.661
Epoch  39 Batch   67/69   train_loss = 2.504
Epoch  40 Batch    0/69   train_loss = 2.580
Epoch  40 Batch    2/69   train_loss = 2.626
Epoch  40 Batch    4/69   train_loss = 2.440
Epoch  40 Batch    6/69   train_loss = 2.465
Epoch  40 Batch    8/69   train_loss = 2.627
Epoch  40 Batch   10/69   train_loss = 2.638
Epoch  40 Batch   12/69   train_loss = 2.619
Epoch  40 Batch   14/69   train_loss = 2.589
Epoch  40 Batch   16/69   train_loss = 2.718
Epoch  40 Batch   18/69   train_loss = 2.548
Epoch  40 Batch   20/69   train_loss = 2.585
Epoch  40 Batch   22/69   train_loss = 2.530
Epoch  40 Batch   24/69   train_loss = 2.628
Epoch  40 Batch   26/69   train_loss = 2.500
Epoch  40 Batch   28/69   train_loss = 2.586
Epoch  40 Batch   30/69   train_loss = 2.570
Epoch  40 Batch   32/69   train_loss = 2.602
Epoch  40 Batch   34/69   train_loss = 2.576
Epoch  40 Batch   36/69   train_loss = 2.637
Epoch  40 Batch   38/69   train_loss = 2.557
Epoch  40 Batch   40/69   train_loss = 2.517
Epoch  40 Batch   42/69   train_loss = 2.560
Epoch  40 Batch   44/69   train_loss = 2.507
Epoch  40 Batch   46/69   train_loss = 2.613
Epoch  40 Batch   48/69   train_loss = 2.618
Epoch  40 Batch   50/69   train_loss = 2.457
Epoch  40 Batch   52/69   train_loss = 2.641
Epoch  40 Batch   54/69   train_loss = 2.429
Epoch  40 Batch   56/69   train_loss = 2.500
Epoch  40 Batch   58/69   train_loss = 2.574
Epoch  40 Batch   60/69   train_loss = 2.534
Epoch  40 Batch   62/69   train_loss = 2.422
Epoch  40 Batch   64/69   train_loss = 2.536
Epoch  40 Batch   66/69   train_loss = 2.539
Epoch  40 Batch   68/69   train_loss = 2.715
Epoch  41 Batch    1/69   train_loss = 2.515
Epoch  41 Batch    3/69   train_loss = 2.391
Epoch  41 Batch    5/69   train_loss = 2.584
Epoch  41 Batch    7/69   train_loss = 2.537
Epoch  41 Batch    9/69   train_loss = 2.568
Epoch  41 Batch   11/69   train_loss = 2.568
Epoch  41 Batch   13/69   train_loss = 2.542
Epoch  41 Batch   15/69   train_loss = 2.548
Epoch  41 Batch   17/69   train_loss = 2.528
Epoch  41 Batch   19/69   train_loss = 2.363
Epoch  41 Batch   21/69   train_loss = 2.483
Epoch  41 Batch   23/69   train_loss = 2.523
Epoch  41 Batch   25/69   train_loss = 2.510
Epoch  41 Batch   27/69   train_loss = 2.533
Epoch  41 Batch   29/69   train_loss = 2.525
Epoch  41 Batch   31/69   train_loss = 2.576
Epoch  41 Batch   33/69   train_loss = 2.562
Epoch  41 Batch   35/69   train_loss = 2.638
Epoch  41 Batch   37/69   train_loss = 2.472
Epoch  41 Batch   39/69   train_loss = 2.530
Epoch  41 Batch   41/69   train_loss = 2.506
Epoch  41 Batch   43/69   train_loss = 2.544
Epoch  41 Batch   45/69   train_loss = 2.517
Epoch  41 Batch   47/69   train_loss = 2.557
Epoch  41 Batch   49/69   train_loss = 2.443
Epoch  41 Batch   51/69   train_loss = 2.449
Epoch  41 Batch   53/69   train_loss = 2.480
Epoch  41 Batch   55/69   train_loss = 2.446
Epoch  41 Batch   57/69   train_loss = 2.460
Epoch  41 Batch   59/69   train_loss = 2.581
Epoch  41 Batch   61/69   train_loss = 2.492
Epoch  41 Batch   63/69   train_loss = 2.555
Epoch  41 Batch   65/69   train_loss = 2.575
Epoch  41 Batch   67/69   train_loss = 2.439
Epoch  42 Batch    0/69   train_loss = 2.524
Epoch  42 Batch    2/69   train_loss = 2.562
Epoch  42 Batch    4/69   train_loss = 2.368
Epoch  42 Batch    6/69   train_loss = 2.386
Epoch  42 Batch    8/69   train_loss = 2.558
Epoch  42 Batch   10/69   train_loss = 2.564
Epoch  42 Batch   12/69   train_loss = 2.548
Epoch  42 Batch   14/69   train_loss = 2.502
Epoch  42 Batch   16/69   train_loss = 2.637
Epoch  42 Batch   18/69   train_loss = 2.479
Epoch  42 Batch   20/69   train_loss = 2.503
Epoch  42 Batch   22/69   train_loss = 2.454
Epoch  42 Batch   24/69   train_loss = 2.561
Epoch  42 Batch   26/69   train_loss = 2.436
Epoch  42 Batch   28/69   train_loss = 2.513
Epoch  42 Batch   30/69   train_loss = 2.492
Epoch  42 Batch   32/69   train_loss = 2.519
Epoch  42 Batch   34/69   train_loss = 2.498
Epoch  42 Batch   36/69   train_loss = 2.557
Epoch  42 Batch   38/69   train_loss = 2.475
Epoch  42 Batch   40/69   train_loss = 2.438
Epoch  42 Batch   42/69   train_loss = 2.473
Epoch  42 Batch   44/69   train_loss = 2.423
Epoch  42 Batch   46/69   train_loss = 2.539
Epoch  42 Batch   48/69   train_loss = 2.530
Epoch  42 Batch   50/69   train_loss = 2.374
Epoch  42 Batch   52/69   train_loss = 2.570
Epoch  42 Batch   54/69   train_loss = 2.351
Epoch  42 Batch   56/69   train_loss = 2.413
Epoch  42 Batch   58/69   train_loss = 2.481
Epoch  42 Batch   60/69   train_loss = 2.452
Epoch  42 Batch   62/69   train_loss = 2.352
Epoch  42 Batch   64/69   train_loss = 2.476
Epoch  42 Batch   66/69   train_loss = 2.454
Epoch  42 Batch   68/69   train_loss = 2.651
Epoch  43 Batch    1/69   train_loss = 2.463
Epoch  43 Batch    3/69   train_loss = 2.319
Epoch  43 Batch    5/69   train_loss = 2.522
Epoch  43 Batch    7/69   train_loss = 2.458
Epoch  43 Batch    9/69   train_loss = 2.494
Epoch  43 Batch   11/69   train_loss = 2.492
Epoch  43 Batch   13/69   train_loss = 2.474
Epoch  43 Batch   15/69   train_loss = 2.474
Epoch  43 Batch   17/69   train_loss = 2.449
Epoch  43 Batch   19/69   train_loss = 2.289
Epoch  43 Batch   21/69   train_loss = 2.417
Epoch  43 Batch   23/69   train_loss = 2.460
Epoch  43 Batch   25/69   train_loss = 2.438
Epoch  43 Batch   27/69   train_loss = 2.464
Epoch  43 Batch   29/69   train_loss = 2.451
Epoch  43 Batch   31/69   train_loss = 2.507
Epoch  43 Batch   33/69   train_loss = 2.487
Epoch  43 Batch   35/69   train_loss = 2.557
Epoch  43 Batch   37/69   train_loss = 2.383
Epoch  43 Batch   39/69   train_loss = 2.443
Epoch  43 Batch   41/69   train_loss = 2.428
Epoch  43 Batch   43/69   train_loss = 2.461
Epoch  43 Batch   45/69   train_loss = 2.431
Epoch  43 Batch   47/69   train_loss = 2.469
Epoch  43 Batch   49/69   train_loss = 2.344
Epoch  43 Batch   51/69   train_loss = 2.363
Epoch  43 Batch   53/69   train_loss = 2.410
Epoch  43 Batch   55/69   train_loss = 2.379
Epoch  43 Batch   57/69   train_loss = 2.382
Epoch  43 Batch   59/69   train_loss = 2.496
Epoch  43 Batch   61/69   train_loss = 2.404
Epoch  43 Batch   63/69   train_loss = 2.491
Epoch  43 Batch   65/69   train_loss = 2.504
Epoch  43 Batch   67/69   train_loss = 2.363
Epoch  44 Batch    0/69   train_loss = 2.447
Epoch  44 Batch    2/69   train_loss = 2.493
Epoch  44 Batch    4/69   train_loss = 2.305
Epoch  44 Batch    6/69   train_loss = 2.320
Epoch  44 Batch    8/69   train_loss = 2.494
Epoch  44 Batch   10/69   train_loss = 2.490
Epoch  44 Batch   12/69   train_loss = 2.487
Epoch  44 Batch   14/69   train_loss = 2.428
Epoch  44 Batch   16/69   train_loss = 2.568
Epoch  44 Batch   18/69   train_loss = 2.414
Epoch  44 Batch   20/69   train_loss = 2.427
Epoch  44 Batch   22/69   train_loss = 2.402
Epoch  44 Batch   24/69   train_loss = 2.506
Epoch  44 Batch   26/69   train_loss = 2.373
Epoch  44 Batch   28/69   train_loss = 2.449
Epoch  44 Batch   30/69   train_loss = 2.427
Epoch  44 Batch   32/69   train_loss = 2.447
Epoch  44 Batch   34/69   train_loss = 2.432
Epoch  44 Batch   36/69   train_loss = 2.499
Epoch  44 Batch   38/69   train_loss = 2.415
Epoch  44 Batch   40/69   train_loss = 2.369
Epoch  44 Batch   42/69   train_loss = 2.391
Epoch  44 Batch   44/69   train_loss = 2.347
Epoch  44 Batch   46/69   train_loss = 2.459
Epoch  44 Batch   48/69   train_loss = 2.452
Epoch  44 Batch   50/69   train_loss = 2.280
Epoch  44 Batch   52/69   train_loss = 2.484
Epoch  44 Batch   54/69   train_loss = 2.258
Epoch  44 Batch   56/69   train_loss = 2.343
Epoch  44 Batch   58/69   train_loss = 2.403
Epoch  44 Batch   60/69   train_loss = 2.367
Epoch  44 Batch   62/69   train_loss = 2.257
Epoch  44 Batch   64/69   train_loss = 2.401
Epoch  44 Batch   66/69   train_loss = 2.410
Epoch  44 Batch   68/69   train_loss = 2.600
Epoch  45 Batch    1/69   train_loss = 2.391
Epoch  45 Batch    3/69   train_loss = 2.243
Epoch  45 Batch    5/69   train_loss = 2.471
Epoch  45 Batch    7/69   train_loss = 2.399
Epoch  45 Batch    9/69   train_loss = 2.417
Epoch  45 Batch   11/69   train_loss = 2.417
Epoch  45 Batch   13/69   train_loss = 2.399
Epoch  45 Batch   15/69   train_loss = 2.411
Epoch  45 Batch   17/69   train_loss = 2.388
Epoch  45 Batch   19/69   train_loss = 2.213
Epoch  45 Batch   21/69   train_loss = 2.339
Epoch  45 Batch   23/69   train_loss = 2.407
Epoch  45 Batch   25/69   train_loss = 2.397
Epoch  45 Batch   27/69   train_loss = 2.405
Epoch  45 Batch   29/69   train_loss = 2.389
Epoch  45 Batch   31/69   train_loss = 2.443
Epoch  45 Batch   33/69   train_loss = 2.425
Epoch  45 Batch   35/69   train_loss = 2.495
Epoch  45 Batch   37/69   train_loss = 2.319
Epoch  45 Batch   39/69   train_loss = 2.372
Epoch  45 Batch   41/69   train_loss = 2.362
Epoch  45 Batch   43/69   train_loss = 2.393
Epoch  45 Batch   45/69   train_loss = 2.369
Epoch  45 Batch   47/69   train_loss = 2.404
Epoch  45 Batch   49/69   train_loss = 2.268
Epoch  45 Batch   51/69   train_loss = 2.282
Epoch  45 Batch   53/69   train_loss = 2.326
Epoch  45 Batch   55/69   train_loss = 2.305
Epoch  45 Batch   57/69   train_loss = 2.299
Epoch  45 Batch   59/69   train_loss = 2.435
Epoch  45 Batch   61/69   train_loss = 2.328
Epoch  45 Batch   63/69   train_loss = 2.397
Epoch  45 Batch   65/69   train_loss = 2.416
Epoch  45 Batch   67/69   train_loss = 2.302
Epoch  46 Batch    0/69   train_loss = 2.406
Epoch  46 Batch    2/69   train_loss = 2.432
Epoch  46 Batch    4/69   train_loss = 2.233
Epoch  46 Batch    6/69   train_loss = 2.251
Epoch  46 Batch    8/69   train_loss = 2.464
Epoch  46 Batch   10/69   train_loss = 2.446
Epoch  46 Batch   12/69   train_loss = 2.425
Epoch  46 Batch   14/69   train_loss = 2.345
Epoch  46 Batch   16/69   train_loss = 2.487
Epoch  46 Batch   18/69   train_loss = 2.371
Epoch  46 Batch   20/69   train_loss = 2.372
Epoch  46 Batch   22/69   train_loss = 2.332
Epoch  46 Batch   24/69   train_loss = 2.442
Epoch  46 Batch   26/69   train_loss = 2.318
Epoch  46 Batch   28/69   train_loss = 2.392
Epoch  46 Batch   30/69   train_loss = 2.360
Epoch  46 Batch   32/69   train_loss = 2.375
Epoch  46 Batch   34/69   train_loss = 2.362
Epoch  46 Batch   36/69   train_loss = 2.443
Epoch  46 Batch   38/69   train_loss = 2.367
Epoch  46 Batch   40/69   train_loss = 2.307
Epoch  46 Batch   42/69   train_loss = 2.324
Epoch  46 Batch   44/69   train_loss = 2.271
Epoch  46 Batch   46/69   train_loss = 2.397
Epoch  46 Batch   48/69   train_loss = 2.389
Epoch  46 Batch   50/69   train_loss = 2.210
Epoch  46 Batch   52/69   train_loss = 2.412
Epoch  46 Batch   54/69   train_loss = 2.179
Epoch  46 Batch   56/69   train_loss = 2.275
Epoch  46 Batch   58/69   train_loss = 2.330
Epoch  46 Batch   60/69   train_loss = 2.290
Epoch  46 Batch   62/69   train_loss = 2.175
Epoch  46 Batch   64/69   train_loss = 2.315
Epoch  46 Batch   66/69   train_loss = 2.320
Epoch  46 Batch   68/69   train_loss = 2.528
Epoch  47 Batch    1/69   train_loss = 2.333
Epoch  47 Batch    3/69   train_loss = 2.164
Epoch  47 Batch    5/69   train_loss = 2.392
Epoch  47 Batch    7/69   train_loss = 2.320
Epoch  47 Batch    9/69   train_loss = 2.325
Epoch  47 Batch   11/69   train_loss = 2.359
Epoch  47 Batch   13/69   train_loss = 2.341
Epoch  47 Batch   15/69   train_loss = 2.349
Epoch  47 Batch   17/69   train_loss = 2.308
Epoch  47 Batch   19/69   train_loss = 2.138
Epoch  47 Batch   21/69   train_loss = 2.272
Epoch  47 Batch   23/69   train_loss = 2.342
Epoch  47 Batch   25/69   train_loss = 2.315
Epoch  47 Batch   27/69   train_loss = 2.333
Epoch  47 Batch   29/69   train_loss = 2.327
Epoch  47 Batch   31/69   train_loss = 2.392
Epoch  47 Batch   33/69   train_loss = 2.356
Epoch  47 Batch   35/69   train_loss = 2.419
Epoch  47 Batch   37/69   train_loss = 2.230
Epoch  47 Batch   39/69   train_loss = 2.305
Epoch  47 Batch   41/69   train_loss = 2.314
Epoch  47 Batch   43/69   train_loss = 2.344
Epoch  47 Batch   45/69   train_loss = 2.286
Epoch  47 Batch   47/69   train_loss = 2.320
Epoch  47 Batch   49/69   train_loss = 2.214
Epoch  47 Batch   51/69   train_loss = 2.241
Epoch  47 Batch   53/69   train_loss = 2.286
Epoch  47 Batch   55/69   train_loss = 2.258
Epoch  47 Batch   57/69   train_loss = 2.229
Epoch  47 Batch   59/69   train_loss = 2.387
Epoch  47 Batch   61/69   train_loss = 2.276
Epoch  47 Batch   63/69   train_loss = 2.356
Epoch  47 Batch   65/69   train_loss = 2.345
Epoch  47 Batch   67/69   train_loss = 2.222
Epoch  48 Batch    0/69   train_loss = 2.324
Epoch  48 Batch    2/69   train_loss = 2.351
Epoch  48 Batch    4/69   train_loss = 2.158
Epoch  48 Batch    6/69   train_loss = 2.174
Epoch  48 Batch    8/69   train_loss = 2.357
Epoch  48 Batch   10/69   train_loss = 2.347
Epoch  48 Batch   12/69   train_loss = 2.342
Epoch  48 Batch   14/69   train_loss = 2.259
Epoch  48 Batch   16/69   train_loss = 2.400
Epoch  48 Batch   18/69   train_loss = 2.270
Epoch  48 Batch   20/69   train_loss = 2.289
Epoch  48 Batch   22/69   train_loss = 2.249
Epoch  48 Batch   24/69   train_loss = 2.376
Epoch  48 Batch   26/69   train_loss = 2.252
Epoch  48 Batch   28/69   train_loss = 2.316
Epoch  48 Batch   30/69   train_loss = 2.276
Epoch  48 Batch   32/69   train_loss = 2.298
Epoch  48 Batch   34/69   train_loss = 2.286
Epoch  48 Batch   36/69   train_loss = 2.363
Epoch  48 Batch   38/69   train_loss = 2.271
Epoch  48 Batch   40/69   train_loss = 2.229
Epoch  48 Batch   42/69   train_loss = 2.242
Epoch  48 Batch   44/69   train_loss = 2.207
Epoch  48 Batch   46/69   train_loss = 2.335
Epoch  48 Batch   48/69   train_loss = 2.300
Epoch  48 Batch   50/69   train_loss = 2.117
Epoch  48 Batch   52/69   train_loss = 2.356
Epoch  48 Batch   54/69   train_loss = 2.134
Epoch  48 Batch   56/69   train_loss = 2.214
Epoch  48 Batch   58/69   train_loss = 2.257
Epoch  48 Batch   60/69   train_loss = 2.224
Epoch  48 Batch   62/69   train_loss = 2.108
Epoch  48 Batch   64/69   train_loss = 2.284
Epoch  48 Batch   66/69   train_loss = 2.286
Epoch  48 Batch   68/69   train_loss = 2.486
Epoch  49 Batch    1/69   train_loss = 2.279
Epoch  49 Batch    3/69   train_loss = 2.082
Epoch  49 Batch    5/69   train_loss = 2.340
Epoch  49 Batch    7/69   train_loss = 2.254
Epoch  49 Batch    9/69   train_loss = 2.246
Epoch  49 Batch   11/69   train_loss = 2.264
Epoch  49 Batch   13/69   train_loss = 2.256
Epoch  49 Batch   15/69   train_loss = 2.279
Epoch  49 Batch   17/69   train_loss = 2.230
Epoch  49 Batch   19/69   train_loss = 2.054
Epoch  49 Batch   21/69   train_loss = 2.173
Epoch  49 Batch   23/69   train_loss = 2.258
Epoch  49 Batch   25/69   train_loss = 2.239
Epoch  49 Batch   27/69   train_loss = 2.267
Epoch  49 Batch   29/69   train_loss = 2.257
Epoch  49 Batch   31/69   train_loss = 2.311
Epoch  49 Batch   33/69   train_loss = 2.272
Epoch  49 Batch   35/69   train_loss = 2.334
Epoch  49 Batch   37/69   train_loss = 2.145
Epoch  49 Batch   39/69   train_loss = 2.217
Epoch  49 Batch   41/69   train_loss = 2.228
Epoch  49 Batch   43/69   train_loss = 2.240
Epoch  49 Batch   45/69   train_loss = 2.209
Epoch  49 Batch   47/69   train_loss = 2.232
Epoch  49 Batch   49/69   train_loss = 2.122
Epoch  49 Batch   51/69   train_loss = 2.125
Epoch  49 Batch   53/69   train_loss = 2.190
Epoch  49 Batch   55/69   train_loss = 2.192
Epoch  49 Batch   57/69   train_loss = 2.172
Epoch  49 Batch   59/69   train_loss = 2.320
Epoch  49 Batch   61/69   train_loss = 2.193
Epoch  49 Batch   63/69   train_loss = 2.270
Epoch  49 Batch   65/69   train_loss = 2.287
Epoch  49 Batch   67/69   train_loss = 2.199
Epoch  50 Batch    0/69   train_loss = 2.281
Epoch  50 Batch    2/69   train_loss = 2.295
Epoch  50 Batch    4/69   train_loss = 2.098
Epoch  50 Batch    6/69   train_loss = 2.108
Epoch  50 Batch    8/69   train_loss = 2.321
Epoch  50 Batch   10/69   train_loss = 2.292
Epoch  50 Batch   12/69   train_loss = 2.283
Epoch  50 Batch   14/69   train_loss = 2.191
Epoch  50 Batch   16/69   train_loss = 2.329
Epoch  50 Batch   18/69   train_loss = 2.214
Epoch  50 Batch   20/69   train_loss = 2.219
Epoch  50 Batch   22/69   train_loss = 2.179
Epoch  50 Batch   24/69   train_loss = 2.312
Epoch  50 Batch   26/69   train_loss = 2.181
Epoch  50 Batch   28/69   train_loss = 2.246
Epoch  50 Batch   30/69   train_loss = 2.216
Epoch  50 Batch   32/69   train_loss = 2.226
Epoch  50 Batch   34/69   train_loss = 2.209
Epoch  50 Batch   36/69   train_loss = 2.296
Epoch  50 Batch   38/69   train_loss = 2.203
Epoch  50 Batch   40/69   train_loss = 2.160
Epoch  50 Batch   42/69   train_loss = 2.149
Epoch  50 Batch   44/69   train_loss = 2.120
Epoch  50 Batch   46/69   train_loss = 2.253
Epoch  50 Batch   48/69   train_loss = 2.223
Epoch  50 Batch   50/69   train_loss = 2.030
Epoch  50 Batch   52/69   train_loss = 2.253
Epoch  50 Batch   54/69   train_loss = 2.010
Epoch  50 Batch   56/69   train_loss = 2.113
Epoch  50 Batch   58/69   train_loss = 2.175
Epoch  50 Batch   60/69   train_loss = 2.169
Epoch  50 Batch   62/69   train_loss = 2.030
Epoch  50 Batch   64/69   train_loss = 2.177
Epoch  50 Batch   66/69   train_loss = 2.196
Epoch  50 Batch   68/69   train_loss = 2.452
Epoch  51 Batch    1/69   train_loss = 2.254
Epoch  51 Batch    3/69   train_loss = 2.029
Epoch  51 Batch    5/69   train_loss = 2.277
Epoch  51 Batch    7/69   train_loss = 2.194
Epoch  51 Batch    9/69   train_loss = 2.181
Epoch  51 Batch   11/69   train_loss = 2.219
Epoch  51 Batch   13/69   train_loss = 2.200
Epoch  51 Batch   15/69   train_loss = 2.228
Epoch  51 Batch   17/69   train_loss = 2.170
Epoch  51 Batch   19/69   train_loss = 1.999
Epoch  51 Batch   21/69   train_loss = 2.101
Epoch  51 Batch   23/69   train_loss = 2.197
Epoch  51 Batch   25/69   train_loss = 2.169
Epoch  51 Batch   27/69   train_loss = 2.205
Epoch  51 Batch   29/69   train_loss = 2.193
Epoch  51 Batch   31/69   train_loss = 2.247
Epoch  51 Batch   33/69   train_loss = 2.218
Epoch  51 Batch   35/69   train_loss = 2.259
Epoch  51 Batch   37/69   train_loss = 2.067
Epoch  51 Batch   39/69   train_loss = 2.137
Epoch  51 Batch   41/69   train_loss = 2.163
Epoch  51 Batch   43/69   train_loss = 2.167
Epoch  51 Batch   45/69   train_loss = 2.134
Epoch  51 Batch   47/69   train_loss = 2.158
Epoch  51 Batch   49/69   train_loss = 2.040
Epoch  51 Batch   51/69   train_loss = 2.050
Epoch  51 Batch   53/69   train_loss = 2.114
Epoch  51 Batch   55/69   train_loss = 2.098
Epoch  51 Batch   57/69   train_loss = 2.075
Epoch  51 Batch   59/69   train_loss = 2.237
Epoch  51 Batch   61/69   train_loss = 2.113
Epoch  51 Batch   63/69   train_loss = 2.194
Epoch  51 Batch   65/69   train_loss = 2.191
Epoch  51 Batch   67/69   train_loss = 2.096
Epoch  52 Batch    0/69   train_loss = 2.198
Epoch  52 Batch    2/69   train_loss = 2.244
Epoch  52 Batch    4/69   train_loss = 2.047
Epoch  52 Batch    6/69   train_loss = 2.054
Epoch  52 Batch    8/69   train_loss = 2.244
Epoch  52 Batch   10/69   train_loss = 2.216
Epoch  52 Batch   12/69   train_loss = 2.226
Epoch  52 Batch   14/69   train_loss = 2.135
Epoch  52 Batch   16/69   train_loss = 2.271
Epoch  52 Batch   18/69   train_loss = 2.143
Epoch  52 Batch   20/69   train_loss = 2.150
Epoch  52 Batch   22/69   train_loss = 2.113
Epoch  52 Batch   24/69   train_loss = 2.264
Epoch  52 Batch   26/69   train_loss = 2.127
Epoch  52 Batch   28/69   train_loss = 2.188
Epoch  52 Batch   30/69   train_loss = 2.155
Epoch  52 Batch   32/69   train_loss = 2.162
Epoch  52 Batch   34/69   train_loss = 2.137
Epoch  52 Batch   36/69   train_loss = 2.236
Epoch  52 Batch   38/69   train_loss = 2.139
Epoch  52 Batch   40/69   train_loss = 2.096
Epoch  52 Batch   42/69   train_loss = 2.079
Epoch  52 Batch   44/69   train_loss = 2.053
Epoch  52 Batch   46/69   train_loss = 2.198
Epoch  52 Batch   48/69   train_loss = 2.161
Epoch  52 Batch   50/69   train_loss = 1.953
Epoch  52 Batch   52/69   train_loss = 2.184
Epoch  52 Batch   54/69   train_loss = 1.938
Epoch  52 Batch   56/69   train_loss = 2.043
Epoch  52 Batch   58/69   train_loss = 2.095
Epoch  52 Batch   60/69   train_loss = 2.091
Epoch  52 Batch   62/69   train_loss = 1.955
Epoch  52 Batch   64/69   train_loss = 2.102
Epoch  52 Batch   66/69   train_loss = 2.123
Epoch  52 Batch   68/69   train_loss = 2.363
Epoch  53 Batch    1/69   train_loss = 2.161
Epoch  53 Batch    3/69   train_loss = 1.948
Epoch  53 Batch    5/69   train_loss = 2.220
Epoch  53 Batch    7/69   train_loss = 2.133
Epoch  53 Batch    9/69   train_loss = 2.108
Epoch  53 Batch   11/69   train_loss = 2.126
Epoch  53 Batch   13/69   train_loss = 2.132
Epoch  53 Batch   15/69   train_loss = 2.165
Epoch  53 Batch   17/69   train_loss = 2.115
Epoch  53 Batch   19/69   train_loss = 1.940
Epoch  53 Batch   21/69   train_loss = 2.030
Epoch  53 Batch   23/69   train_loss = 2.122
Epoch  53 Batch   25/69   train_loss = 2.108
Epoch  53 Batch   27/69   train_loss = 2.155
Epoch  53 Batch   29/69   train_loss = 2.133
Epoch  53 Batch   31/69   train_loss = 2.187
Epoch  53 Batch   33/69   train_loss = 2.155
Epoch  53 Batch   35/69   train_loss = 2.184
Epoch  53 Batch   37/69   train_loss = 1.998
Epoch  53 Batch   39/69   train_loss = 2.081
Epoch  53 Batch   41/69   train_loss = 2.108
Epoch  53 Batch   43/69   train_loss = 2.098
Epoch  53 Batch   45/69   train_loss = 2.073
Epoch  53 Batch   47/69   train_loss = 2.093
Epoch  53 Batch   49/69   train_loss = 1.970
Epoch  53 Batch   51/69   train_loss = 1.977
Epoch  53 Batch   53/69   train_loss = 2.045
Epoch  53 Batch   55/69   train_loss = 2.035
Epoch  53 Batch   57/69   train_loss = 2.002
Epoch  53 Batch   59/69   train_loss = 2.179
Epoch  53 Batch   61/69   train_loss = 2.048
Epoch  53 Batch   63/69   train_loss = 2.137
Epoch  53 Batch   65/69   train_loss = 2.132
Epoch  53 Batch   67/69   train_loss = 2.034
Epoch  54 Batch    0/69   train_loss = 2.136
Epoch  54 Batch    2/69   train_loss = 2.173
Epoch  54 Batch    4/69   train_loss = 1.984
Epoch  54 Batch    6/69   train_loss = 1.997
Epoch  54 Batch    8/69   train_loss = 2.186
Epoch  54 Batch   10/69   train_loss = 2.146
Epoch  54 Batch   12/69   train_loss = 2.150
Epoch  54 Batch   14/69   train_loss = 2.052
Epoch  54 Batch   16/69   train_loss = 2.198
Epoch  54 Batch   18/69   train_loss = 2.080
Epoch  54 Batch   20/69   train_loss = 2.089
Epoch  54 Batch   22/69   train_loss = 2.054
Epoch  54 Batch   24/69   train_loss = 2.199
Epoch  54 Batch   26/69   train_loss = 2.054
Epoch  54 Batch   28/69   train_loss = 2.124
Epoch  54 Batch   30/69   train_loss = 2.096
Epoch  54 Batch   32/69   train_loss = 2.102
Epoch  54 Batch   34/69   train_loss = 2.081
Epoch  54 Batch   36/69   train_loss = 2.169
Epoch  54 Batch   38/69   train_loss = 2.072
Epoch  54 Batch   40/69   train_loss = 2.035
Epoch  54 Batch   42/69   train_loss = 2.010
Epoch  54 Batch   44/69   train_loss = 1.990
Epoch  54 Batch   46/69   train_loss = 2.141
Epoch  54 Batch   48/69   train_loss = 2.098
Epoch  54 Batch   50/69   train_loss = 1.880
Epoch  54 Batch   52/69   train_loss = 2.114
Epoch  54 Batch   54/69   train_loss = 1.869
Epoch  54 Batch   56/69   train_loss = 1.972
Epoch  54 Batch   58/69   train_loss = 2.024
Epoch  54 Batch   60/69   train_loss = 2.033
Epoch  54 Batch   62/69   train_loss = 1.904
Epoch  54 Batch   64/69   train_loss = 2.046
Epoch  54 Batch   66/69   train_loss = 2.061
Epoch  54 Batch   68/69   train_loss = 2.306
Epoch  55 Batch    1/69   train_loss = 2.100
Epoch  55 Batch    3/69   train_loss = 1.885
Epoch  55 Batch    5/69   train_loss = 2.168
Epoch  55 Batch    7/69   train_loss = 2.084
Epoch  55 Batch    9/69   train_loss = 2.058
Epoch  55 Batch   11/69   train_loss = 2.059
Epoch  55 Batch   13/69   train_loss = 2.071
Epoch  55 Batch   15/69   train_loss = 2.107
Epoch  55 Batch   17/69   train_loss = 2.041
Epoch  55 Batch   19/69   train_loss = 1.880
Epoch  55 Batch   21/69   train_loss = 1.966
Epoch  55 Batch   23/69   train_loss = 2.060
Epoch  55 Batch   25/69   train_loss = 2.051
Epoch  55 Batch   27/69   train_loss = 2.080
Epoch  55 Batch   29/69   train_loss = 2.064
Epoch  55 Batch   31/69   train_loss = 2.129
Epoch  55 Batch   33/69   train_loss = 2.091
Epoch  55 Batch   35/69   train_loss = 2.124
Epoch  55 Batch   37/69   train_loss = 1.927
Epoch  55 Batch   39/69   train_loss = 2.012
Epoch  55 Batch   41/69   train_loss = 2.044
Epoch  55 Batch   43/69   train_loss = 2.031
Epoch  55 Batch   45/69   train_loss = 2.013
Epoch  55 Batch   47/69   train_loss = 2.039
Epoch  55 Batch   49/69   train_loss = 1.907
Epoch  55 Batch   51/69   train_loss = 1.905
Epoch  55 Batch   53/69   train_loss = 1.980
Epoch  55 Batch   55/69   train_loss = 1.970
Epoch  55 Batch   57/69   train_loss = 1.920
Epoch  55 Batch   59/69   train_loss = 2.115
Epoch  55 Batch   61/69   train_loss = 1.978
Epoch  55 Batch   63/69   train_loss = 2.078
Epoch  55 Batch   65/69   train_loss = 2.079
Epoch  55 Batch   67/69   train_loss = 1.974
Epoch  56 Batch    0/69   train_loss = 2.069
Epoch  56 Batch    2/69   train_loss = 2.095
Epoch  56 Batch    4/69   train_loss = 1.927
Epoch  56 Batch    6/69   train_loss = 1.959
Epoch  56 Batch    8/69   train_loss = 2.147
Epoch  56 Batch   10/69   train_loss = 2.095
Epoch  56 Batch   12/69   train_loss = 2.088
Epoch  56 Batch   14/69   train_loss = 1.993
Epoch  56 Batch   16/69   train_loss = 2.134
Epoch  56 Batch   18/69   train_loss = 2.032
Epoch  56 Batch   20/69   train_loss = 2.037
Epoch  56 Batch   22/69   train_loss = 2.006
Epoch  56 Batch   24/69   train_loss = 2.152
Epoch  56 Batch   26/69   train_loss = 1.990
Epoch  56 Batch   28/69   train_loss = 2.059
Epoch  56 Batch   30/69   train_loss = 2.041
Epoch  56 Batch   32/69   train_loss = 2.032
Epoch  56 Batch   34/69   train_loss = 2.017
Epoch  56 Batch   36/69   train_loss = 2.114
Epoch  56 Batch   38/69   train_loss = 2.020
Epoch  56 Batch   40/69   train_loss = 1.975
Epoch  56 Batch   42/69   train_loss = 1.936
Epoch  56 Batch   44/69   train_loss = 1.923
Epoch  56 Batch   46/69   train_loss = 2.084
Epoch  56 Batch   48/69   train_loss = 2.036
Epoch  56 Batch   50/69   train_loss = 1.813
Epoch  56 Batch   52/69   train_loss = 2.043
Epoch  56 Batch   54/69   train_loss = 1.800
Epoch  56 Batch   56/69   train_loss = 1.914
Epoch  56 Batch   58/69   train_loss = 1.951
Epoch  56 Batch   60/69   train_loss = 1.954
Epoch  56 Batch   62/69   train_loss = 1.829
Epoch  56 Batch   64/69   train_loss = 1.982
Epoch  56 Batch   66/69   train_loss = 2.008
Epoch  56 Batch   68/69   train_loss = 2.239
Epoch  57 Batch    1/69   train_loss = 2.030
Epoch  57 Batch    3/69   train_loss = 1.810
Epoch  57 Batch    5/69   train_loss = 2.082
Epoch  57 Batch    7/69   train_loss = 2.034
Epoch  57 Batch    9/69   train_loss = 2.013
Epoch  57 Batch   11/69   train_loss = 2.017
Epoch  57 Batch   13/69   train_loss = 2.014
Epoch  57 Batch   15/69   train_loss = 2.037
Epoch  57 Batch   17/69   train_loss = 1.981
Epoch  57 Batch   19/69   train_loss = 1.829
Epoch  57 Batch   21/69   train_loss = 1.933
Epoch  57 Batch   23/69   train_loss = 2.022
Epoch  57 Batch   25/69   train_loss = 2.005
Epoch  57 Batch   27/69   train_loss = 2.021
Epoch  57 Batch   29/69   train_loss = 2.005
Epoch  57 Batch   31/69   train_loss = 2.075
Epoch  57 Batch   33/69   train_loss = 2.036
Epoch  57 Batch   35/69   train_loss = 2.068
Epoch  57 Batch   37/69   train_loss = 1.874
Epoch  57 Batch   39/69   train_loss = 1.962
Epoch  57 Batch   41/69   train_loss = 1.991
Epoch  57 Batch   43/69   train_loss = 1.970
Epoch  57 Batch   45/69   train_loss = 1.955
Epoch  57 Batch   47/69   train_loss = 1.979
Epoch  57 Batch   49/69   train_loss = 1.848
Epoch  57 Batch   51/69   train_loss = 1.848
Epoch  57 Batch   53/69   train_loss = 1.921
Epoch  57 Batch   55/69   train_loss = 1.909
Epoch  57 Batch   57/69   train_loss = 1.851
Epoch  57 Batch   59/69   train_loss = 2.056
Epoch  57 Batch   61/69   train_loss = 1.914
Epoch  57 Batch   63/69   train_loss = 2.002
Epoch  57 Batch   65/69   train_loss = 2.002
Epoch  57 Batch   67/69   train_loss = 1.898
Epoch  58 Batch    0/69   train_loss = 2.002
Epoch  58 Batch    2/69   train_loss = 2.022
Epoch  58 Batch    4/69   train_loss = 1.851
Epoch  58 Batch    6/69   train_loss = 1.875
Epoch  58 Batch    8/69   train_loss = 2.067
Epoch  58 Batch   10/69   train_loss = 2.021
Epoch  58 Batch   12/69   train_loss = 2.019
Epoch  58 Batch   14/69   train_loss = 1.916
Epoch  58 Batch   16/69   train_loss = 2.042
Epoch  58 Batch   18/69   train_loss = 1.958
Epoch  58 Batch   20/69   train_loss = 1.961
Epoch  58 Batch   22/69   train_loss = 1.954
Epoch  58 Batch   24/69   train_loss = 2.104
Epoch  58 Batch   26/69   train_loss = 1.929
Epoch  58 Batch   28/69   train_loss = 2.001
Epoch  58 Batch   30/69   train_loss = 1.976
Epoch  58 Batch   32/69   train_loss = 1.965
Epoch  58 Batch   34/69   train_loss = 1.950
Epoch  58 Batch   36/69   train_loss = 2.058
Epoch  58 Batch   38/69   train_loss = 1.961
Epoch  58 Batch   40/69   train_loss = 1.916
Epoch  58 Batch   42/69   train_loss = 1.866
Epoch  58 Batch   44/69   train_loss = 1.856
Epoch  58 Batch   46/69   train_loss = 2.024
Epoch  58 Batch   48/69   train_loss = 1.979
Epoch  58 Batch   50/69   train_loss = 1.748
Epoch  58 Batch   52/69   train_loss = 1.971
Epoch  58 Batch   54/69   train_loss = 1.737
Epoch  58 Batch   56/69   train_loss = 1.844
Epoch  58 Batch   58/69   train_loss = 1.883
Epoch  58 Batch   60/69   train_loss = 1.899
Epoch  58 Batch   62/69   train_loss = 1.765
Epoch  58 Batch   64/69   train_loss = 1.923
Epoch  58 Batch   66/69   train_loss = 1.948
Epoch  58 Batch   68/69   train_loss = 2.172
Epoch  59 Batch    1/69   train_loss = 1.962
Epoch  59 Batch    3/69   train_loss = 1.743
Epoch  59 Batch    5/69   train_loss = 2.015
Epoch  59 Batch    7/69   train_loss = 1.963
Epoch  59 Batch    9/69   train_loss = 1.931
Epoch  59 Batch   11/69   train_loss = 1.945
Epoch  59 Batch   13/69   train_loss = 1.943
Epoch  59 Batch   15/69   train_loss = 1.958
Epoch  59 Batch   17/69   train_loss = 1.904
Epoch  59 Batch   19/69   train_loss = 1.756
Epoch  59 Batch   21/69   train_loss = 1.861
Epoch  59 Batch   23/69   train_loss = 1.958
Epoch  59 Batch   25/69   train_loss = 1.940
Epoch  59 Batch   27/69   train_loss = 1.961
Epoch  59 Batch   29/69   train_loss = 1.935
Epoch  59 Batch   31/69   train_loss = 1.999
Epoch  59 Batch   33/69   train_loss = 1.961
Epoch  59 Batch   35/69   train_loss = 1.997
Epoch  59 Batch   37/69   train_loss = 1.800
Epoch  59 Batch   39/69   train_loss = 1.890
Epoch  59 Batch   41/69   train_loss = 1.929
Epoch  59 Batch   43/69   train_loss = 1.905
Epoch  59 Batch   45/69   train_loss = 1.879
Epoch  59 Batch   47/69   train_loss = 1.915
Epoch  59 Batch   49/69   train_loss = 1.782
Epoch  59 Batch   51/69   train_loss = 1.785
Epoch  59 Batch   53/69   train_loss = 1.869
Epoch  59 Batch   55/69   train_loss = 1.845
Epoch  59 Batch   57/69   train_loss = 1.785
Epoch  59 Batch   59/69   train_loss = 1.992
Epoch  59 Batch   61/69   train_loss = 1.847
Epoch  59 Batch   63/69   train_loss = 1.940
Epoch  59 Batch   65/69   train_loss = 1.936
Epoch  59 Batch   67/69   train_loss = 1.843
Epoch  60 Batch    0/69   train_loss = 1.950
Epoch  60 Batch    2/69   train_loss = 1.952
Epoch  60 Batch    4/69   train_loss = 1.790
Epoch  60 Batch    6/69   train_loss = 1.814
Epoch  60 Batch    8/69   train_loss = 1.998
Epoch  60 Batch   10/69   train_loss = 1.954
Epoch  60 Batch   12/69   train_loss = 1.964
Epoch  60 Batch   14/69   train_loss = 1.853
Epoch  60 Batch   16/69   train_loss = 1.971
Epoch  60 Batch   18/69   train_loss = 1.884
Epoch  60 Batch   20/69   train_loss = 1.878
Epoch  60 Batch   22/69   train_loss = 1.889
Epoch  60 Batch   24/69   train_loss = 2.045
Epoch  60 Batch   26/69   train_loss = 1.879
Epoch  60 Batch   28/69   train_loss = 1.947
Epoch  60 Batch   30/69   train_loss = 1.902
Epoch  60 Batch   32/69   train_loss = 1.897
Epoch  60 Batch   34/69   train_loss = 1.881
Epoch  60 Batch   36/69   train_loss = 1.993
Epoch  60 Batch   38/69   train_loss = 1.897
Epoch  60 Batch   40/69   train_loss = 1.860
Epoch  60 Batch   42/69   train_loss = 1.809
Epoch  60 Batch   44/69   train_loss = 1.788
Epoch  60 Batch   46/69   train_loss = 1.955
Epoch  60 Batch   48/69   train_loss = 1.911
Epoch  60 Batch   50/69   train_loss = 1.682
Epoch  60 Batch   52/69   train_loss = 1.905
Epoch  60 Batch   54/69   train_loss = 1.682
Epoch  60 Batch   56/69   train_loss = 1.783
Epoch  60 Batch   58/69   train_loss = 1.816
Epoch  60 Batch   60/69   train_loss = 1.828
Epoch  60 Batch   62/69   train_loss = 1.701
Epoch  60 Batch   64/69   train_loss = 1.860
Epoch  60 Batch   66/69   train_loss = 1.891
Epoch  60 Batch   68/69   train_loss = 2.117
Epoch  61 Batch    1/69   train_loss = 1.903
Epoch  61 Batch    3/69   train_loss = 1.674
Epoch  61 Batch    5/69   train_loss = 1.953
Epoch  61 Batch    7/69   train_loss = 1.886
Epoch  61 Batch    9/69   train_loss = 1.853
Epoch  61 Batch   11/69   train_loss = 1.861
Epoch  61 Batch   13/69   train_loss = 1.878
Epoch  61 Batch   15/69   train_loss = 1.898
Epoch  61 Batch   17/69   train_loss = 1.838
Epoch  61 Batch   19/69   train_loss = 1.683
Epoch  61 Batch   21/69   train_loss = 1.788
Epoch  61 Batch   23/69   train_loss = 1.888
Epoch  61 Batch   25/69   train_loss = 1.885
Epoch  61 Batch   27/69   train_loss = 1.906
Epoch  61 Batch   29/69   train_loss = 1.880
Epoch  61 Batch   31/69   train_loss = 1.940
Epoch  61 Batch   33/69   train_loss = 1.890
Epoch  61 Batch   35/69   train_loss = 1.923
Epoch  61 Batch   37/69   train_loss = 1.733
Epoch  61 Batch   39/69   train_loss = 1.835
Epoch  61 Batch   41/69   train_loss = 1.882
Epoch  61 Batch   43/69   train_loss = 1.842
Epoch  61 Batch   45/69   train_loss = 1.811
Epoch  61 Batch   47/69   train_loss = 1.850
Epoch  61 Batch   49/69   train_loss = 1.715
Epoch  61 Batch   51/69   train_loss = 1.723
Epoch  61 Batch   53/69   train_loss = 1.813
Epoch  61 Batch   55/69   train_loss = 1.795
Epoch  61 Batch   57/69   train_loss = 1.726
Epoch  61 Batch   59/69   train_loss = 1.937
Epoch  61 Batch   61/69   train_loss = 1.783
Epoch  61 Batch   63/69   train_loss = 1.876
Epoch  61 Batch   65/69   train_loss = 1.865
Epoch  61 Batch   67/69   train_loss = 1.786
Epoch  62 Batch    0/69   train_loss = 1.886
Epoch  62 Batch    2/69   train_loss = 1.889
Epoch  62 Batch    4/69   train_loss = 1.731
Epoch  62 Batch    6/69   train_loss = 1.755
Epoch  62 Batch    8/69   train_loss = 1.934
Epoch  62 Batch   10/69   train_loss = 1.882
Epoch  62 Batch   12/69   train_loss = 1.892
Epoch  62 Batch   14/69   train_loss = 1.778
Epoch  62 Batch   16/69   train_loss = 1.895
Epoch  62 Batch   18/69   train_loss = 1.818
Epoch  62 Batch   20/69   train_loss = 1.809
Epoch  62 Batch   22/69   train_loss = 1.820
Epoch  62 Batch   24/69   train_loss = 1.981
Epoch  62 Batch   26/69   train_loss = 1.821
Epoch  62 Batch   28/69   train_loss = 1.887
Epoch  62 Batch   30/69   train_loss = 1.840
Epoch  62 Batch   32/69   train_loss = 1.831
Epoch  62 Batch   34/69   train_loss = 1.807
Epoch  62 Batch   36/69   train_loss = 1.915
Epoch  62 Batch   38/69   train_loss = 1.834
Epoch  62 Batch   40/69   train_loss = 1.785
Epoch  62 Batch   42/69   train_loss = 1.756
Epoch  62 Batch   44/69   train_loss = 1.736
Epoch  62 Batch   46/69   train_loss = 1.901
Epoch  62 Batch   48/69   train_loss = 1.843
Epoch  62 Batch   50/69   train_loss = 1.613
Epoch  62 Batch   52/69   train_loss = 1.838
Epoch  62 Batch   54/69   train_loss = 1.613
Epoch  62 Batch   56/69   train_loss = 1.730
Epoch  62 Batch   58/69   train_loss = 1.770
Epoch  62 Batch   60/69   train_loss = 1.774
Epoch  62 Batch   62/69   train_loss = 1.651
Epoch  62 Batch   64/69   train_loss = 1.791
Epoch  62 Batch   66/69   train_loss = 1.827
Epoch  62 Batch   68/69   train_loss = 2.068
Epoch  63 Batch    1/69   train_loss = 1.855
Epoch  63 Batch    3/69   train_loss = 1.611
Epoch  63 Batch    5/69   train_loss = 1.899
Epoch  63 Batch    7/69   train_loss = 1.823
Epoch  63 Batch    9/69   train_loss = 1.779
Epoch  63 Batch   11/69   train_loss = 1.784
Epoch  63 Batch   13/69   train_loss = 1.808
Epoch  63 Batch   15/69   train_loss = 1.829
Epoch  63 Batch   17/69   train_loss = 1.772
Epoch  63 Batch   19/69   train_loss = 1.614
Epoch  63 Batch   21/69   train_loss = 1.719
Epoch  63 Batch   23/69   train_loss = 1.818
Epoch  63 Batch   25/69   train_loss = 1.814
Epoch  63 Batch   27/69   train_loss = 1.836
Epoch  63 Batch   29/69   train_loss = 1.817
Epoch  63 Batch   31/69   train_loss = 1.879
Epoch  63 Batch   33/69   train_loss = 1.827
Epoch  63 Batch   35/69   train_loss = 1.858
Epoch  63 Batch   37/69   train_loss = 1.657
Epoch  63 Batch   39/69   train_loss = 1.763
Epoch  63 Batch   41/69   train_loss = 1.819
Epoch  63 Batch   43/69   train_loss = 1.777
Epoch  63 Batch   45/69   train_loss = 1.754
Epoch  63 Batch   47/69   train_loss = 1.802
Epoch  63 Batch   49/69   train_loss = 1.666
Epoch  63 Batch   51/69   train_loss = 1.663
Epoch  63 Batch   53/69   train_loss = 1.748
Epoch  63 Batch   55/69   train_loss = 1.730
Epoch  63 Batch   57/69   train_loss = 1.661
Epoch  63 Batch   59/69   train_loss = 1.888
Epoch  63 Batch   61/69   train_loss = 1.743
Epoch  63 Batch   63/69   train_loss = 1.837
Epoch  63 Batch   65/69   train_loss = 1.815
Epoch  63 Batch   67/69   train_loss = 1.740
Epoch  64 Batch    0/69   train_loss = 1.833
Epoch  64 Batch    2/69   train_loss = 1.838
Epoch  64 Batch    4/69   train_loss = 1.686
Epoch  64 Batch    6/69   train_loss = 1.718
Epoch  64 Batch    8/69   train_loss = 1.883
Epoch  64 Batch   10/69   train_loss = 1.828
Epoch  64 Batch   12/69   train_loss = 1.833
Epoch  64 Batch   14/69   train_loss = 1.709
Epoch  64 Batch   16/69   train_loss = 1.822
Epoch  64 Batch   18/69   train_loss = 1.753
Epoch  64 Batch   20/69   train_loss = 1.737
Epoch  64 Batch   22/69   train_loss = 1.751
Epoch  64 Batch   24/69   train_loss = 1.913
Epoch  64 Batch   26/69   train_loss = 1.750
Epoch  64 Batch   28/69   train_loss = 1.826
Epoch  64 Batch   30/69   train_loss = 1.768
Epoch  64 Batch   32/69   train_loss = 1.760
Epoch  64 Batch   34/69   train_loss = 1.737
Epoch  64 Batch   36/69   train_loss = 1.848
Epoch  64 Batch   38/69   train_loss = 1.784
Epoch  64 Batch   40/69   train_loss = 1.715
Epoch  64 Batch   42/69   train_loss = 1.682
Epoch  64 Batch   44/69   train_loss = 1.668
Epoch  64 Batch   46/69   train_loss = 1.843
Epoch  64 Batch   48/69   train_loss = 1.784
Epoch  64 Batch   50/69   train_loss = 1.559
Epoch  64 Batch   52/69   train_loss = 1.780
Epoch  64 Batch   54/69   train_loss = 1.550
Epoch  64 Batch   56/69   train_loss = 1.660
Epoch  64 Batch   58/69   train_loss = 1.703
Epoch  64 Batch   60/69   train_loss = 1.720
Epoch  64 Batch   62/69   train_loss = 1.614
Epoch  64 Batch   64/69   train_loss = 1.748
Epoch  64 Batch   66/69   train_loss = 1.780
Epoch  64 Batch   68/69   train_loss = 2.020
Epoch  65 Batch    1/69   train_loss = 1.805
Epoch  65 Batch    3/69   train_loss = 1.559
Epoch  65 Batch    5/69   train_loss = 1.845
Epoch  65 Batch    7/69   train_loss = 1.785
Epoch  65 Batch    9/69   train_loss = 1.734
Epoch  65 Batch   11/69   train_loss = 1.745
Epoch  65 Batch   13/69   train_loss = 1.753
Epoch  65 Batch   15/69   train_loss = 1.772
Epoch  65 Batch   17/69   train_loss = 1.722
Epoch  65 Batch   19/69   train_loss = 1.556
Epoch  65 Batch   21/69   train_loss = 1.662
Epoch  65 Batch   23/69   train_loss = 1.759
Epoch  65 Batch   25/69   train_loss = 1.753
Epoch  65 Batch   27/69   train_loss = 1.776
Epoch  65 Batch   29/69   train_loss = 1.756
Epoch  65 Batch   31/69   train_loss = 1.819
Epoch  65 Batch   33/69   train_loss = 1.774
Epoch  65 Batch   35/69   train_loss = 1.790
Epoch  65 Batch   37/69   train_loss = 1.600
Epoch  65 Batch   39/69   train_loss = 1.704
Epoch  65 Batch   41/69   train_loss = 1.764
Epoch  65 Batch   43/69   train_loss = 1.719
Epoch  65 Batch   45/69   train_loss = 1.684
Epoch  65 Batch   47/69   train_loss = 1.733
Epoch  65 Batch   49/69   train_loss = 1.610
Epoch  65 Batch   51/69   train_loss = 1.608
Epoch  65 Batch   53/69   train_loss = 1.696
Epoch  65 Batch   55/69   train_loss = 1.674
Epoch  65 Batch   57/69   train_loss = 1.603
Epoch  65 Batch   59/69   train_loss = 1.810
Epoch  65 Batch   61/69   train_loss = 1.682
Epoch  65 Batch   63/69   train_loss = 1.769
Epoch  65 Batch   65/69   train_loss = 1.762
Epoch  65 Batch   67/69   train_loss = 1.699
Epoch  66 Batch    0/69   train_loss = 1.779
Epoch  66 Batch    2/69   train_loss = 1.771
Epoch  66 Batch    4/69   train_loss = 1.625
Epoch  66 Batch    6/69   train_loss = 1.669
Epoch  66 Batch    8/69   train_loss = 1.842
Epoch  66 Batch   10/69   train_loss = 1.791
Epoch  66 Batch   12/69   train_loss = 1.805
Epoch  66 Batch   14/69   train_loss = 1.675
Epoch  66 Batch   16/69   train_loss = 1.782
Epoch  66 Batch   18/69   train_loss = 1.703
Epoch  66 Batch   20/69   train_loss = 1.676
Epoch  66 Batch   22/69   train_loss = 1.693
Epoch  66 Batch   24/69   train_loss = 1.867
Epoch  66 Batch   26/69   train_loss = 1.700
Epoch  66 Batch   28/69   train_loss = 1.763
Epoch  66 Batch   30/69   train_loss = 1.714
Epoch  66 Batch   32/69   train_loss = 1.700
Epoch  66 Batch   34/69   train_loss = 1.676
Epoch  66 Batch   36/69   train_loss = 1.781
Epoch  66 Batch   38/69   train_loss = 1.725
Epoch  66 Batch   40/69   train_loss = 1.663
Epoch  66 Batch   42/69   train_loss = 1.623
Epoch  66 Batch   44/69   train_loss = 1.616
Epoch  66 Batch   46/69   train_loss = 1.788
Epoch  66 Batch   48/69   train_loss = 1.722
Epoch  66 Batch   50/69   train_loss = 1.498
Epoch  66 Batch   52/69   train_loss = 1.714
Epoch  66 Batch   54/69   train_loss = 1.484
Epoch  66 Batch   56/69   train_loss = 1.609
Epoch  66 Batch   58/69   train_loss = 1.643
Epoch  66 Batch   60/69   train_loss = 1.664
Epoch  66 Batch   62/69   train_loss = 1.554
Epoch  66 Batch   64/69   train_loss = 1.682
Epoch  66 Batch   66/69   train_loss = 1.721
Epoch  66 Batch   68/69   train_loss = 1.987
Epoch  67 Batch    1/69   train_loss = 1.761
Epoch  67 Batch    3/69   train_loss = 1.507
Epoch  67 Batch    5/69   train_loss = 1.778
Epoch  67 Batch    7/69   train_loss = 1.720
Epoch  67 Batch    9/69   train_loss = 1.682
Epoch  67 Batch   11/69   train_loss = 1.692
Epoch  67 Batch   13/69   train_loss = 1.717
Epoch  67 Batch   15/69   train_loss = 1.741
Epoch  67 Batch   17/69   train_loss = 1.688
Epoch  67 Batch   19/69   train_loss = 1.520
Epoch  67 Batch   21/69   train_loss = 1.619
Epoch  67 Batch   23/69   train_loss = 1.712
Epoch  67 Batch   25/69   train_loss = 1.708
Epoch  67 Batch   27/69   train_loss = 1.735
Epoch  67 Batch   29/69   train_loss = 1.702
Epoch  67 Batch   31/69   train_loss = 1.769
Epoch  67 Batch   33/69   train_loss = 1.721
Epoch  67 Batch   35/69   train_loss = 1.735
Epoch  67 Batch   37/69   train_loss = 1.532
Epoch  67 Batch   39/69   train_loss = 1.653
Epoch  67 Batch   41/69   train_loss = 1.714
Epoch  67 Batch   43/69   train_loss = 1.667
Epoch  67 Batch   45/69   train_loss = 1.639
Epoch  67 Batch   47/69   train_loss = 1.672
Epoch  67 Batch   49/69   train_loss = 1.557
Epoch  67 Batch   51/69   train_loss = 1.538
Epoch  67 Batch   53/69   train_loss = 1.638
Epoch  67 Batch   55/69   train_loss = 1.620
Epoch  67 Batch   57/69   train_loss = 1.548
Epoch  67 Batch   59/69   train_loss = 1.758
Epoch  67 Batch   61/69   train_loss = 1.627
Epoch  67 Batch   63/69   train_loss = 1.720
Epoch  67 Batch   65/69   train_loss = 1.693
Epoch  67 Batch   67/69   train_loss = 1.647
Epoch  68 Batch    0/69   train_loss = 1.735
Epoch  68 Batch    2/69   train_loss = 1.728
Epoch  68 Batch    4/69   train_loss = 1.592
Epoch  68 Batch    6/69   train_loss = 1.629
Epoch  68 Batch    8/69   train_loss = 1.774
Epoch  68 Batch   10/69   train_loss = 1.737
Epoch  68 Batch   12/69   train_loss = 1.749
Epoch  68 Batch   14/69   train_loss = 1.628
Epoch  68 Batch   16/69   train_loss = 1.731
Epoch  68 Batch   18/69   train_loss = 1.662
Epoch  68 Batch   20/69   train_loss = 1.636
Epoch  68 Batch   22/69   train_loss = 1.643
Epoch  68 Batch   24/69   train_loss = 1.820
Epoch  68 Batch   26/69   train_loss = 1.661
Epoch  68 Batch   28/69   train_loss = 1.722
Epoch  68 Batch   30/69   train_loss = 1.667
Epoch  68 Batch   32/69   train_loss = 1.659
Epoch  68 Batch   34/69   train_loss = 1.617
Epoch  68 Batch   36/69   train_loss = 1.727
Epoch  68 Batch   38/69   train_loss = 1.672
Epoch  68 Batch   40/69   train_loss = 1.614
Epoch  68 Batch   42/69   train_loss = 1.584
Epoch  68 Batch   44/69   train_loss = 1.573
Epoch  68 Batch   46/69   train_loss = 1.742
Epoch  68 Batch   48/69   train_loss = 1.669
Epoch  68 Batch   50/69   train_loss = 1.447
Epoch  68 Batch   52/69   train_loss = 1.661
Epoch  68 Batch   54/69   train_loss = 1.420
Epoch  68 Batch   56/69   train_loss = 1.556
Epoch  68 Batch   58/69   train_loss = 1.584
Epoch  68 Batch   60/69   train_loss = 1.611
Epoch  68 Batch   62/69   train_loss = 1.513
Epoch  68 Batch   64/69   train_loss = 1.629
Epoch  68 Batch   66/69   train_loss = 1.671
Epoch  68 Batch   68/69   train_loss = 1.933
Epoch  69 Batch    1/69   train_loss = 1.703
Epoch  69 Batch    3/69   train_loss = 1.461
Epoch  69 Batch    5/69   train_loss = 1.745
Epoch  69 Batch    7/69   train_loss = 1.688
Epoch  69 Batch    9/69   train_loss = 1.625
Epoch  69 Batch   11/69   train_loss = 1.623
Epoch  69 Batch   13/69   train_loss = 1.664
Epoch  69 Batch   15/69   train_loss = 1.689
Epoch  69 Batch   17/69   train_loss = 1.631
Epoch  69 Batch   19/69   train_loss = 1.466
Epoch  69 Batch   21/69   train_loss = 1.575
Epoch  69 Batch   23/69   train_loss = 1.675
Epoch  69 Batch   25/69   train_loss = 1.675
Epoch  69 Batch   27/69   train_loss = 1.684
Epoch  69 Batch   29/69   train_loss = 1.662
Epoch  69 Batch   31/69   train_loss = 1.717
Epoch  69 Batch   33/69   train_loss = 1.674
Epoch  69 Batch   35/69   train_loss = 1.684
Epoch  69 Batch   37/69   train_loss = 1.491
Epoch  69 Batch   39/69   train_loss = 1.604
Epoch  69 Batch   41/69   train_loss = 1.672
Epoch  69 Batch   43/69   train_loss = 1.623
Epoch  69 Batch   45/69   train_loss = 1.594
Epoch  69 Batch   47/69   train_loss = 1.628
Epoch  69 Batch   49/69   train_loss = 1.524
Epoch  69 Batch   51/69   train_loss = 1.492
Epoch  69 Batch   53/69   train_loss = 1.588
Epoch  69 Batch   55/69   train_loss = 1.559
Epoch  69 Batch   57/69   train_loss = 1.484
Epoch  69 Batch   59/69   train_loss = 1.697
Epoch  69 Batch   61/69   train_loss = 1.572
Epoch  69 Batch   63/69   train_loss = 1.670
Epoch  69 Batch   65/69   train_loss = 1.649
Epoch  69 Batch   67/69   train_loss = 1.605
Epoch  70 Batch    0/69   train_loss = 1.683
Epoch  70 Batch    2/69   train_loss = 1.679
Epoch  70 Batch    4/69   train_loss = 1.540
Epoch  70 Batch    6/69   train_loss = 1.588
Epoch  70 Batch    8/69   train_loss = 1.735
Epoch  70 Batch   10/69   train_loss = 1.689
Epoch  70 Batch   12/69   train_loss = 1.694
Epoch  70 Batch   14/69   train_loss = 1.572
Epoch  70 Batch   16/69   train_loss = 1.667
Epoch  70 Batch   18/69   train_loss = 1.607
Epoch  70 Batch   20/69   train_loss = 1.569
Epoch  70 Batch   22/69   train_loss = 1.602
Epoch  70 Batch   24/69   train_loss = 1.779
Epoch  70 Batch   26/69   train_loss = 1.607
Epoch  70 Batch   28/69   train_loss = 1.662
Epoch  70 Batch   30/69   train_loss = 1.620
Epoch  70 Batch   32/69   train_loss = 1.607
Epoch  70 Batch   34/69   train_loss = 1.560
Epoch  70 Batch   36/69   train_loss = 1.680
Epoch  70 Batch   38/69   train_loss = 1.629
Epoch  70 Batch   40/69   train_loss = 1.574
Epoch  70 Batch   42/69   train_loss = 1.525
Epoch  70 Batch   44/69   train_loss = 1.514
Epoch  70 Batch   46/69   train_loss = 1.699
Epoch  70 Batch   48/69   train_loss = 1.628
Epoch  70 Batch   50/69   train_loss = 1.415
Epoch  70 Batch   52/69   train_loss = 1.620
Epoch  70 Batch   54/69   train_loss = 1.374
Epoch  70 Batch   56/69   train_loss = 1.504
Epoch  70 Batch   58/69   train_loss = 1.531
Epoch  70 Batch   60/69   train_loss = 1.553
Epoch  70 Batch   62/69   train_loss = 1.467
Epoch  70 Batch   64/69   train_loss = 1.579
Epoch  70 Batch   66/69   train_loss = 1.617
Epoch  70 Batch   68/69   train_loss = 1.887
Epoch  71 Batch    1/69   train_loss = 1.654
Epoch  71 Batch    3/69   train_loss = 1.402
Epoch  71 Batch    5/69   train_loss = 1.683
Epoch  71 Batch    7/69   train_loss = 1.635
Epoch  71 Batch    9/69   train_loss = 1.606
Epoch  71 Batch   11/69   train_loss = 1.610
Epoch  71 Batch   13/69   train_loss = 1.620
Epoch  71 Batch   15/69   train_loss = 1.638
Epoch  71 Batch   17/69   train_loss = 1.581
Epoch  71 Batch   19/69   train_loss = 1.423
Epoch  71 Batch   21/69   train_loss = 1.532
Epoch  71 Batch   23/69   train_loss = 1.628
Epoch  71 Batch   25/69   train_loss = 1.622
Epoch  71 Batch   27/69   train_loss = 1.635
Epoch  71 Batch   29/69   train_loss = 1.610
Epoch  71 Batch   31/69   train_loss = 1.660
Epoch  71 Batch   33/69   train_loss = 1.620
Epoch  71 Batch   35/69   train_loss = 1.617
Epoch  71 Batch   37/69   train_loss = 1.435
Epoch  71 Batch   39/69   train_loss = 1.555
Epoch  71 Batch   41/69   train_loss = 1.617
Epoch  71 Batch   43/69   train_loss = 1.568
Epoch  71 Batch   45/69   train_loss = 1.537
Epoch  71 Batch   47/69   train_loss = 1.570
Epoch  71 Batch   49/69   train_loss = 1.477
Epoch  71 Batch   51/69   train_loss = 1.449
Epoch  71 Batch   53/69   train_loss = 1.551
Epoch  71 Batch   55/69   train_loss = 1.530
Epoch  71 Batch   57/69   train_loss = 1.444
Epoch  71 Batch   59/69   train_loss = 1.642
Epoch  71 Batch   61/69   train_loss = 1.526
Epoch  71 Batch   63/69   train_loss = 1.625
Epoch  71 Batch   65/69   train_loss = 1.595
Epoch  71 Batch   67/69   train_loss = 1.570
Epoch  72 Batch    0/69   train_loss = 1.652
Epoch  72 Batch    2/69   train_loss = 1.648
Epoch  72 Batch    4/69   train_loss = 1.500
Epoch  72 Batch    6/69   train_loss = 1.545
Epoch  72 Batch    8/69   train_loss = 1.678
Epoch  72 Batch   10/69   train_loss = 1.647
Epoch  72 Batch   12/69   train_loss = 1.668
Epoch  72 Batch   14/69   train_loss = 1.545
Epoch  72 Batch   16/69   train_loss = 1.622
Epoch  72 Batch   18/69   train_loss = 1.561
Epoch  72 Batch   20/69   train_loss = 1.529
Epoch  72 Batch   22/69   train_loss = 1.557
Epoch  72 Batch   24/69   train_loss = 1.739
Epoch  72 Batch   26/69   train_loss = 1.557
Epoch  72 Batch   28/69   train_loss = 1.616
Epoch  72 Batch   30/69   train_loss = 1.565
Epoch  72 Batch   32/69   train_loss = 1.554
Epoch  72 Batch   34/69   train_loss = 1.501
Epoch  72 Batch   36/69   train_loss = 1.626
Epoch  72 Batch   38/69   train_loss = 1.578
Epoch  72 Batch   40/69   train_loss = 1.527
Epoch  72 Batch   42/69   train_loss = 1.473
Epoch  72 Batch   44/69   train_loss = 1.462
Epoch  72 Batch   46/69   train_loss = 1.645
Epoch  72 Batch   48/69   train_loss = 1.565
Epoch  72 Batch   50/69   train_loss = 1.366
Epoch  72 Batch   52/69   train_loss = 1.559
Epoch  72 Batch   54/69   train_loss = 1.327
Epoch  72 Batch   56/69   train_loss = 1.462
Epoch  72 Batch   58/69   train_loss = 1.487
Epoch  72 Batch   60/69   train_loss = 1.532
Epoch  72 Batch   62/69   train_loss = 1.433
Epoch  72 Batch   64/69   train_loss = 1.533
Epoch  72 Batch   66/69   train_loss = 1.569
Epoch  72 Batch   68/69   train_loss = 1.836
Epoch  73 Batch    1/69   train_loss = 1.621
Epoch  73 Batch    3/69   train_loss = 1.372
Epoch  73 Batch    5/69   train_loss = 1.651
Epoch  73 Batch    7/69   train_loss = 1.616
Epoch  73 Batch    9/69   train_loss = 1.561
Epoch  73 Batch   11/69   train_loss = 1.551
Epoch  73 Batch   13/69   train_loss = 1.581
Epoch  73 Batch   15/69   train_loss = 1.602
Epoch  73 Batch   17/69   train_loss = 1.537
Epoch  73 Batch   19/69   train_loss = 1.376
Epoch  73 Batch   21/69   train_loss = 1.495
Epoch  73 Batch   23/69   train_loss = 1.584
Epoch  73 Batch   25/69   train_loss = 1.583
Epoch  73 Batch   27/69   train_loss = 1.591
Epoch  73 Batch   29/69   train_loss = 1.561
Epoch  73 Batch   31/69   train_loss = 1.611
Epoch  73 Batch   33/69   train_loss = 1.571
Epoch  73 Batch   35/69   train_loss = 1.552
Epoch  73 Batch   37/69   train_loss = 1.383
Epoch  73 Batch   39/69   train_loss = 1.502
Epoch  73 Batch   41/69   train_loss = 1.572
Epoch  73 Batch   43/69   train_loss = 1.517
Epoch  73 Batch   45/69   train_loss = 1.494
Epoch  73 Batch   47/69   train_loss = 1.507
Epoch  73 Batch   49/69   train_loss = 1.420
Epoch  73 Batch   51/69   train_loss = 1.386
Epoch  73 Batch   53/69   train_loss = 1.497
Epoch  73 Batch   55/69   train_loss = 1.470
Epoch  73 Batch   57/69   train_loss = 1.377
Epoch  73 Batch   59/69   train_loss = 1.583
Epoch  73 Batch   61/69   train_loss = 1.472
Epoch  73 Batch   63/69   train_loss = 1.584
Epoch  73 Batch   65/69   train_loss = 1.553
Epoch  73 Batch   67/69   train_loss = 1.516
Epoch  74 Batch    0/69   train_loss = 1.604
Epoch  74 Batch    2/69   train_loss = 1.586
Epoch  74 Batch    4/69   train_loss = 1.460
Epoch  74 Batch    6/69   train_loss = 1.525
Epoch  74 Batch    8/69   train_loss = 1.656
Epoch  74 Batch   10/69   train_loss = 1.629
Epoch  74 Batch   12/69   train_loss = 1.630
Epoch  74 Batch   14/69   train_loss = 1.490
Epoch  74 Batch   16/69   train_loss = 1.577
Epoch  74 Batch   18/69   train_loss = 1.530
Epoch  74 Batch   20/69   train_loss = 1.491
Epoch  74 Batch   22/69   train_loss = 1.518
Epoch  74 Batch   24/69   train_loss = 1.707
Epoch  74 Batch   26/69   train_loss = 1.518
Epoch  74 Batch   28/69   train_loss = 1.577
Epoch  74 Batch   30/69   train_loss = 1.525
Epoch  74 Batch   32/69   train_loss = 1.502
Epoch  74 Batch   34/69   train_loss = 1.440
Epoch  74 Batch   36/69   train_loss = 1.577
Epoch  74 Batch   38/69   train_loss = 1.518
Epoch  74 Batch   40/69   train_loss = 1.473
Epoch  74 Batch   42/69   train_loss = 1.421
Epoch  74 Batch   44/69   train_loss = 1.405
Epoch  74 Batch   46/69   train_loss = 1.584
Epoch  74 Batch   48/69   train_loss = 1.521
Epoch  74 Batch   50/69   train_loss = 1.307
Epoch  74 Batch   52/69   train_loss = 1.494
Epoch  74 Batch   54/69   train_loss = 1.261
Epoch  74 Batch   56/69   train_loss = 1.405
Epoch  74 Batch   58/69   train_loss = 1.426
Epoch  74 Batch   60/69   train_loss = 1.464
Epoch  74 Batch   62/69   train_loss = 1.370
Epoch  74 Batch   64/69   train_loss = 1.464
Epoch  74 Batch   66/69   train_loss = 1.515
Epoch  74 Batch   68/69   train_loss = 1.796
Epoch  75 Batch    1/69   train_loss = 1.566
Epoch  75 Batch    3/69   train_loss = 1.305
Epoch  75 Batch    5/69   train_loss = 1.590
Epoch  75 Batch    7/69   train_loss = 1.560
Epoch  75 Batch    9/69   train_loss = 1.534
Epoch  75 Batch   11/69   train_loss = 1.536
Epoch  75 Batch   13/69   train_loss = 1.562
Epoch  75 Batch   15/69   train_loss = 1.556
Epoch  75 Batch   17/69   train_loss = 1.491
Epoch  75 Batch   19/69   train_loss = 1.339
Epoch  75 Batch   21/69   train_loss = 1.468
Epoch  75 Batch   23/69   train_loss = 1.542
Epoch  75 Batch   25/69   train_loss = 1.556
Epoch  75 Batch   27/69   train_loss = 1.558
Epoch  75 Batch   29/69   train_loss = 1.533
Epoch  75 Batch   31/69   train_loss = 1.578
Epoch  75 Batch   33/69   train_loss = 1.530
Epoch  75 Batch   35/69   train_loss = 1.497
Epoch  75 Batch   37/69   train_loss = 1.339
Epoch  75 Batch   39/69   train_loss = 1.453
Epoch  75 Batch   41/69   train_loss = 1.525
Epoch  75 Batch   43/69   train_loss = 1.466
Epoch  75 Batch   45/69   train_loss = 1.441
Epoch  75 Batch   47/69   train_loss = 1.457
Epoch  75 Batch   49/69   train_loss = 1.372
Epoch  75 Batch   51/69   train_loss = 1.335
Epoch  75 Batch   53/69   train_loss = 1.446
Epoch  75 Batch   55/69   train_loss = 1.418
Epoch  75 Batch   57/69   train_loss = 1.322
Epoch  75 Batch   59/69   train_loss = 1.520
Epoch  75 Batch   61/69   train_loss = 1.412
Epoch  75 Batch   63/69   train_loss = 1.508
Epoch  75 Batch   65/69   train_loss = 1.480
Epoch  75 Batch   67/69   train_loss = 1.454
Epoch  76 Batch    0/69   train_loss = 1.545
Epoch  76 Batch    2/69   train_loss = 1.516
Epoch  76 Batch    4/69   train_loss = 1.399
Epoch  76 Batch    6/69   train_loss = 1.448
Epoch  76 Batch    8/69   train_loss = 1.577
Epoch  76 Batch   10/69   train_loss = 1.559
Epoch  76 Batch   12/69   train_loss = 1.585
Epoch  76 Batch   14/69   train_loss = 1.450
Epoch  76 Batch   16/69   train_loss = 1.523
Epoch  76 Batch   18/69   train_loss = 1.479
Epoch  76 Batch   20/69   train_loss = 1.435
Epoch  76 Batch   22/69   train_loss = 1.462
Epoch  76 Batch   24/69   train_loss = 1.658
Epoch  76 Batch   26/69   train_loss = 1.489
Epoch  76 Batch   28/69   train_loss = 1.553
Epoch  76 Batch   30/69   train_loss = 1.502
Epoch  76 Batch   32/69   train_loss = 1.466
Epoch  76 Batch   34/69   train_loss = 1.396
Epoch  76 Batch   36/69   train_loss = 1.533
Epoch  76 Batch   38/69   train_loss = 1.468
Epoch  76 Batch   40/69   train_loss = 1.425
Epoch  76 Batch   42/69   train_loss = 1.378
Epoch  76 Batch   44/69   train_loss = 1.363
Epoch  76 Batch   46/69   train_loss = 1.545
Epoch  76 Batch   48/69   train_loss = 1.467
Epoch  76 Batch   50/69   train_loss = 1.257
Epoch  76 Batch   52/69   train_loss = 1.436
Epoch  76 Batch   54/69   train_loss = 1.212
Epoch  76 Batch   56/69   train_loss = 1.355
Epoch  76 Batch   58/69   train_loss = 1.379
Epoch  76 Batch   60/69   train_loss = 1.419
Epoch  76 Batch   62/69   train_loss = 1.315
Epoch  76 Batch   64/69   train_loss = 1.403
Epoch  76 Batch   66/69   train_loss = 1.458
Epoch  76 Batch   68/69   train_loss = 1.727
Epoch  77 Batch    1/69   train_loss = 1.500
Epoch  77 Batch    3/69   train_loss = 1.247
Epoch  77 Batch    5/69   train_loss = 1.539
Epoch  77 Batch    7/69   train_loss = 1.492
Epoch  77 Batch    9/69   train_loss = 1.448
Epoch  77 Batch   11/69   train_loss = 1.455
Epoch  77 Batch   13/69   train_loss = 1.489
Epoch  77 Batch   15/69   train_loss = 1.505
Epoch  77 Batch   17/69   train_loss = 1.452
Epoch  77 Batch   19/69   train_loss = 1.295
Epoch  77 Batch   21/69   train_loss = 1.415
Epoch  77 Batch   23/69   train_loss = 1.489
Epoch  77 Batch   25/69   train_loss = 1.517
Epoch  77 Batch   27/69   train_loss = 1.521
Epoch  77 Batch   29/69   train_loss = 1.498
Epoch  77 Batch   31/69   train_loss = 1.553
Epoch  77 Batch   33/69   train_loss = 1.501
Epoch  77 Batch   35/69   train_loss = 1.467
Epoch  77 Batch   37/69   train_loss = 1.305
Epoch  77 Batch   39/69   train_loss = 1.409
Epoch  77 Batch   41/69   train_loss = 1.462
Epoch  77 Batch   43/69   train_loss = 1.424
Epoch  77 Batch   45/69   train_loss = 1.399
Epoch  77 Batch   47/69   train_loss = 1.422
Epoch  77 Batch   49/69   train_loss = 1.331
Epoch  77 Batch   51/69   train_loss = 1.298
Epoch  77 Batch   53/69   train_loss = 1.394
Epoch  77 Batch   55/69   train_loss = 1.361
Epoch  77 Batch   57/69   train_loss = 1.266
Epoch  77 Batch   59/69   train_loss = 1.475
Epoch  77 Batch   61/69   train_loss = 1.361
Epoch  77 Batch   63/69   train_loss = 1.461
Epoch  77 Batch   65/69   train_loss = 1.419
Epoch  77 Batch   67/69   train_loss = 1.398
Epoch  78 Batch    0/69   train_loss = 1.496
Epoch  78 Batch    2/69   train_loss = 1.451
Epoch  78 Batch    4/69   train_loss = 1.341
Epoch  78 Batch    6/69   train_loss = 1.399
Epoch  78 Batch    8/69   train_loss = 1.515
Epoch  78 Batch   10/69   train_loss = 1.503
Epoch  78 Batch   12/69   train_loss = 1.523
Epoch  78 Batch   14/69   train_loss = 1.392
Epoch  78 Batch   16/69   train_loss = 1.457
Epoch  78 Batch   18/69   train_loss = 1.422
Epoch  78 Batch   20/69   train_loss = 1.382
Epoch  78 Batch   22/69   train_loss = 1.388
Epoch  78 Batch   24/69   train_loss = 1.589
Epoch  78 Batch   26/69   train_loss = 1.439
Epoch  78 Batch   28/69   train_loss = 1.503
Epoch  78 Batch   30/69   train_loss = 1.455
Epoch  78 Batch   32/69   train_loss = 1.418
Epoch  78 Batch   34/69   train_loss = 1.363
Epoch  78 Batch   36/69   train_loss = 1.524
Epoch  78 Batch   38/69   train_loss = 1.427
Epoch  78 Batch   40/69   train_loss = 1.377
Epoch  78 Batch   42/69   train_loss = 1.322
Epoch  78 Batch   44/69   train_loss = 1.306
Epoch  78 Batch   46/69   train_loss = 1.504
Epoch  78 Batch   48/69   train_loss = 1.433
Epoch  78 Batch   50/69   train_loss = 1.232
Epoch  78 Batch   52/69   train_loss = 1.391
Epoch  78 Batch   54/69   train_loss = 1.164
Epoch  78 Batch   56/69   train_loss = 1.307
Epoch  78 Batch   58/69   train_loss = 1.329
Epoch  78 Batch   60/69   train_loss = 1.367
Epoch  78 Batch   62/69   train_loss = 1.274
Epoch  78 Batch   64/69   train_loss = 1.354
Epoch  78 Batch   66/69   train_loss = 1.418
Epoch  78 Batch   68/69   train_loss = 1.675
Epoch  79 Batch    1/69   train_loss = 1.456
Epoch  79 Batch    3/69   train_loss = 1.196
Epoch  79 Batch    5/69   train_loss = 1.482
Epoch  79 Batch    7/69   train_loss = 1.437
Epoch  79 Batch    9/69   train_loss = 1.389
Epoch  79 Batch   11/69   train_loss = 1.398
Epoch  79 Batch   13/69   train_loss = 1.441
Epoch  79 Batch   15/69   train_loss = 1.465
Epoch  79 Batch   17/69   train_loss = 1.412
Epoch  79 Batch   19/69   train_loss = 1.256
Epoch  79 Batch   21/69   train_loss = 1.368
Epoch  79 Batch   23/69   train_loss = 1.420
Epoch  79 Batch   25/69   train_loss = 1.453
Epoch  79 Batch   27/69   train_loss = 1.463
Epoch  79 Batch   29/69   train_loss = 1.449
Epoch  79 Batch   31/69   train_loss = 1.507
Epoch  79 Batch   33/69   train_loss = 1.452
Epoch  79 Batch   35/69   train_loss = 1.421
Epoch  79 Batch   37/69   train_loss = 1.277
Epoch  79 Batch   39/69   train_loss = 1.372
Epoch  79 Batch   41/69   train_loss = 1.422
Epoch  79 Batch   43/69   train_loss = 1.374
Epoch  79 Batch   45/69   train_loss = 1.348
Epoch  79 Batch   47/69   train_loss = 1.378
Epoch  79 Batch   49/69   train_loss = 1.295
Epoch  79 Batch   51/69   train_loss = 1.271
Epoch  79 Batch   53/69   train_loss = 1.371
Epoch  79 Batch   55/69   train_loss = 1.333
Epoch  79 Batch   57/69   train_loss = 1.214
Epoch  79 Batch   59/69   train_loss = 1.432
Epoch  79 Batch   61/69   train_loss = 1.325
Epoch  79 Batch   63/69   train_loss = 1.417
Epoch  79 Batch   65/69   train_loss = 1.383
Epoch  79 Batch   67/69   train_loss = 1.376
Epoch  80 Batch    0/69   train_loss = 1.455
Epoch  80 Batch    2/69   train_loss = 1.395
Epoch  80 Batch    4/69   train_loss = 1.294
Epoch  80 Batch    6/69   train_loss = 1.357
Epoch  80 Batch    8/69   train_loss = 1.453
Epoch  80 Batch   10/69   train_loss = 1.447
Epoch  80 Batch   12/69   train_loss = 1.466
Epoch  80 Batch   14/69   train_loss = 1.345
Epoch  80 Batch   16/69   train_loss = 1.421
Epoch  80 Batch   18/69   train_loss = 1.408
Epoch  80 Batch   20/69   train_loss = 1.361
Epoch  80 Batch   22/69   train_loss = 1.341
Epoch  80 Batch   24/69   train_loss = 1.531
Epoch  80 Batch   26/69   train_loss = 1.386
Epoch  80 Batch   28/69   train_loss = 1.455
Epoch  80 Batch   30/69   train_loss = 1.393
Epoch  80 Batch   32/69   train_loss = 1.372
Epoch  80 Batch   34/69   train_loss = 1.310
Epoch  80 Batch   36/69   train_loss = 1.471
Epoch  80 Batch   38/69   train_loss = 1.400
Epoch  80 Batch   40/69   train_loss = 1.347
Epoch  80 Batch   42/69   train_loss = 1.276
Epoch  80 Batch   44/69   train_loss = 1.270
Epoch  80 Batch   46/69   train_loss = 1.441
Epoch  80 Batch   48/69   train_loss = 1.385
Epoch  80 Batch   50/69   train_loss = 1.198
Epoch  80 Batch   52/69   train_loss = 1.366
Epoch  80 Batch   54/69   train_loss = 1.127
Epoch  80 Batch   56/69   train_loss = 1.280
Epoch  80 Batch   58/69   train_loss = 1.288
Epoch  80 Batch   60/69   train_loss = 1.318
Epoch  80 Batch   62/69   train_loss = 1.232
Epoch  80 Batch   64/69   train_loss = 1.304
Epoch  80 Batch   66/69   train_loss = 1.377
Epoch  80 Batch   68/69   train_loss = 1.645
Epoch  81 Batch    1/69   train_loss = 1.437
Epoch  81 Batch    3/69   train_loss = 1.166
Epoch  81 Batch    5/69   train_loss = 1.451
Epoch  81 Batch    7/69   train_loss = 1.391
Epoch  81 Batch    9/69   train_loss = 1.324
Epoch  81 Batch   11/69   train_loss = 1.325
Epoch  81 Batch   13/69   train_loss = 1.382
Epoch  81 Batch   15/69   train_loss = 1.402
Epoch  81 Batch   17/69   train_loss = 1.348
Epoch  81 Batch   19/69   train_loss = 1.225
Epoch  81 Batch   21/69   train_loss = 1.336
Epoch  81 Batch   23/69   train_loss = 1.394
Epoch  81 Batch   25/69   train_loss = 1.406
Epoch  81 Batch   27/69   train_loss = 1.395
Epoch  81 Batch   29/69   train_loss = 1.385
Epoch  81 Batch   31/69   train_loss = 1.462
Epoch  81 Batch   33/69   train_loss = 1.413
Epoch  81 Batch   35/69   train_loss = 1.367
Epoch  81 Batch   37/69   train_loss = 1.232
Epoch  81 Batch   39/69   train_loss = 1.336
Epoch  81 Batch   41/69   train_loss = 1.393
Epoch  81 Batch   43/69   train_loss = 1.338
Epoch  81 Batch   45/69   train_loss = 1.296
Epoch  81 Batch   47/69   train_loss = 1.332
Epoch  81 Batch   49/69   train_loss = 1.243
Epoch  81 Batch   51/69   train_loss = 1.222
Epoch  81 Batch   53/69   train_loss = 1.329
Epoch  81 Batch   55/69   train_loss = 1.305
Epoch  81 Batch   57/69   train_loss = 1.189
Epoch  81 Batch   59/69   train_loss = 1.396
Epoch  81 Batch   61/69   train_loss = 1.267
Epoch  81 Batch   63/69   train_loss = 1.354
Epoch  81 Batch   65/69   train_loss = 1.319
Epoch  81 Batch   67/69   train_loss = 1.332
Epoch  82 Batch    0/69   train_loss = 1.421
Epoch  82 Batch    2/69   train_loss = 1.360
Epoch  82 Batch    4/69   train_loss = 1.270
Epoch  82 Batch    6/69   train_loss = 1.332
Epoch  82 Batch    8/69   train_loss = 1.405
Epoch  82 Batch   10/69   train_loss = 1.402
Epoch  82 Batch   12/69   train_loss = 1.401
Epoch  82 Batch   14/69   train_loss = 1.285
Epoch  82 Batch   16/69   train_loss = 1.358
Epoch  82 Batch   18/69   train_loss = 1.345
Epoch  82 Batch   20/69   train_loss = 1.311
Epoch  82 Batch   22/69   train_loss = 1.306
Epoch  82 Batch   24/69   train_loss = 1.490
Epoch  82 Batch   26/69   train_loss = 1.342
Epoch  82 Batch   28/69   train_loss = 1.395
Epoch  82 Batch   30/69   train_loss = 1.323
Epoch  82 Batch   32/69   train_loss = 1.313
Epoch  82 Batch   34/69   train_loss = 1.265
Epoch  82 Batch   36/69   train_loss = 1.434
Epoch  82 Batch   38/69   train_loss = 1.374
Epoch  82 Batch   40/69   train_loss = 1.319
Epoch  82 Batch   42/69   train_loss = 1.249
Epoch  82 Batch   44/69   train_loss = 1.233
Epoch  82 Batch   46/69   train_loss = 1.393
Epoch  82 Batch   48/69   train_loss = 1.342
Epoch  82 Batch   50/69   train_loss = 1.157
Epoch  82 Batch   52/69   train_loss = 1.319
Epoch  82 Batch   54/69   train_loss = 1.087
Epoch  82 Batch   56/69   train_loss = 1.242
Epoch  82 Batch   58/69   train_loss = 1.256
Epoch  82 Batch   60/69   train_loss = 1.285
Epoch  82 Batch   62/69   train_loss = 1.189
Epoch  82 Batch   64/69   train_loss = 1.243
Epoch  82 Batch   66/69   train_loss = 1.307
Epoch  82 Batch   68/69   train_loss = 1.585
Epoch  83 Batch    1/69   train_loss = 1.394
Epoch  83 Batch    3/69   train_loss = 1.131
Epoch  83 Batch    5/69   train_loss = 1.409
Epoch  83 Batch    7/69   train_loss = 1.358
Epoch  83 Batch    9/69   train_loss = 1.275
Epoch  83 Batch   11/69   train_loss = 1.273
Epoch  83 Batch   13/69   train_loss = 1.324
Epoch  83 Batch   15/69   train_loss = 1.344
Epoch  83 Batch   17/69   train_loss = 1.301
Epoch  83 Batch   19/69   train_loss = 1.179
Epoch  83 Batch   21/69   train_loss = 1.286
Epoch  83 Batch   23/69   train_loss = 1.354
Epoch  83 Batch   25/69   train_loss = 1.373
Epoch  83 Batch   27/69   train_loss = 1.358
Epoch  83 Batch   29/69   train_loss = 1.326
Epoch  83 Batch   31/69   train_loss = 1.401
Epoch  83 Batch   33/69   train_loss = 1.343
Epoch  83 Batch   35/69   train_loss = 1.293
Epoch  83 Batch   37/69   train_loss = 1.179
Epoch  83 Batch   39/69   train_loss = 1.292
Epoch  83 Batch   41/69   train_loss = 1.363
Epoch  83 Batch   43/69   train_loss = 1.296
Epoch  83 Batch   45/69   train_loss = 1.266
Epoch  83 Batch   47/69   train_loss = 1.292
Epoch  83 Batch   49/69   train_loss = 1.200
Epoch  83 Batch   51/69   train_loss = 1.171
Epoch  83 Batch   53/69   train_loss = 1.291
Epoch  83 Batch   55/69   train_loss = 1.260
Epoch  83 Batch   57/69   train_loss = 1.155
Epoch  83 Batch   59/69   train_loss = 1.381
Epoch  83 Batch   61/69   train_loss = 1.251
Epoch  83 Batch   63/69   train_loss = 1.326
Epoch  83 Batch   65/69   train_loss = 1.282
Epoch  83 Batch   67/69   train_loss = 1.276
Epoch  84 Batch    0/69   train_loss = 1.363
Epoch  84 Batch    2/69   train_loss = 1.298
Epoch  84 Batch    4/69   train_loss = 1.243
Epoch  84 Batch    6/69   train_loss = 1.297
Epoch  84 Batch    8/69   train_loss = 1.371
Epoch  84 Batch   10/69   train_loss = 1.362
Epoch  84 Batch   12/69   train_loss = 1.345
Epoch  84 Batch   14/69   train_loss = 1.239
Epoch  84 Batch   16/69   train_loss = 1.296
Epoch  84 Batch   18/69   train_loss = 1.297
Epoch  84 Batch   20/69   train_loss = 1.257
Epoch  84 Batch   22/69   train_loss = 1.256
Epoch  84 Batch   24/69   train_loss = 1.461
Epoch  84 Batch   26/69   train_loss = 1.302
Epoch  84 Batch   28/69   train_loss = 1.344
Epoch  84 Batch   30/69   train_loss = 1.274
Epoch  84 Batch   32/69   train_loss = 1.252
Epoch  84 Batch   34/69   train_loss = 1.196
Epoch  84 Batch   36/69   train_loss = 1.354
Epoch  84 Batch   38/69   train_loss = 1.315
Epoch  84 Batch   40/69   train_loss = 1.270
Epoch  84 Batch   42/69   train_loss = 1.196
Epoch  84 Batch   44/69   train_loss = 1.186
Epoch  84 Batch   46/69   train_loss = 1.346
Epoch  84 Batch   48/69   train_loss = 1.293
Epoch  84 Batch   50/69   train_loss = 1.105
Epoch  84 Batch   52/69   train_loss = 1.254
Epoch  84 Batch   54/69   train_loss = 1.040
Epoch  84 Batch   56/69   train_loss = 1.197
Epoch  84 Batch   58/69   train_loss = 1.210
Epoch  84 Batch   60/69   train_loss = 1.230
Epoch  84 Batch   62/69   train_loss = 1.149
Epoch  84 Batch   64/69   train_loss = 1.202
Epoch  84 Batch   66/69   train_loss = 1.265
Epoch  84 Batch   68/69   train_loss = 1.515
Epoch  85 Batch    1/69   train_loss = 1.352
Epoch  85 Batch    3/69   train_loss = 1.091
Epoch  85 Batch    5/69   train_loss = 1.362
Epoch  85 Batch    7/69   train_loss = 1.332
Epoch  85 Batch    9/69   train_loss = 1.242
Epoch  85 Batch   11/69   train_loss = 1.236
Epoch  85 Batch   13/69   train_loss = 1.274
Epoch  85 Batch   15/69   train_loss = 1.289
Epoch  85 Batch   17/69   train_loss = 1.231
Epoch  85 Batch   19/69   train_loss = 1.112
Epoch  85 Batch   21/69   train_loss = 1.236
Epoch  85 Batch   23/69   train_loss = 1.322
Epoch  85 Batch   25/69   train_loss = 1.352
Epoch  85 Batch   27/69   train_loss = 1.330
Epoch  85 Batch   29/69   train_loss = 1.280
Epoch  85 Batch   31/69   train_loss = 1.336
Epoch  85 Batch   33/69   train_loss = 1.282
Epoch  85 Batch   35/69   train_loss = 1.224
Epoch  85 Batch   37/69   train_loss = 1.126
Epoch  85 Batch   39/69   train_loss = 1.235
Epoch  85 Batch   41/69   train_loss = 1.314
Epoch  85 Batch   43/69   train_loss = 1.245
Epoch  85 Batch   45/69   train_loss = 1.212
Epoch  85 Batch   47/69   train_loss = 1.241
Epoch  85 Batch   49/69   train_loss = 1.158
Epoch  85 Batch   51/69   train_loss = 1.126
Epoch  85 Batch   53/69   train_loss = 1.237
Epoch  85 Batch   55/69   train_loss = 1.203
Epoch  85 Batch   57/69   train_loss = 1.100
Epoch  85 Batch   59/69   train_loss = 1.319
Epoch  85 Batch   61/69   train_loss = 1.191
Epoch  85 Batch   63/69   train_loss = 1.264
Epoch  85 Batch   65/69   train_loss = 1.232
Epoch  85 Batch   67/69   train_loss = 1.224
Epoch  86 Batch    0/69   train_loss = 1.294
Epoch  86 Batch    2/69   train_loss = 1.233
Epoch  86 Batch    4/69   train_loss = 1.194
Epoch  86 Batch    6/69   train_loss = 1.248
Epoch  86 Batch    8/69   train_loss = 1.333
Epoch  86 Batch   10/69   train_loss = 1.319
Epoch  86 Batch   12/69   train_loss = 1.309
Epoch  86 Batch   14/69   train_loss = 1.199
Epoch  86 Batch   16/69   train_loss = 1.235
Epoch  86 Batch   18/69   train_loss = 1.225
Epoch  86 Batch   20/69   train_loss = 1.195
Epoch  86 Batch   22/69   train_loss = 1.200
Epoch  86 Batch   24/69   train_loss = 1.401
Epoch  86 Batch   26/69   train_loss = 1.262
Epoch  86 Batch   28/69   train_loss = 1.314
Epoch  86 Batch   30/69   train_loss = 1.243
Epoch  86 Batch   32/69   train_loss = 1.204
Epoch  86 Batch   34/69   train_loss = 1.128
Epoch  86 Batch   36/69   train_loss = 1.290
Epoch  86 Batch   38/69   train_loss = 1.256
Epoch  86 Batch   40/69   train_loss = 1.217
Epoch  86 Batch   42/69   train_loss = 1.136
Epoch  86 Batch   44/69   train_loss = 1.131
Epoch  86 Batch   46/69   train_loss = 1.287
Epoch  86 Batch   48/69   train_loss = 1.229
Epoch  86 Batch   50/69   train_loss = 1.058
Epoch  86 Batch   52/69   train_loss = 1.207
Epoch  86 Batch   54/69   train_loss = 0.995
Epoch  86 Batch   56/69   train_loss = 1.151
Epoch  86 Batch   58/69   train_loss = 1.165
Epoch  86 Batch   60/69   train_loss = 1.190
Epoch  86 Batch   62/69   train_loss = 1.107
Epoch  86 Batch   64/69   train_loss = 1.162
Epoch  86 Batch   66/69   train_loss = 1.226
Epoch  86 Batch   68/69   train_loss = 1.464
Epoch  87 Batch    1/69   train_loss = 1.289
Epoch  87 Batch    3/69   train_loss = 1.037
Epoch  87 Batch    5/69   train_loss = 1.301
Epoch  87 Batch    7/69   train_loss = 1.260
Epoch  87 Batch    9/69   train_loss = 1.194
Epoch  87 Batch   11/69   train_loss = 1.191
Epoch  87 Batch   13/69   train_loss = 1.232
Epoch  87 Batch   15/69   train_loss = 1.248
Epoch  87 Batch   17/69   train_loss = 1.179
Epoch  87 Batch   19/69   train_loss = 1.063
Epoch  87 Batch   21/69   train_loss = 1.175
Epoch  87 Batch   23/69   train_loss = 1.256
Epoch  87 Batch   25/69   train_loss = 1.297
Epoch  87 Batch   27/69   train_loss = 1.285
Epoch  87 Batch   29/69   train_loss = 1.230
Epoch  87 Batch   31/69   train_loss = 1.289
Epoch  87 Batch   33/69   train_loss = 1.237
Epoch  87 Batch   35/69   train_loss = 1.161
Epoch  87 Batch   37/69   train_loss = 1.069
Epoch  87 Batch   39/69   train_loss = 1.170
Epoch  87 Batch   41/69   train_loss = 1.256
Epoch  87 Batch   43/69   train_loss = 1.190
Epoch  87 Batch   45/69   train_loss = 1.167
Epoch  87 Batch   47/69   train_loss = 1.190
Epoch  87 Batch   49/69   train_loss = 1.099
Epoch  87 Batch   51/69   train_loss = 1.065
Epoch  87 Batch   53/69   train_loss = 1.183
Epoch  87 Batch   55/69   train_loss = 1.154
Epoch  87 Batch   57/69   train_loss = 1.050
Epoch  87 Batch   59/69   train_loss = 1.267
Epoch  87 Batch   61/69   train_loss = 1.134
Epoch  87 Batch   63/69   train_loss = 1.217
Epoch  87 Batch   65/69   train_loss = 1.192
Epoch  87 Batch   67/69   train_loss = 1.192
Epoch  88 Batch    0/69   train_loss = 1.254
Epoch  88 Batch    2/69   train_loss = 1.187
Epoch  88 Batch    4/69   train_loss = 1.143
Epoch  88 Batch    6/69   train_loss = 1.195
Epoch  88 Batch    8/69   train_loss = 1.274
Epoch  88 Batch   10/69   train_loss = 1.271
Epoch  88 Batch   12/69   train_loss = 1.261
Epoch  88 Batch   14/69   train_loss = 1.160
Epoch  88 Batch   16/69   train_loss = 1.195
Epoch  88 Batch   18/69   train_loss = 1.182
Epoch  88 Batch   20/69   train_loss = 1.146
Epoch  88 Batch   22/69   train_loss = 1.147
Epoch  88 Batch   24/69   train_loss = 1.353
Epoch  88 Batch   26/69   train_loss = 1.216
Epoch  88 Batch   28/69   train_loss = 1.263
Epoch  88 Batch   30/69   train_loss = 1.186
Epoch  88 Batch   32/69   train_loss = 1.152
Epoch  88 Batch   34/69   train_loss = 1.074
Epoch  88 Batch   36/69   train_loss = 1.242
Epoch  88 Batch   38/69   train_loss = 1.194
Epoch  88 Batch   40/69   train_loss = 1.154
Epoch  88 Batch   42/69   train_loss = 1.083
Epoch  88 Batch   44/69   train_loss = 1.080
Epoch  88 Batch   46/69   train_loss = 1.234
Epoch  88 Batch   48/69   train_loss = 1.173
Epoch  88 Batch   50/69   train_loss = 0.997
Epoch  88 Batch   52/69   train_loss = 1.128
Epoch  88 Batch   54/69   train_loss = 0.928
Epoch  88 Batch   56/69   train_loss = 1.089
Epoch  88 Batch   58/69   train_loss = 1.105
Epoch  88 Batch   60/69   train_loss = 1.127
Epoch  88 Batch   62/69   train_loss = 1.052
Epoch  88 Batch   64/69   train_loss = 1.098
Epoch  88 Batch   66/69   train_loss = 1.173
Epoch  88 Batch   68/69   train_loss = 1.414
Epoch  89 Batch    1/69   train_loss = 1.245
Epoch  89 Batch    3/69   train_loss = 0.986
Epoch  89 Batch    5/69   train_loss = 1.252
Epoch  89 Batch    7/69   train_loss = 1.204
Epoch  89 Batch    9/69   train_loss = 1.133
Epoch  89 Batch   11/69   train_loss = 1.127
Epoch  89 Batch   13/69   train_loss = 1.178
Epoch  89 Batch   15/69   train_loss = 1.212
Epoch  89 Batch   17/69   train_loss = 1.145
Epoch  89 Batch   19/69   train_loss = 1.019
Epoch  89 Batch   21/69   train_loss = 1.122
Epoch  89 Batch   23/69   train_loss = 1.204
Epoch  89 Batch   25/69   train_loss = 1.245
Epoch  89 Batch   27/69   train_loss = 1.240
Epoch  89 Batch   29/69   train_loss = 1.196
Epoch  89 Batch   31/69   train_loss = 1.242
Epoch  89 Batch   33/69   train_loss = 1.189
Epoch  89 Batch   35/69   train_loss = 1.112
Epoch  89 Batch   37/69   train_loss = 1.016
Epoch  89 Batch   39/69   train_loss = 1.119
Epoch  89 Batch   41/69   train_loss = 1.201
Epoch  89 Batch   43/69   train_loss = 1.143
Epoch  89 Batch   45/69   train_loss = 1.124
Epoch  89 Batch   47/69   train_loss = 1.147
Epoch  89 Batch   49/69   train_loss = 1.059
Epoch  89 Batch   51/69   train_loss = 1.023
Epoch  89 Batch   53/69   train_loss = 1.130
Epoch  89 Batch   55/69   train_loss = 1.097
Epoch  89 Batch   57/69   train_loss = 0.997
Epoch  89 Batch   59/69   train_loss = 1.217
Epoch  89 Batch   61/69   train_loss = 1.083
Epoch  89 Batch   63/69   train_loss = 1.151
Epoch  89 Batch   65/69   train_loss = 1.135
Epoch  89 Batch   67/69   train_loss = 1.140
Epoch  90 Batch    0/69   train_loss = 1.195
Epoch  90 Batch    2/69   train_loss = 1.137
Epoch  90 Batch    4/69   train_loss = 1.108
Epoch  90 Batch    6/69   train_loss = 1.160
Epoch  90 Batch    8/69   train_loss = 1.229
Epoch  90 Batch   10/69   train_loss = 1.215
Epoch  90 Batch   12/69   train_loss = 1.208
Epoch  90 Batch   14/69   train_loss = 1.114
Epoch  90 Batch   16/69   train_loss = 1.146
Epoch  90 Batch   18/69   train_loss = 1.145
Epoch  90 Batch   20/69   train_loss = 1.104
Epoch  90 Batch   22/69   train_loss = 1.105
Epoch  90 Batch   24/69   train_loss = 1.297
Epoch  90 Batch   26/69   train_loss = 1.176
Epoch  90 Batch   28/69   train_loss = 1.220
Epoch  90 Batch   30/69   train_loss = 1.139
Epoch  90 Batch   32/69   train_loss = 1.109
Epoch  90 Batch   34/69   train_loss = 1.023
Epoch  90 Batch   36/69   train_loss = 1.196
Epoch  90 Batch   38/69   train_loss = 1.143
Epoch  90 Batch   40/69   train_loss = 1.093
Epoch  90 Batch   42/69   train_loss = 1.031
Epoch  90 Batch   44/69   train_loss = 1.024
Epoch  90 Batch   46/69   train_loss = 1.181
Epoch  90 Batch   48/69   train_loss = 1.127
Epoch  90 Batch   50/69   train_loss = 0.957
Epoch  90 Batch   52/69   train_loss = 1.084
Epoch  90 Batch   54/69   train_loss = 0.876
Epoch  90 Batch   56/69   train_loss = 1.036
Epoch  90 Batch   58/69   train_loss = 1.061
Epoch  90 Batch   60/69   train_loss = 1.090
Epoch  90 Batch   62/69   train_loss = 1.014
Epoch  90 Batch   64/69   train_loss = 1.052
Epoch  90 Batch   66/69   train_loss = 1.122
Epoch  90 Batch   68/69   train_loss = 1.356
Epoch  91 Batch    1/69   train_loss = 1.192
Epoch  91 Batch    3/69   train_loss = 0.939
Epoch  91 Batch    5/69   train_loss = 1.208
Epoch  91 Batch    7/69   train_loss = 1.155
Epoch  91 Batch    9/69   train_loss = 1.085
Epoch  91 Batch   11/69   train_loss = 1.084
Epoch  91 Batch   13/69   train_loss = 1.145
Epoch  91 Batch   15/69   train_loss = 1.170
Epoch  91 Batch   17/69   train_loss = 1.104
Epoch  91 Batch   19/69   train_loss = 0.981
Epoch  91 Batch   21/69   train_loss = 1.078
Epoch  91 Batch   23/69   train_loss = 1.163
Epoch  91 Batch   25/69   train_loss = 1.203
Epoch  91 Batch   27/69   train_loss = 1.194
Epoch  91 Batch   29/69   train_loss = 1.152
Epoch  91 Batch   31/69   train_loss = 1.198
Epoch  91 Batch   33/69   train_loss = 1.143
Epoch  91 Batch   35/69   train_loss = 1.064
Epoch  91 Batch   37/69   train_loss = 0.971
Epoch  91 Batch   39/69   train_loss = 1.063
Epoch  91 Batch   41/69   train_loss = 1.154
Epoch  91 Batch   43/69   train_loss = 1.093
Epoch  91 Batch   45/69   train_loss = 1.072
Epoch  91 Batch   47/69   train_loss = 1.088
Epoch  91 Batch   49/69   train_loss = 1.015
Epoch  91 Batch   51/69   train_loss = 0.981
Epoch  91 Batch   53/69   train_loss = 1.080
Epoch  91 Batch   55/69   train_loss = 1.048
Epoch  91 Batch   57/69   train_loss = 0.956
Epoch  91 Batch   59/69   train_loss = 1.167
Epoch  91 Batch   61/69   train_loss = 1.033
Epoch  91 Batch   63/69   train_loss = 1.107
Epoch  91 Batch   65/69   train_loss = 1.091
Epoch  91 Batch   67/69   train_loss = 1.106
Epoch  92 Batch    0/69   train_loss = 1.148
Epoch  92 Batch    2/69   train_loss = 1.095
Epoch  92 Batch    4/69   train_loss = 1.069
Epoch  92 Batch    6/69   train_loss = 1.125
Epoch  92 Batch    8/69   train_loss = 1.184
Epoch  92 Batch   10/69   train_loss = 1.161
Epoch  92 Batch   12/69   train_loss = 1.164
Epoch  92 Batch   14/69   train_loss = 1.065
Epoch  92 Batch   16/69   train_loss = 1.099
Epoch  92 Batch   18/69   train_loss = 1.109
Epoch  92 Batch   20/69   train_loss = 1.058
Epoch  92 Batch   22/69   train_loss = 1.053
Epoch  92 Batch   24/69   train_loss = 1.251
Epoch  92 Batch   26/69   train_loss = 1.141
Epoch  92 Batch   28/69   train_loss = 1.188
Epoch  92 Batch   30/69   train_loss = 1.101
Epoch  92 Batch   32/69   train_loss = 1.072
Epoch  92 Batch   34/69   train_loss = 0.987
Epoch  92 Batch   36/69   train_loss = 1.163
Epoch  92 Batch   38/69   train_loss = 1.095
Epoch  92 Batch   40/69   train_loss = 1.051
Epoch  92 Batch   42/69   train_loss = 0.987
Epoch  92 Batch   44/69   train_loss = 0.989
Epoch  92 Batch   46/69   train_loss = 1.142
Epoch  92 Batch   48/69   train_loss = 1.088
Epoch  92 Batch   50/69   train_loss = 0.913
Epoch  92 Batch   52/69   train_loss = 1.047
Epoch  92 Batch   54/69   train_loss = 0.839
Epoch  92 Batch   56/69   train_loss = 1.001
Epoch  92 Batch   58/69   train_loss = 1.008
Epoch  92 Batch   60/69   train_loss = 1.039
Epoch  92 Batch   62/69   train_loss = 0.970
Epoch  92 Batch   64/69   train_loss = 1.006
Epoch  92 Batch   66/69   train_loss = 1.074
Epoch  92 Batch   68/69   train_loss = 1.302
Epoch  93 Batch    1/69   train_loss = 1.141
Epoch  93 Batch    3/69   train_loss = 0.896
Epoch  93 Batch    5/69   train_loss = 1.162
Epoch  93 Batch    7/69   train_loss = 1.106
Epoch  93 Batch    9/69   train_loss = 1.030
Epoch  93 Batch   11/69   train_loss = 1.027
Epoch  93 Batch   13/69   train_loss = 1.090
Epoch  93 Batch   15/69   train_loss = 1.123
Epoch  93 Batch   17/69   train_loss = 1.060
Epoch  93 Batch   19/69   train_loss = 0.955
Epoch  93 Batch   21/69   train_loss = 1.050
Epoch  93 Batch   23/69   train_loss = 1.134
Epoch  93 Batch   25/69   train_loss = 1.163
Epoch  93 Batch   27/69   train_loss = 1.149
Epoch  93 Batch   29/69   train_loss = 1.117
Epoch  93 Batch   31/69   train_loss = 1.172
Epoch  93 Batch   33/69   train_loss = 1.113
Epoch  93 Batch   35/69   train_loss = 1.020
Epoch  93 Batch   37/69   train_loss = 0.933
Epoch  93 Batch   39/69   train_loss = 1.014
Epoch  93 Batch   41/69   train_loss = 1.109
Epoch  93 Batch   43/69   train_loss = 1.052
Epoch  93 Batch   45/69   train_loss = 1.026
Epoch  93 Batch   47/69   train_loss = 1.051
Epoch  93 Batch   49/69   train_loss = 0.978
Epoch  93 Batch   51/69   train_loss = 0.946
Epoch  93 Batch   53/69   train_loss = 1.045
Epoch  93 Batch   55/69   train_loss = 0.999
Epoch  93 Batch   57/69   train_loss = 0.910
Epoch  93 Batch   59/69   train_loss = 1.116
Epoch  93 Batch   61/69   train_loss = 1.014
Epoch  93 Batch   63/69   train_loss = 1.083
Epoch  93 Batch   65/69   train_loss = 1.052
Epoch  93 Batch   67/69   train_loss = 1.055
Epoch  94 Batch    0/69   train_loss = 1.103
Epoch  94 Batch    2/69   train_loss = 1.050
Epoch  94 Batch    4/69   train_loss = 1.030
Epoch  94 Batch    6/69   train_loss = 1.075
Epoch  94 Batch    8/69   train_loss = 1.135
Epoch  94 Batch   10/69   train_loss = 1.112
Epoch  94 Batch   12/69   train_loss = 1.123
Epoch  94 Batch   14/69   train_loss = 1.026
Epoch  94 Batch   16/69   train_loss = 1.051
Epoch  94 Batch   18/69   train_loss = 1.058
Epoch  94 Batch   20/69   train_loss = 1.005
Epoch  94 Batch   22/69   train_loss = 1.010
Epoch  94 Batch   24/69   train_loss = 1.229
Epoch  94 Batch   26/69   train_loss = 1.117
Epoch  94 Batch   28/69   train_loss = 1.147
Epoch  94 Batch   30/69   train_loss = 1.053
Epoch  94 Batch   32/69   train_loss = 1.038
Epoch  94 Batch   34/69   train_loss = 0.957
Epoch  94 Batch   36/69   train_loss = 1.133
Epoch  94 Batch   38/69   train_loss = 1.078
Epoch  94 Batch   40/69   train_loss = 1.028
Epoch  94 Batch   42/69   train_loss = 0.947
Epoch  94 Batch   44/69   train_loss = 0.959
Epoch  94 Batch   46/69   train_loss = 1.114
Epoch  94 Batch   48/69   train_loss = 1.062
Epoch  94 Batch   50/69   train_loss = 0.887
Epoch  94 Batch   52/69   train_loss = 1.007
Epoch  94 Batch   54/69   train_loss = 0.797
Epoch  94 Batch   56/69   train_loss = 0.956
Epoch  94 Batch   58/69   train_loss = 0.965
Epoch  94 Batch   60/69   train_loss = 1.006
Epoch  94 Batch   62/69   train_loss = 0.933
Epoch  94 Batch   64/69   train_loss = 0.984
Epoch  94 Batch   66/69   train_loss = 1.044
Epoch  94 Batch   68/69   train_loss = 1.261
Epoch  95 Batch    1/69   train_loss = 1.100
Epoch  95 Batch    3/69   train_loss = 0.859
Epoch  95 Batch    5/69   train_loss = 1.121
Epoch  95 Batch    7/69   train_loss = 1.067
Epoch  95 Batch    9/69   train_loss = 0.985
Epoch  95 Batch   11/69   train_loss = 0.978
Epoch  95 Batch   13/69   train_loss = 1.047
Epoch  95 Batch   15/69   train_loss = 1.080
Epoch  95 Batch   17/69   train_loss = 1.015
Epoch  95 Batch   19/69   train_loss = 0.907
Epoch  95 Batch   21/69   train_loss = 0.980
Epoch  95 Batch   23/69   train_loss = 1.073
Epoch  95 Batch   25/69   train_loss = 1.127
Epoch  95 Batch   27/69   train_loss = 1.117
Epoch  95 Batch   29/69   train_loss = 1.088
Epoch  95 Batch   31/69   train_loss = 1.130
Epoch  95 Batch   33/69   train_loss = 1.068
Epoch  95 Batch   35/69   train_loss = 0.980
Epoch  95 Batch   37/69   train_loss = 0.902
Epoch  95 Batch   39/69   train_loss = 0.979
Epoch  95 Batch   41/69   train_loss = 1.082
Epoch  95 Batch   43/69   train_loss = 1.007
Epoch  95 Batch   45/69   train_loss = 0.991
Epoch  95 Batch   47/69   train_loss = 1.016
Epoch  95 Batch   49/69   train_loss = 0.949
Epoch  95 Batch   51/69   train_loss = 0.917
Epoch  95 Batch   53/69   train_loss = 1.011
Epoch  95 Batch   55/69   train_loss = 0.959
Epoch  95 Batch   57/69   train_loss = 0.876
Epoch  95 Batch   59/69   train_loss = 1.062
Epoch  95 Batch   61/69   train_loss = 0.967
Epoch  95 Batch   63/69   train_loss = 1.037
Epoch  95 Batch   65/69   train_loss = 1.016
Epoch  95 Batch   67/69   train_loss = 1.024
Epoch  96 Batch    0/69   train_loss = 1.068
Epoch  96 Batch    2/69   train_loss = 1.013
Epoch  96 Batch    4/69   train_loss = 0.993
Epoch  96 Batch    6/69   train_loss = 1.040
Epoch  96 Batch    8/69   train_loss = 1.090
Epoch  96 Batch   10/69   train_loss = 1.070
Epoch  96 Batch   12/69   train_loss = 1.085
Epoch  96 Batch   14/69   train_loss = 0.986
Epoch  96 Batch   16/69   train_loss = 1.007
Epoch  96 Batch   18/69   train_loss = 1.018
Epoch  96 Batch   20/69   train_loss = 0.968
Epoch  96 Batch   22/69   train_loss = 0.962
Epoch  96 Batch   24/69   train_loss = 1.161
Epoch  96 Batch   26/69   train_loss = 1.063
Epoch  96 Batch   28/69   train_loss = 1.111
Epoch  96 Batch   30/69   train_loss = 1.020
Epoch  96 Batch   32/69   train_loss = 0.999
Epoch  96 Batch   34/69   train_loss = 0.905
Epoch  96 Batch   36/69   train_loss = 1.091
Epoch  96 Batch   38/69   train_loss = 1.042
Epoch  96 Batch   40/69   train_loss = 0.990
Epoch  96 Batch   42/69   train_loss = 0.903
Epoch  96 Batch   44/69   train_loss = 0.919
Epoch  96 Batch   46/69   train_loss = 1.064
Epoch  96 Batch   48/69   train_loss = 1.013
Epoch  96 Batch   50/69   train_loss = 0.853
Epoch  96 Batch   52/69   train_loss = 0.976
Epoch  96 Batch   54/69   train_loss = 0.777
Epoch  96 Batch   56/69   train_loss = 0.927
Epoch  96 Batch   58/69   train_loss = 0.922
Epoch  96 Batch   60/69   train_loss = 0.960
Epoch  96 Batch   62/69   train_loss = 0.892
Epoch  96 Batch   64/69   train_loss = 0.943
Epoch  96 Batch   66/69   train_loss = 1.020
Epoch  96 Batch   68/69   train_loss = 1.222
Epoch  97 Batch    1/69   train_loss = 1.061
Epoch  97 Batch    3/69   train_loss = 0.822
Epoch  97 Batch    5/69   train_loss = 1.074
Epoch  97 Batch    7/69   train_loss = 1.032
Epoch  97 Batch    9/69   train_loss = 0.944
Epoch  97 Batch   11/69   train_loss = 0.936
Epoch  97 Batch   13/69   train_loss = 1.000
Epoch  97 Batch   15/69   train_loss = 1.044
Epoch  97 Batch   17/69   train_loss = 0.979
Epoch  97 Batch   19/69   train_loss = 0.872
Epoch  97 Batch   21/69   train_loss = 0.950
Epoch  97 Batch   23/69   train_loss = 1.028
Epoch  97 Batch   25/69   train_loss = 1.082
Epoch  97 Batch   27/69   train_loss = 1.068
Epoch  97 Batch   29/69   train_loss = 1.036
Epoch  97 Batch   31/69   train_loss = 1.095
Epoch  97 Batch   33/69   train_loss = 1.029
Epoch  97 Batch   35/69   train_loss = 0.934
Epoch  97 Batch   37/69   train_loss = 0.863
Epoch  97 Batch   39/69   train_loss = 0.940
Epoch  97 Batch   41/69   train_loss = 1.041
Epoch  97 Batch   43/69   train_loss = 0.959
Epoch  97 Batch   45/69   train_loss = 0.950
Epoch  97 Batch   47/69   train_loss = 0.976
Epoch  97 Batch   49/69   train_loss = 0.909
Epoch  97 Batch   51/69   train_loss = 0.877
Epoch  97 Batch   53/69   train_loss = 0.970
Epoch  97 Batch   55/69   train_loss = 0.923
Epoch  97 Batch   57/69   train_loss = 0.841
Epoch  97 Batch   59/69   train_loss = 1.032
Epoch  97 Batch   61/69   train_loss = 0.922
Epoch  97 Batch   63/69   train_loss = 0.991
Epoch  97 Batch   65/69   train_loss = 0.975
Epoch  97 Batch   67/69   train_loss = 0.985
Epoch  98 Batch    0/69   train_loss = 1.040
Epoch  98 Batch    2/69   train_loss = 0.975
Epoch  98 Batch    4/69   train_loss = 0.955
Epoch  98 Batch    6/69   train_loss = 1.004
Epoch  98 Batch    8/69   train_loss = 1.046
Epoch  98 Batch   10/69   train_loss = 1.032
Epoch  98 Batch   12/69   train_loss = 1.043
Epoch  98 Batch   14/69   train_loss = 0.942
Epoch  98 Batch   16/69   train_loss = 0.962
Epoch  98 Batch   18/69   train_loss = 0.968
Epoch  98 Batch   20/69   train_loss = 0.925
Epoch  98 Batch   22/69   train_loss = 0.920
Epoch  98 Batch   24/69   train_loss = 1.117
Epoch  98 Batch   26/69   train_loss = 1.028
Epoch  98 Batch   28/69   train_loss = 1.063
Epoch  98 Batch   30/69   train_loss = 0.975
Epoch  98 Batch   32/69   train_loss = 0.952
Epoch  98 Batch   34/69   train_loss = 0.870
Epoch  98 Batch   36/69   train_loss = 1.055
Epoch  98 Batch   38/69   train_loss = 0.995
Epoch  98 Batch   40/69   train_loss = 0.947
Epoch  98 Batch   42/69   train_loss = 0.864
Epoch  98 Batch   44/69   train_loss = 0.881
Epoch  98 Batch   46/69   train_loss = 1.021
Epoch  98 Batch   48/69   train_loss = 0.972
Epoch  98 Batch   50/69   train_loss = 0.808
Epoch  98 Batch   52/69   train_loss = 0.929
Epoch  98 Batch   54/69   train_loss = 0.738
Epoch  98 Batch   56/69   train_loss = 0.887
Epoch  98 Batch   58/69   train_loss = 0.888
Epoch  98 Batch   60/69   train_loss = 0.913
Epoch  98 Batch   62/69   train_loss = 0.852
Epoch  98 Batch   64/69   train_loss = 0.898
Epoch  98 Batch   66/69   train_loss = 0.976
Epoch  98 Batch   68/69   train_loss = 1.187
Epoch  99 Batch    1/69   train_loss = 1.038
Epoch  99 Batch    3/69   train_loss = 0.799
Epoch  99 Batch    5/69   train_loss = 1.053
Epoch  99 Batch    7/69   train_loss = 0.998
Epoch  99 Batch    9/69   train_loss = 0.911
Epoch  99 Batch   11/69   train_loss = 0.902
Epoch  99 Batch   13/69   train_loss = 0.966
Epoch  99 Batch   15/69   train_loss = 1.016
Epoch  99 Batch   17/69   train_loss = 0.947
Epoch  99 Batch   19/69   train_loss = 0.838
Epoch  99 Batch   21/69   train_loss = 0.906
Epoch  99 Batch   23/69   train_loss = 0.990
Epoch  99 Batch   25/69   train_loss = 1.043
Epoch  99 Batch   27/69   train_loss = 1.031
Epoch  99 Batch   29/69   train_loss = 0.993
Epoch  99 Batch   31/69   train_loss = 1.048
Epoch  99 Batch   33/69   train_loss = 0.992
Epoch  99 Batch   35/69   train_loss = 0.886
Epoch  99 Batch   37/69   train_loss = 0.824
Epoch  99 Batch   39/69   train_loss = 0.900
Epoch  99 Batch   41/69   train_loss = 0.992
Epoch  99 Batch   43/69   train_loss = 0.914
Epoch  99 Batch   45/69   train_loss = 0.918
Epoch  99 Batch   47/69   train_loss = 0.947
Epoch  99 Batch   49/69   train_loss = 0.871
Epoch  99 Batch   51/69   train_loss = 0.842
Epoch  99 Batch   53/69   train_loss = 0.934
Epoch  99 Batch   55/69   train_loss = 0.883
Epoch  99 Batch   57/69   train_loss = 0.811
Epoch  99 Batch   59/69   train_loss = 1.007
Epoch  99 Batch   61/69   train_loss = 0.886
Epoch  99 Batch   63/69   train_loss = 0.944
Epoch  99 Batch   65/69   train_loss = 0.935
Epoch  99 Batch   67/69   train_loss = 0.955
Epoch 100 Batch    0/69   train_loss = 1.009
Epoch 100 Batch    2/69   train_loss = 0.931
Epoch 100 Batch    4/69   train_loss = 0.919
Epoch 100 Batch    6/69   train_loss = 0.968
Epoch 100 Batch    8/69   train_loss = 1.010
Epoch 100 Batch   10/69   train_loss = 0.989
Epoch 100 Batch   12/69   train_loss = 0.999
Epoch 100 Batch   14/69   train_loss = 0.904
Epoch 100 Batch   16/69   train_loss = 0.934
Epoch 100 Batch   18/69   train_loss = 0.936
Epoch 100 Batch   20/69   train_loss = 0.885
Epoch 100 Batch   22/69   train_loss = 0.887
Epoch 100 Batch   24/69   train_loss = 1.068
Epoch 100 Batch   26/69   train_loss = 0.984
Epoch 100 Batch   28/69   train_loss = 1.019
Epoch 100 Batch   30/69   train_loss = 0.932
Epoch 100 Batch   32/69   train_loss = 0.912
Epoch 100 Batch   34/69   train_loss = 0.827
Epoch 100 Batch   36/69   train_loss = 1.015
Epoch 100 Batch   38/69   train_loss = 0.966
Epoch 100 Batch   40/69   train_loss = 0.906
Epoch 100 Batch   42/69   train_loss = 0.823
Epoch 100 Batch   44/69   train_loss = 0.833
Epoch 100 Batch   46/69   train_loss = 0.980
Epoch 100 Batch   48/69   train_loss = 0.933
Epoch 100 Batch   50/69   train_loss = 0.774
Epoch 100 Batch   52/69   train_loss = 0.882
Epoch 100 Batch   54/69   train_loss = 0.698
Epoch 100 Batch   56/69   train_loss = 0.847
Epoch 100 Batch   58/69   train_loss = 0.849
Epoch 100 Batch   60/69   train_loss = 0.881
Epoch 100 Batch   62/69   train_loss = 0.820
Epoch 100 Batch   64/69   train_loss = 0.849
Epoch 100 Batch   66/69   train_loss = 0.928
Epoch 100 Batch   68/69   train_loss = 1.130
Epoch 101 Batch    1/69   train_loss = 0.994
Epoch 101 Batch    3/69   train_loss = 0.774
Epoch 101 Batch    5/69   train_loss = 1.025
Epoch 101 Batch    7/69   train_loss = 0.942
Epoch 101 Batch    9/69   train_loss = 0.864
Epoch 101 Batch   11/69   train_loss = 0.845
Epoch 101 Batch   13/69   train_loss = 0.925
Epoch 101 Batch   15/69   train_loss = 0.978
Epoch 101 Batch   17/69   train_loss = 0.917
Epoch 101 Batch   19/69   train_loss = 0.800
Epoch 101 Batch   21/69   train_loss = 0.872
Epoch 101 Batch   23/69   train_loss = 0.950
Epoch 101 Batch   25/69   train_loss = 1.012
Epoch 101 Batch   27/69   train_loss = 0.984
Epoch 101 Batch   29/69   train_loss = 0.950
Epoch 101 Batch   31/69   train_loss = 1.003
Epoch 101 Batch   33/69   train_loss = 0.961
Epoch 101 Batch   35/69   train_loss = 0.851
Epoch 101 Batch   37/69   train_loss = 0.786
Epoch 101 Batch   39/69   train_loss = 0.856
Epoch 101 Batch   41/69   train_loss = 0.954
Epoch 101 Batch   43/69   train_loss = 0.875
Epoch 101 Batch   45/69   train_loss = 0.873
Epoch 101 Batch   47/69   train_loss = 0.901
Epoch 101 Batch   49/69   train_loss = 0.830
Epoch 101 Batch   51/69   train_loss = 0.810
Epoch 101 Batch   53/69   train_loss = 0.888
Epoch 101 Batch   55/69   train_loss = 0.834
Epoch 101 Batch   57/69   train_loss = 0.764
Epoch 101 Batch   59/69   train_loss = 0.955
Epoch 101 Batch   61/69   train_loss = 0.846
Epoch 101 Batch   63/69   train_loss = 0.906
Epoch 101 Batch   65/69   train_loss = 0.902
Epoch 101 Batch   67/69   train_loss = 0.904
Epoch 102 Batch    0/69   train_loss = 0.941
Epoch 102 Batch    2/69   train_loss = 0.882
Epoch 102 Batch    4/69   train_loss = 0.894
Epoch 102 Batch    6/69   train_loss = 0.944
Epoch 102 Batch    8/69   train_loss = 0.991
Epoch 102 Batch   10/69   train_loss = 0.952
Epoch 102 Batch   12/69   train_loss = 0.962
Epoch 102 Batch   14/69   train_loss = 0.861
Epoch 102 Batch   16/69   train_loss = 0.887
Epoch 102 Batch   18/69   train_loss = 0.908
Epoch 102 Batch   20/69   train_loss = 0.854
Epoch 102 Batch   22/69   train_loss = 0.854
Epoch 102 Batch   24/69   train_loss = 1.039
Epoch 102 Batch   26/69   train_loss = 0.954
Epoch 102 Batch   28/69   train_loss = 0.976
Epoch 102 Batch   30/69   train_loss = 0.885
Epoch 102 Batch   32/69   train_loss = 0.874
Epoch 102 Batch   34/69   train_loss = 0.787
Epoch 102 Batch   36/69   train_loss = 0.986
Epoch 102 Batch   38/69   train_loss = 0.943
Epoch 102 Batch   40/69   train_loss = 0.876
Epoch 102 Batch   42/69   train_loss = 0.789
Epoch 102 Batch   44/69   train_loss = 0.803
Epoch 102 Batch   46/69   train_loss = 0.934
Epoch 102 Batch   48/69   train_loss = 0.897
Epoch 102 Batch   50/69   train_loss = 0.740
Epoch 102 Batch   52/69   train_loss = 0.837
Epoch 102 Batch   54/69   train_loss = 0.654
Epoch 102 Batch   56/69   train_loss = 0.807
Epoch 102 Batch   58/69   train_loss = 0.800
Epoch 102 Batch   60/69   train_loss = 0.826
Epoch 102 Batch   62/69   train_loss = 0.776
Epoch 102 Batch   64/69   train_loss = 0.806
Epoch 102 Batch   66/69   train_loss = 0.878
Epoch 102 Batch   68/69   train_loss = 1.089
Epoch 103 Batch    1/69   train_loss = 0.942
Epoch 103 Batch    3/69   train_loss = 0.720
Epoch 103 Batch    5/69   train_loss = 0.983
Epoch 103 Batch    7/69   train_loss = 0.902
Epoch 103 Batch    9/69   train_loss = 0.825
Epoch 103 Batch   11/69   train_loss = 0.816
Epoch 103 Batch   13/69   train_loss = 0.883
Epoch 103 Batch   15/69   train_loss = 0.938
Epoch 103 Batch   17/69   train_loss = 0.876
Epoch 103 Batch   19/69   train_loss = 0.778
Epoch 103 Batch   21/69   train_loss = 0.843
Epoch 103 Batch   23/69   train_loss = 0.926
Epoch 103 Batch   25/69   train_loss = 0.974
Epoch 103 Batch   27/69   train_loss = 0.938
Epoch 103 Batch   29/69   train_loss = 0.912
Epoch 103 Batch   31/69   train_loss = 0.957
Epoch 103 Batch   33/69   train_loss = 0.917
Epoch 103 Batch   35/69   train_loss = 0.806
Epoch 103 Batch   37/69   train_loss = 0.746
Epoch 103 Batch   39/69   train_loss = 0.826
Epoch 103 Batch   41/69   train_loss = 0.930
Epoch 103 Batch   43/69   train_loss = 0.845
Epoch 103 Batch   45/69   train_loss = 0.839
Epoch 103 Batch   47/69   train_loss = 0.860
Epoch 103 Batch   49/69   train_loss = 0.794
Epoch 103 Batch   51/69   train_loss = 0.773
Epoch 103 Batch   53/69   train_loss = 0.851
Epoch 103 Batch   55/69   train_loss = 0.807
Epoch 103 Batch   57/69   train_loss = 0.727
Epoch 103 Batch   59/69   train_loss = 0.906
Epoch 103 Batch   61/69   train_loss = 0.803
Epoch 103 Batch   63/69   train_loss = 0.855
Epoch 103 Batch   65/69   train_loss = 0.856
Epoch 103 Batch   67/69   train_loss = 0.864
Epoch 104 Batch    0/69   train_loss = 0.892
Epoch 104 Batch    2/69   train_loss = 0.838
Epoch 104 Batch    4/69   train_loss = 0.844
Epoch 104 Batch    6/69   train_loss = 0.886
Epoch 104 Batch    8/69   train_loss = 0.935
Epoch 104 Batch   10/69   train_loss = 0.917
Epoch 104 Batch   12/69   train_loss = 0.926
Epoch 104 Batch   14/69   train_loss = 0.831
Epoch 104 Batch   16/69   train_loss = 0.843
Epoch 104 Batch   18/69   train_loss = 0.864
Epoch 104 Batch   20/69   train_loss = 0.812
Epoch 104 Batch   22/69   train_loss = 0.827
Epoch 104 Batch   24/69   train_loss = 1.018
Epoch 104 Batch   26/69   train_loss = 0.930
Epoch 104 Batch   28/69   train_loss = 0.939
Epoch 104 Batch   30/69   train_loss = 0.846
Epoch 104 Batch   32/69   train_loss = 0.835
Epoch 104 Batch   34/69   train_loss = 0.750
Epoch 104 Batch   36/69   train_loss = 0.947
Epoch 104 Batch   38/69   train_loss = 0.910
Epoch 104 Batch   40/69   train_loss = 0.840
Epoch 104 Batch   42/69   train_loss = 0.761
Epoch 104 Batch   44/69   train_loss = 0.776
Epoch 104 Batch   46/69   train_loss = 0.905
Epoch 104 Batch   48/69   train_loss = 0.861
Epoch 104 Batch   50/69   train_loss = 0.710
Epoch 104 Batch   52/69   train_loss = 0.800
Epoch 104 Batch   54/69   train_loss = 0.627
Epoch 104 Batch   56/69   train_loss = 0.778
Epoch 104 Batch   58/69   train_loss = 0.777
Epoch 104 Batch   60/69   train_loss = 0.794
Epoch 104 Batch   62/69   train_loss = 0.743
Epoch 104 Batch   64/69   train_loss = 0.771
Epoch 104 Batch   66/69   train_loss = 0.833
Epoch 104 Batch   68/69   train_loss = 1.049
Epoch 105 Batch    1/69   train_loss = 0.899
Epoch 105 Batch    3/69   train_loss = 0.683
Epoch 105 Batch    5/69   train_loss = 0.936
Epoch 105 Batch    7/69   train_loss = 0.861
Epoch 105 Batch    9/69   train_loss = 0.783
Epoch 105 Batch   11/69   train_loss = 0.779
Epoch 105 Batch   13/69   train_loss = 0.842
Epoch 105 Batch   15/69   train_loss = 0.898
Epoch 105 Batch   17/69   train_loss = 0.834
Epoch 105 Batch   19/69   train_loss = 0.731
Epoch 105 Batch   21/69   train_loss = 0.798
Epoch 105 Batch   23/69   train_loss = 0.882
Epoch 105 Batch   25/69   train_loss = 0.951
Epoch 105 Batch   27/69   train_loss = 0.919
Epoch 105 Batch   29/69   train_loss = 0.879
Epoch 105 Batch   31/69   train_loss = 0.917
Epoch 105 Batch   33/69   train_loss = 0.876
Epoch 105 Batch   35/69   train_loss = 0.775
Epoch 105 Batch   37/69   train_loss = 0.723
Epoch 105 Batch   39/69   train_loss = 0.794
Epoch 105 Batch   41/69   train_loss = 0.907
Epoch 105 Batch   43/69   train_loss = 0.804
Epoch 105 Batch   45/69   train_loss = 0.810
Epoch 105 Batch   47/69   train_loss = 0.835
Epoch 105 Batch   49/69   train_loss = 0.762
Epoch 105 Batch   51/69   train_loss = 0.745
Epoch 105 Batch   53/69   train_loss = 0.822
Epoch 105 Batch   55/69   train_loss = 0.775
Epoch 105 Batch   57/69   train_loss = 0.700
Epoch 105 Batch   59/69   train_loss = 0.880
Epoch 105 Batch   61/69   train_loss = 0.780
Epoch 105 Batch   63/69   train_loss = 0.810
Epoch 105 Batch   65/69   train_loss = 0.819
Epoch 105 Batch   67/69   train_loss = 0.830
Epoch 106 Batch    0/69   train_loss = 0.852
Epoch 106 Batch    2/69   train_loss = 0.806
Epoch 106 Batch    4/69   train_loss = 0.818
Epoch 106 Batch    6/69   train_loss = 0.846
Epoch 106 Batch    8/69   train_loss = 0.897
Epoch 106 Batch   10/69   train_loss = 0.876
Epoch 106 Batch   12/69   train_loss = 0.901
Epoch 106 Batch   14/69   train_loss = 0.800
Epoch 106 Batch   16/69   train_loss = 0.814
Epoch 106 Batch   18/69   train_loss = 0.832
Epoch 106 Batch   20/69   train_loss = 0.778
Epoch 106 Batch   22/69   train_loss = 0.782
Epoch 106 Batch   24/69   train_loss = 0.968
Epoch 106 Batch   26/69   train_loss = 0.896
Epoch 106 Batch   28/69   train_loss = 0.913
Epoch 106 Batch   30/69   train_loss = 0.832
Epoch 106 Batch   32/69   train_loss = 0.804
Epoch 106 Batch   34/69   train_loss = 0.703
Epoch 106 Batch   36/69   train_loss = 0.907
Epoch 106 Batch   38/69   train_loss = 0.885
Epoch 106 Batch   40/69   train_loss = 0.825
Epoch 106 Batch   42/69   train_loss = 0.736
Epoch 106 Batch   44/69   train_loss = 0.757
Epoch 106 Batch   46/69   train_loss = 0.879
Epoch 106 Batch   48/69   train_loss = 0.832
Epoch 106 Batch   50/69   train_loss = 0.698
Epoch 106 Batch   52/69   train_loss = 0.784
Epoch 106 Batch   54/69   train_loss = 0.622
Epoch 106 Batch   56/69   train_loss = 0.755
Epoch 106 Batch   58/69   train_loss = 0.749
Epoch 106 Batch   60/69   train_loss = 0.772
Epoch 106 Batch   62/69   train_loss = 0.721
Epoch 106 Batch   64/69   train_loss = 0.766
Epoch 106 Batch   66/69   train_loss = 0.807
Epoch 106 Batch   68/69   train_loss = 1.012
Epoch 107 Batch    1/69   train_loss = 0.870
Epoch 107 Batch    3/69   train_loss = 0.654
Epoch 107 Batch    5/69   train_loss = 0.898
Epoch 107 Batch    7/69   train_loss = 0.842
Epoch 107 Batch    9/69   train_loss = 0.748
Epoch 107 Batch   11/69   train_loss = 0.740
Epoch 107 Batch   13/69   train_loss = 0.809
Epoch 107 Batch   15/69   train_loss = 0.867
Epoch 107 Batch   17/69   train_loss = 0.817
Epoch 107 Batch   19/69   train_loss = 0.707
Epoch 107 Batch   21/69   train_loss = 0.761
Epoch 107 Batch   23/69   train_loss = 0.850
Epoch 107 Batch   25/69   train_loss = 0.915
Epoch 107 Batch   27/69   train_loss = 0.898
Epoch 107 Batch   29/69   train_loss = 0.862
Epoch 107 Batch   31/69   train_loss = 0.896
Epoch 107 Batch   33/69   train_loss = 0.860
Epoch 107 Batch   35/69   train_loss = 0.746
Epoch 107 Batch   37/69   train_loss = 0.679
Epoch 107 Batch   39/69   train_loss = 0.768
Epoch 107 Batch   41/69   train_loss = 0.887
Epoch 107 Batch   43/69   train_loss = 0.795
Epoch 107 Batch   45/69   train_loss = 0.794
Epoch 107 Batch   47/69   train_loss = 0.807
Epoch 107 Batch   49/69   train_loss = 0.737
Epoch 107 Batch   51/69   train_loss = 0.727
Epoch 107 Batch   53/69   train_loss = 0.789
Epoch 107 Batch   55/69   train_loss = 0.754
Epoch 107 Batch   57/69   train_loss = 0.676
Epoch 107 Batch   59/69   train_loss = 0.862
Epoch 107 Batch   61/69   train_loss = 0.779
Epoch 107 Batch   63/69   train_loss = 0.790
Epoch 107 Batch   65/69   train_loss = 0.799
Epoch 107 Batch   67/69   train_loss = 0.818
Epoch 108 Batch    0/69   train_loss = 0.839
Epoch 108 Batch    2/69   train_loss = 0.784
Epoch 108 Batch    4/69   train_loss = 0.801
Epoch 108 Batch    6/69   train_loss = 0.820
Epoch 108 Batch    8/69   train_loss = 0.864
Epoch 108 Batch   10/69   train_loss = 0.844
Epoch 108 Batch   12/69   train_loss = 0.859
Epoch 108 Batch   14/69   train_loss = 0.757
Epoch 108 Batch   16/69   train_loss = 0.778
Epoch 108 Batch   18/69   train_loss = 0.802
Epoch 108 Batch   20/69   train_loss = 0.752
Epoch 108 Batch   22/69   train_loss = 0.756
Epoch 108 Batch   24/69   train_loss = 0.922
Epoch 108 Batch   26/69   train_loss = 0.860
Epoch 108 Batch   28/69   train_loss = 0.880
Epoch 108 Batch   30/69   train_loss = 0.819
Epoch 108 Batch   32/69   train_loss = 0.791
Epoch 108 Batch   34/69   train_loss = 0.700
Epoch 108 Batch   36/69   train_loss = 0.895
Epoch 108 Batch   38/69   train_loss = 0.846
Epoch 108 Batch   40/69   train_loss = 0.793
Epoch 108 Batch   42/69   train_loss = 0.708
Epoch 108 Batch   44/69   train_loss = 0.751
Epoch 108 Batch   46/69   train_loss = 0.859
Epoch 108 Batch   48/69   train_loss = 0.822
Epoch 108 Batch   50/69   train_loss = 0.673
Epoch 108 Batch   52/69   train_loss = 0.758
Epoch 108 Batch   54/69   train_loss = 0.602
Epoch 108 Batch   56/69   train_loss = 0.739
Epoch 108 Batch   58/69   train_loss = 0.732
Epoch 108 Batch   60/69   train_loss = 0.745
Epoch 108 Batch   62/69   train_loss = 0.706
Epoch 108 Batch   64/69   train_loss = 0.733
Epoch 108 Batch   66/69   train_loss = 0.781
Epoch 108 Batch   68/69   train_loss = 0.991
Epoch 109 Batch    1/69   train_loss = 0.855
Epoch 109 Batch    3/69   train_loss = 0.637
Epoch 109 Batch    5/69   train_loss = 0.893
Epoch 109 Batch    7/69   train_loss = 0.812
Epoch 109 Batch    9/69   train_loss = 0.737
Epoch 109 Batch   11/69   train_loss = 0.718
Epoch 109 Batch   13/69   train_loss = 0.788
Epoch 109 Batch   15/69   train_loss = 0.836
Epoch 109 Batch   17/69   train_loss = 0.784
Epoch 109 Batch   19/69   train_loss = 0.677
Epoch 109 Batch   21/69   train_loss = 0.737
Epoch 109 Batch   23/69   train_loss = 0.823
Epoch 109 Batch   25/69   train_loss = 0.876
Epoch 109 Batch   27/69   train_loss = 0.852
Epoch 109 Batch   29/69   train_loss = 0.821
Epoch 109 Batch   31/69   train_loss = 0.855
Epoch 109 Batch   33/69   train_loss = 0.832
Epoch 109 Batch   35/69   train_loss = 0.727
Epoch 109 Batch   37/69   train_loss = 0.662
Epoch 109 Batch   39/69   train_loss = 0.744
Epoch 109 Batch   41/69   train_loss = 0.846
Epoch 109 Batch   43/69   train_loss = 0.757
Epoch 109 Batch   45/69   train_loss = 0.788
Epoch 109 Batch   47/69   train_loss = 0.808
Epoch 109 Batch   49/69   train_loss = 0.731
Epoch 109 Batch   51/69   train_loss = 0.706
Epoch 109 Batch   53/69   train_loss = 0.764
Epoch 109 Batch   55/69   train_loss = 0.725
Epoch 109 Batch   57/69   train_loss = 0.665
Epoch 109 Batch   59/69   train_loss = 0.875
Epoch 109 Batch   61/69   train_loss = 0.752
Epoch 109 Batch   63/69   train_loss = 0.766
Epoch 109 Batch   65/69   train_loss = 0.770
Epoch 109 Batch   67/69   train_loss = 0.777
Epoch 110 Batch    0/69   train_loss = 0.817
Epoch 110 Batch    2/69   train_loss = 0.769
Epoch 110 Batch    4/69   train_loss = 0.777
Epoch 110 Batch    6/69   train_loss = 0.801
Epoch 110 Batch    8/69   train_loss = 0.846
Epoch 110 Batch   10/69   train_loss = 0.819
Epoch 110 Batch   12/69   train_loss = 0.834
Epoch 110 Batch   14/69   train_loss = 0.742
Epoch 110 Batch   16/69   train_loss = 0.744
Epoch 110 Batch   18/69   train_loss = 0.765
Epoch 110 Batch   20/69   train_loss = 0.722
Epoch 110 Batch   22/69   train_loss = 0.730
Epoch 110 Batch   24/69   train_loss = 0.907
Epoch 110 Batch   26/69   train_loss = 0.843
Epoch 110 Batch   28/69   train_loss = 0.837
Epoch 110 Batch   30/69   train_loss = 0.762
Epoch 110 Batch   32/69   train_loss = 0.751
Epoch 110 Batch   34/69   train_loss = 0.651
Epoch 110 Batch   36/69   train_loss = 0.849
Epoch 110 Batch   38/69   train_loss = 0.822
Epoch 110 Batch   40/69   train_loss = 0.761
Epoch 110 Batch   42/69   train_loss = 0.679
Epoch 110 Batch   44/69   train_loss = 0.707
Epoch 110 Batch   46/69   train_loss = 0.829
Epoch 110 Batch   48/69   train_loss = 0.789
Epoch 110 Batch   50/69   train_loss = 0.659
Epoch 110 Batch   52/69   train_loss = 0.735
Epoch 110 Batch   54/69   train_loss = 0.563
Epoch 110 Batch   56/69   train_loss = 0.697
Epoch 110 Batch   58/69   train_loss = 0.700
Epoch 110 Batch   60/69   train_loss = 0.731
Epoch 110 Batch   62/69   train_loss = 0.691
Epoch 110 Batch   64/69   train_loss = 0.712
Epoch 110 Batch   66/69   train_loss = 0.759
Epoch 110 Batch   68/69   train_loss = 0.949
Epoch 111 Batch    1/69   train_loss = 0.805
Epoch 111 Batch    3/69   train_loss = 0.625
Epoch 111 Batch    5/69   train_loss = 0.907
Epoch 111 Batch    7/69   train_loss = 0.809
Epoch 111 Batch    9/69   train_loss = 0.721
Epoch 111 Batch   11/69   train_loss = 0.694
Epoch 111 Batch   13/69   train_loss = 0.771
Epoch 111 Batch   15/69   train_loss = 0.833
Epoch 111 Batch   17/69   train_loss = 0.788
Epoch 111 Batch   19/69   train_loss = 0.677
Epoch 111 Batch   21/69   train_loss = 0.696
Epoch 111 Batch   23/69   train_loss = 0.784
Epoch 111 Batch   25/69   train_loss = 0.860
Epoch 111 Batch   27/69   train_loss = 0.817
Epoch 111 Batch   29/69   train_loss = 0.786
Epoch 111 Batch   31/69   train_loss = 0.812
Epoch 111 Batch   33/69   train_loss = 0.803
Epoch 111 Batch   35/69   train_loss = 0.683
Epoch 111 Batch   37/69   train_loss = 0.626
Epoch 111 Batch   39/69   train_loss = 0.708
Epoch 111 Batch   41/69   train_loss = 0.812
Epoch 111 Batch   43/69   train_loss = 0.726
Epoch 111 Batch   45/69   train_loss = 0.740
Epoch 111 Batch   47/69   train_loss = 0.757
Epoch 111 Batch   49/69   train_loss = 0.694
Epoch 111 Batch   51/69   train_loss = 0.680
Epoch 111 Batch   53/69   train_loss = 0.748
Epoch 111 Batch   55/69   train_loss = 0.703
Epoch 111 Batch   57/69   train_loss = 0.621
Epoch 111 Batch   59/69   train_loss = 0.814
Epoch 111 Batch   61/69   train_loss = 0.716
Epoch 111 Batch   63/69   train_loss = 0.747
Epoch 111 Batch   65/69   train_loss = 0.750
Epoch 111 Batch   67/69   train_loss = 0.763
Epoch 112 Batch    0/69   train_loss = 0.773
Epoch 112 Batch    2/69   train_loss = 0.710
Epoch 112 Batch    4/69   train_loss = 0.738
Epoch 112 Batch    6/69   train_loss = 0.791
Epoch 112 Batch    8/69   train_loss = 0.873
Epoch 112 Batch   10/69   train_loss = 0.828
Epoch 112 Batch   12/69   train_loss = 0.811
Epoch 112 Batch   14/69   train_loss = 0.704
Epoch 112 Batch   16/69   train_loss = 0.699
Epoch 112 Batch   18/69   train_loss = 0.758
Epoch 112 Batch   20/69   train_loss = 0.715
Epoch 112 Batch   22/69   train_loss = 0.717
Epoch 112 Batch   24/69   train_loss = 0.872
Epoch 112 Batch   26/69   train_loss = 0.799
Epoch 112 Batch   28/69   train_loss = 0.809
Epoch 112 Batch   30/69   train_loss = 0.725
Epoch 112 Batch   32/69   train_loss = 0.712
Epoch 112 Batch   34/69   train_loss = 0.620
Epoch 112 Batch   36/69   train_loss = 0.820
Epoch 112 Batch   38/69   train_loss = 0.798
Epoch 112 Batch   40/69   train_loss = 0.721
Epoch 112 Batch   42/69   train_loss = 0.642
Epoch 112 Batch   44/69   train_loss = 0.668
Epoch 112 Batch   46/69   train_loss = 0.778
Epoch 112 Batch   48/69   train_loss = 0.743
Epoch 112 Batch   50/69   train_loss = 0.613
Epoch 112 Batch   52/69   train_loss = 0.698
Epoch 112 Batch   54/69   train_loss = 0.529
Epoch 112 Batch   56/69   train_loss = 0.674
Epoch 112 Batch   58/69   train_loss = 0.663
Epoch 112 Batch   60/69   train_loss = 0.681
Epoch 112 Batch   62/69   train_loss = 0.645
Epoch 112 Batch   64/69   train_loss = 0.687
Epoch 112 Batch   66/69   train_loss = 0.729
Epoch 112 Batch   68/69   train_loss = 0.934
Epoch 113 Batch    1/69   train_loss = 0.773
Epoch 113 Batch    3/69   train_loss = 0.574
Epoch 113 Batch    5/69   train_loss = 0.818
Epoch 113 Batch    7/69   train_loss = 0.747
Epoch 113 Batch    9/69   train_loss = 0.696
Epoch 113 Batch   11/69   train_loss = 0.690
Epoch 113 Batch   13/69   train_loss = 0.747
Epoch 113 Batch   15/69   train_loss = 0.789
Epoch 113 Batch   17/69   train_loss = 0.740
Epoch 113 Batch   19/69   train_loss = 0.632
Epoch 113 Batch   21/69   train_loss = 0.683
Epoch 113 Batch   23/69   train_loss = 0.780
Epoch 113 Batch   25/69   train_loss = 0.855
Epoch 113 Batch   27/69   train_loss = 0.796
Epoch 113 Batch   29/69   train_loss = 0.760
Epoch 113 Batch   31/69   train_loss = 0.783
Epoch 113 Batch   33/69   train_loss = 0.746
Epoch 113 Batch   35/69   train_loss = 0.638
Epoch 113 Batch   37/69   train_loss = 0.594
Epoch 113 Batch   39/69   train_loss = 0.677
Epoch 113 Batch   41/69   train_loss = 0.786
Epoch 113 Batch   43/69   train_loss = 0.681
Epoch 113 Batch   45/69   train_loss = 0.690
Epoch 113 Batch   47/69   train_loss = 0.714
Epoch 113 Batch   49/69   train_loss = 0.652
Epoch 113 Batch   51/69   train_loss = 0.635
Epoch 113 Batch   53/69   train_loss = 0.698
Epoch 113 Batch   55/69   train_loss = 0.663
Epoch 113 Batch   57/69   train_loss = 0.594
Epoch 113 Batch   59/69   train_loss = 0.772
Epoch 113 Batch   61/69   train_loss = 0.683
Epoch 113 Batch   63/69   train_loss = 0.688
Epoch 113 Batch   65/69   train_loss = 0.704
Epoch 113 Batch   67/69   train_loss = 0.726
Epoch 114 Batch    0/69   train_loss = 0.732
Epoch 114 Batch    2/69   train_loss = 0.689
Epoch 114 Batch    4/69   train_loss = 0.711
Epoch 114 Batch    6/69   train_loss = 0.733
Epoch 114 Batch    8/69   train_loss = 0.775
Epoch 114 Batch   10/69   train_loss = 0.755
Epoch 114 Batch   12/69   train_loss = 0.771
Epoch 114 Batch   14/69   train_loss = 0.692
Epoch 114 Batch   16/69   train_loss = 0.688
Epoch 114 Batch   18/69   train_loss = 0.710
Epoch 114 Batch   20/69   train_loss = 0.649
Epoch 114 Batch   22/69   train_loss = 0.677
Epoch 114 Batch   24/69   train_loss = 0.839
Epoch 114 Batch   26/69   train_loss = 0.782
Epoch 114 Batch   28/69   train_loss = 0.785
Epoch 114 Batch   30/69   train_loss = 0.717
Epoch 114 Batch   32/69   train_loss = 0.701
Epoch 114 Batch   34/69   train_loss = 0.592
Epoch 114 Batch   36/69   train_loss = 0.762
Epoch 114 Batch   38/69   train_loss = 0.757
Epoch 114 Batch   40/69   train_loss = 0.700
Epoch 114 Batch   42/69   train_loss = 0.629
Epoch 114 Batch   44/69   train_loss = 0.649
Epoch 114 Batch   46/69   train_loss = 0.733
Epoch 114 Batch   48/69   train_loss = 0.706
Epoch 114 Batch   50/69   train_loss = 0.583
Epoch 114 Batch   52/69   train_loss = 0.665
Epoch 114 Batch   54/69   train_loss = 0.497
Epoch 114 Batch   56/69   train_loss = 0.633
Epoch 114 Batch   58/69   train_loss = 0.616
Epoch 114 Batch   60/69   train_loss = 0.651
Epoch 114 Batch   62/69   train_loss = 0.623
Epoch 114 Batch   64/69   train_loss = 0.658
Epoch 114 Batch   66/69   train_loss = 0.675
Epoch 114 Batch   68/69   train_loss = 0.885
Epoch 115 Batch    1/69   train_loss = 0.738
Epoch 115 Batch    3/69   train_loss = 0.542
Epoch 115 Batch    5/69   train_loss = 0.783
Epoch 115 Batch    7/69   train_loss = 0.720
Epoch 115 Batch    9/69   train_loss = 0.647
Epoch 115 Batch   11/69   train_loss = 0.621
Epoch 115 Batch   13/69   train_loss = 0.682
Epoch 115 Batch   15/69   train_loss = 0.744
Epoch 115 Batch   17/69   train_loss = 0.707
Epoch 115 Batch   19/69   train_loss = 0.604
Epoch 115 Batch   21/69   train_loss = 0.635
Epoch 115 Batch   23/69   train_loss = 0.718
Epoch 115 Batch   25/69   train_loss = 0.790
Epoch 115 Batch   27/69   train_loss = 0.755
Epoch 115 Batch   29/69   train_loss = 0.735
Epoch 115 Batch   31/69   train_loss = 0.768
Epoch 115 Batch   33/69   train_loss = 0.740
Epoch 115 Batch   35/69   train_loss = 0.621
Epoch 115 Batch   37/69   train_loss = 0.557
Epoch 115 Batch   39/69   train_loss = 0.634
Epoch 115 Batch   41/69   train_loss = 0.749
Epoch 115 Batch   43/69   train_loss = 0.680
Epoch 115 Batch   45/69   train_loss = 0.697
Epoch 115 Batch   47/69   train_loss = 0.695
Epoch 115 Batch   49/69   train_loss = 0.618
Epoch 115 Batch   51/69   train_loss = 0.612
Epoch 115 Batch   53/69   train_loss = 0.675
Epoch 115 Batch   55/69   train_loss = 0.631
Epoch 115 Batch   57/69   train_loss = 0.557
Epoch 115 Batch   59/69   train_loss = 0.735
Epoch 115 Batch   61/69   train_loss = 0.646
Epoch 115 Batch   63/69   train_loss = 0.665
Epoch 115 Batch   65/69   train_loss = 0.681
Epoch 115 Batch   67/69   train_loss = 0.693
Epoch 116 Batch    0/69   train_loss = 0.701
Epoch 116 Batch    2/69   train_loss = 0.648
Epoch 116 Batch    4/69   train_loss = 0.689
Epoch 116 Batch    6/69   train_loss = 0.714
Epoch 116 Batch    8/69   train_loss = 0.745
Epoch 116 Batch   10/69   train_loss = 0.713
Epoch 116 Batch   12/69   train_loss = 0.734
Epoch 116 Batch   14/69   train_loss = 0.634
Epoch 116 Batch   16/69   train_loss = 0.631
Epoch 116 Batch   18/69   train_loss = 0.668
Epoch 116 Batch   20/69   train_loss = 0.620
Epoch 116 Batch   22/69   train_loss = 0.626
Epoch 116 Batch   24/69   train_loss = 0.773
Epoch 116 Batch   26/69   train_loss = 0.724
Epoch 116 Batch   28/69   train_loss = 0.728
Epoch 116 Batch   30/69   train_loss = 0.671
Epoch 116 Batch   32/69   train_loss = 0.671
Epoch 116 Batch   34/69   train_loss = 0.572
Epoch 116 Batch   36/69   train_loss = 0.752
Epoch 116 Batch   38/69   train_loss = 0.719
Epoch 116 Batch   40/69   train_loss = 0.648
Epoch 116 Batch   42/69   train_loss = 0.578
Epoch 116 Batch   44/69   train_loss = 0.617
Epoch 116 Batch   46/69   train_loss = 0.726
Epoch 116 Batch   48/69   train_loss = 0.690
Epoch 116 Batch   50/69   train_loss = 0.556
Epoch 116 Batch   52/69   train_loss = 0.640
Epoch 116 Batch   54/69   train_loss = 0.472
Epoch 116 Batch   56/69   train_loss = 0.615
Epoch 116 Batch   58/69   train_loss = 0.604
Epoch 116 Batch   60/69   train_loss = 0.631
Epoch 116 Batch   62/69   train_loss = 0.597
Epoch 116 Batch   64/69   train_loss = 0.636
Epoch 116 Batch   66/69   train_loss = 0.667
Epoch 116 Batch   68/69   train_loss = 0.855
Epoch 117 Batch    1/69   train_loss = 0.705
Epoch 117 Batch    3/69   train_loss = 0.527
Epoch 117 Batch    5/69   train_loss = 0.784
Epoch 117 Batch    7/69   train_loss = 0.688
Epoch 117 Batch    9/69   train_loss = 0.628
Epoch 117 Batch   11/69   train_loss = 0.604
Epoch 117 Batch   13/69   train_loss = 0.663
Epoch 117 Batch   15/69   train_loss = 0.724
Epoch 117 Batch   17/69   train_loss = 0.672
Epoch 117 Batch   19/69   train_loss = 0.572
Epoch 117 Batch   21/69   train_loss = 0.603
Epoch 117 Batch   23/69   train_loss = 0.688
Epoch 117 Batch   25/69   train_loss = 0.755
Epoch 117 Batch   27/69   train_loss = 0.700
Epoch 117 Batch   29/69   train_loss = 0.681
Epoch 117 Batch   31/69   train_loss = 0.709
Epoch 117 Batch   33/69   train_loss = 0.698
Epoch 117 Batch   35/69   train_loss = 0.580
Epoch 117 Batch   37/69   train_loss = 0.526
Epoch 117 Batch   39/69   train_loss = 0.605
Epoch 117 Batch   41/69   train_loss = 0.704
Epoch 117 Batch   43/69   train_loss = 0.620
Epoch 117 Batch   45/69   train_loss = 0.653
Epoch 117 Batch   47/69   train_loss = 0.666
Epoch 117 Batch   49/69   train_loss = 0.613
Epoch 117 Batch   51/69   train_loss = 0.598
Epoch 117 Batch   53/69   train_loss = 0.647
Epoch 117 Batch   55/69   train_loss = 0.599
Epoch 117 Batch   57/69   train_loss = 0.538
Epoch 117 Batch   59/69   train_loss = 0.722
Epoch 117 Batch   61/69   train_loss = 0.619
Epoch 117 Batch   63/69   train_loss = 0.638
Epoch 117 Batch   65/69   train_loss = 0.655
Epoch 117 Batch   67/69   train_loss = 0.682
Epoch 118 Batch    0/69   train_loss = 0.691
Epoch 118 Batch    2/69   train_loss = 0.622
Epoch 118 Batch    4/69   train_loss = 0.646
Epoch 118 Batch    6/69   train_loss = 0.692
Epoch 118 Batch    8/69   train_loss = 0.756
Epoch 118 Batch   10/69   train_loss = 0.708
Epoch 118 Batch   12/69   train_loss = 0.709
Epoch 118 Batch   14/69   train_loss = 0.615
Epoch 118 Batch   16/69   train_loss = 0.618
Epoch 118 Batch   18/69   train_loss = 0.655
Epoch 118 Batch   20/69   train_loss = 0.608
Epoch 118 Batch   22/69   train_loss = 0.611
Epoch 118 Batch   24/69   train_loss = 0.745
Epoch 118 Batch   26/69   train_loss = 0.704
Epoch 118 Batch   28/69   train_loss = 0.703
Epoch 118 Batch   30/69   train_loss = 0.632
Epoch 118 Batch   32/69   train_loss = 0.623
Epoch 118 Batch   34/69   train_loss = 0.530
Epoch 118 Batch   36/69   train_loss = 0.712
Epoch 118 Batch   38/69   train_loss = 0.687
Epoch 118 Batch   40/69   train_loss = 0.630
Epoch 118 Batch   42/69   train_loss = 0.555
Epoch 118 Batch   44/69   train_loss = 0.574
Epoch 118 Batch   46/69   train_loss = 0.669
Epoch 118 Batch   48/69   train_loss = 0.647
Epoch 118 Batch   50/69   train_loss = 0.522
Epoch 118 Batch   52/69   train_loss = 0.614
Epoch 118 Batch   54/69   train_loss = 0.453
Epoch 118 Batch   56/69   train_loss = 0.588
Epoch 118 Batch   58/69   train_loss = 0.565
Epoch 118 Batch   60/69   train_loss = 0.592
Epoch 118 Batch   62/69   train_loss = 0.560
Epoch 118 Batch   64/69   train_loss = 0.601
Epoch 118 Batch   66/69   train_loss = 0.638
Epoch 118 Batch   68/69   train_loss = 0.851
Epoch 119 Batch    1/69   train_loss = 0.690
Epoch 119 Batch    3/69   train_loss = 0.502
Epoch 119 Batch    5/69   train_loss = 0.727
Epoch 119 Batch    7/69   train_loss = 0.651
Epoch 119 Batch    9/69   train_loss = 0.617
Epoch 119 Batch   11/69   train_loss = 0.605
Epoch 119 Batch   13/69   train_loss = 0.644
Epoch 119 Batch   15/69   train_loss = 0.699
Epoch 119 Batch   17/69   train_loss = 0.643
Epoch 119 Batch   19/69   train_loss = 0.559
Epoch 119 Batch   21/69   train_loss = 0.609
Epoch 119 Batch   23/69   train_loss = 0.687
Epoch 119 Batch   25/69   train_loss = 0.737
Epoch 119 Batch   27/69   train_loss = 0.677
Epoch 119 Batch   29/69   train_loss = 0.664
Epoch 119 Batch   31/69   train_loss = 0.702
Epoch 119 Batch   33/69   train_loss = 0.668
Epoch 119 Batch   35/69   train_loss = 0.545
Epoch 119 Batch   37/69   train_loss = 0.498
Epoch 119 Batch   39/69   train_loss = 0.581
Epoch 119 Batch   41/69   train_loss = 0.691
Epoch 119 Batch   43/69   train_loss = 0.601
Epoch 119 Batch   45/69   train_loss = 0.624
Epoch 119 Batch   47/69   train_loss = 0.640
Epoch 119 Batch   49/69   train_loss = 0.569
Epoch 119 Batch   51/69   train_loss = 0.556
Epoch 119 Batch   53/69   train_loss = 0.618
Epoch 119 Batch   55/69   train_loss = 0.581
Epoch 119 Batch   57/69   train_loss = 0.518
Epoch 119 Batch   59/69   train_loss = 0.687
Epoch 119 Batch   61/69   train_loss = 0.592
Epoch 119 Batch   63/69   train_loss = 0.598
Epoch 119 Batch   65/69   train_loss = 0.614
Epoch 119 Batch   67/69   train_loss = 0.652
Epoch 120 Batch    0/69   train_loss = 0.659
Epoch 120 Batch    2/69   train_loss = 0.602
Epoch 120 Batch    4/69   train_loss = 0.620
Epoch 120 Batch    6/69   train_loss = 0.641
Epoch 120 Batch    8/69   train_loss = 0.686
Epoch 120 Batch   10/69   train_loss = 0.673
Epoch 120 Batch   12/69   train_loss = 0.695
Epoch 120 Batch   14/69   train_loss = 0.618
Epoch 120 Batch   16/69   train_loss = 0.607
Epoch 120 Batch   18/69   train_loss = 0.625
Epoch 120 Batch   20/69   train_loss = 0.574
Epoch 120 Batch   22/69   train_loss = 0.597
Epoch 120 Batch   24/69   train_loss = 0.752
Epoch 120 Batch   26/69   train_loss = 0.693
Epoch 120 Batch   28/69   train_loss = 0.668
Epoch 120 Batch   30/69   train_loss = 0.614
Epoch 120 Batch   32/69   train_loss = 0.628
Epoch 120 Batch   34/69   train_loss = 0.532
Epoch 120 Batch   36/69   train_loss = 0.698
Epoch 120 Batch   38/69   train_loss = 0.662
Epoch 120 Batch   40/69   train_loss = 0.612
Epoch 120 Batch   42/69   train_loss = 0.541
Epoch 120 Batch   44/69   train_loss = 0.579
Epoch 120 Batch   46/69   train_loss = 0.656
Epoch 120 Batch   48/69   train_loss = 0.622
Epoch 120 Batch   50/69   train_loss = 0.495
Epoch 120 Batch   52/69   train_loss = 0.599
Epoch 120 Batch   54/69   train_loss = 0.436
Epoch 120 Batch   56/69   train_loss = 0.565
Epoch 120 Batch   58/69   train_loss = 0.539
Epoch 120 Batch   60/69   train_loss = 0.576
Epoch 120 Batch   62/69   train_loss = 0.541
Epoch 120 Batch   64/69   train_loss = 0.576
Epoch 120 Batch   66/69   train_loss = 0.595
Epoch 120 Batch   68/69   train_loss = 0.797
Epoch 121 Batch    1/69   train_loss = 0.664
Epoch 121 Batch    3/69   train_loss = 0.486
Epoch 121 Batch    5/69   train_loss = 0.701
Epoch 121 Batch    7/69   train_loss = 0.617
Epoch 121 Batch    9/69   train_loss = 0.571
Epoch 121 Batch   11/69   train_loss = 0.550
Epoch 121 Batch   13/69   train_loss = 0.619
Epoch 121 Batch   15/69   train_loss = 0.688
Epoch 121 Batch   17/69   train_loss = 0.631
Epoch 121 Batch   19/69   train_loss = 0.532
Epoch 121 Batch   21/69   train_loss = 0.567
Epoch 121 Batch   23/69   train_loss = 0.643
Epoch 121 Batch   25/69   train_loss = 0.711
Epoch 121 Batch   27/69   train_loss = 0.678
Epoch 121 Batch   29/69   train_loss = 0.650
Epoch 121 Batch   31/69   train_loss = 0.664
Epoch 121 Batch   33/69   train_loss = 0.648
Epoch 121 Batch   35/69   train_loss = 0.548
Epoch 121 Batch   37/69   train_loss = 0.503
Epoch 121 Batch   39/69   train_loss = 0.575
Epoch 121 Batch   41/69   train_loss = 0.657
Epoch 121 Batch   43/69   train_loss = 0.577
Epoch 121 Batch   45/69   train_loss = 0.612
Epoch 121 Batch   47/69   train_loss = 0.638
Epoch 121 Batch   49/69   train_loss = 0.569
Epoch 121 Batch   51/69   train_loss = 0.536
Epoch 121 Batch   53/69   train_loss = 0.600
Epoch 121 Batch   55/69   train_loss = 0.573
Epoch 121 Batch   57/69   train_loss = 0.510
Epoch 121 Batch   59/69   train_loss = 0.666
Epoch 121 Batch   61/69   train_loss = 0.565
Epoch 121 Batch   63/69   train_loss = 0.585
Epoch 121 Batch   65/69   train_loss = 0.606
Epoch 121 Batch   67/69   train_loss = 0.641
Epoch 122 Batch    0/69   train_loss = 0.630
Epoch 122 Batch    2/69   train_loss = 0.572
Epoch 122 Batch    4/69   train_loss = 0.595
Epoch 122 Batch    6/69   train_loss = 0.622
Epoch 122 Batch    8/69   train_loss = 0.682
Epoch 122 Batch   10/69   train_loss = 0.641
Epoch 122 Batch   12/69   train_loss = 0.648
Epoch 122 Batch   14/69   train_loss = 0.568
Epoch 122 Batch   16/69   train_loss = 0.589
Epoch 122 Batch   18/69   train_loss = 0.621
Epoch 122 Batch   20/69   train_loss = 0.555
Epoch 122 Batch   22/69   train_loss = 0.558
Epoch 122 Batch   24/69   train_loss = 0.690
Epoch 122 Batch   26/69   train_loss = 0.653
Epoch 122 Batch   28/69   train_loss = 0.655
Epoch 122 Batch   30/69   train_loss = 0.588
Epoch 122 Batch   32/69   train_loss = 0.593
Epoch 122 Batch   34/69   train_loss = 0.492
Epoch 122 Batch   36/69   train_loss = 0.660
Epoch 122 Batch   38/69   train_loss = 0.639
Epoch 122 Batch   40/69   train_loss = 0.603
Epoch 122 Batch   42/69   train_loss = 0.517
Epoch 122 Batch   44/69   train_loss = 0.530
Epoch 122 Batch   46/69   train_loss = 0.612
Epoch 122 Batch   48/69   train_loss = 0.604
Epoch 122 Batch   50/69   train_loss = 0.492
Epoch 122 Batch   52/69   train_loss = 0.574
Epoch 122 Batch   54/69   train_loss = 0.403
Epoch 122 Batch   56/69   train_loss = 0.538
Epoch 122 Batch   58/69   train_loss = 0.522
Epoch 122 Batch   60/69   train_loss = 0.564
Epoch 122 Batch   62/69   train_loss = 0.520
Epoch 122 Batch   64/69   train_loss = 0.553
Epoch 122 Batch   66/69   train_loss = 0.570
Epoch 122 Batch   68/69   train_loss = 0.796
Epoch 123 Batch    1/69   train_loss = 0.660
Epoch 123 Batch    3/69   train_loss = 0.462
Epoch 123 Batch    5/69   train_loss = 0.660
Epoch 123 Batch    7/69   train_loss = 0.595
Epoch 123 Batch    9/69   train_loss = 0.566
Epoch 123 Batch   11/69   train_loss = 0.548
Epoch 123 Batch   13/69   train_loss = 0.587
Epoch 123 Batch   15/69   train_loss = 0.648
Epoch 123 Batch   17/69   train_loss = 0.609
Epoch 123 Batch   19/69   train_loss = 0.529
Epoch 123 Batch   21/69   train_loss = 0.587
Epoch 123 Batch   23/69   train_loss = 0.645
Epoch 123 Batch   25/69   train_loss = 0.688
Epoch 123 Batch   27/69   train_loss = 0.631
Epoch 123 Batch   29/69   train_loss = 0.620
Epoch 123 Batch   31/69   train_loss = 0.664
Epoch 123 Batch   33/69   train_loss = 0.633
Epoch 123 Batch   35/69   train_loss = 0.509
Epoch 123 Batch   37/69   train_loss = 0.466
Epoch 123 Batch   39/69   train_loss = 0.551
Epoch 123 Batch   41/69   train_loss = 0.636
Epoch 123 Batch   43/69   train_loss = 0.561
Epoch 123 Batch   45/69   train_loss = 0.581
Epoch 123 Batch   47/69   train_loss = 0.579
Epoch 123 Batch   49/69   train_loss = 0.520
Epoch 123 Batch   51/69   train_loss = 0.519
Epoch 123 Batch   53/69   train_loss = 0.573
Epoch 123 Batch   55/69   train_loss = 0.538
Epoch 123 Batch   57/69   train_loss = 0.471
Epoch 123 Batch   59/69   train_loss = 0.632
Epoch 123 Batch   61/69   train_loss = 0.544
Epoch 123 Batch   63/69   train_loss = 0.569
Epoch 123 Batch   65/69   train_loss = 0.559
Epoch 123 Batch   67/69   train_loss = 0.591
Epoch 124 Batch    0/69   train_loss = 0.593
Epoch 124 Batch    2/69   train_loss = 0.563
Epoch 124 Batch    4/69   train_loss = 0.587
Epoch 124 Batch    6/69   train_loss = 0.590
Epoch 124 Batch    8/69   train_loss = 0.632
Epoch 124 Batch   10/69   train_loss = 0.601
Epoch 124 Batch   12/69   train_loss = 0.629
Epoch 124 Batch   14/69   train_loss = 0.567
Epoch 124 Batch   16/69   train_loss = 0.570
Epoch 124 Batch   18/69   train_loss = 0.592
Epoch 124 Batch   20/69   train_loss = 0.535
Epoch 124 Batch   22/69   train_loss = 0.557
Epoch 124 Batch   24/69   train_loss = 0.705
Epoch 124 Batch   26/69   train_loss = 0.655
Epoch 124 Batch   28/69   train_loss = 0.622
Epoch 124 Batch   30/69   train_loss = 0.556
Epoch 124 Batch   32/69   train_loss = 0.586
Epoch 124 Batch   34/69   train_loss = 0.500
Epoch 124 Batch   36/69   train_loss = 0.668
Epoch 124 Batch   38/69   train_loss = 0.634
Epoch 124 Batch   40/69   train_loss = 0.578
Epoch 124 Batch   42/69   train_loss = 0.500
Epoch 124 Batch   44/69   train_loss = 0.526
Epoch 124 Batch   46/69   train_loss = 0.593
Epoch 124 Batch   48/69   train_loss = 0.571
Epoch 124 Batch   50/69   train_loss = 0.465
Epoch 124 Batch   52/69   train_loss = 0.541
Epoch 124 Batch   54/69   train_loss = 0.392
Epoch 124 Batch   56/69   train_loss = 0.516
Epoch 124 Batch   58/69   train_loss = 0.482
Epoch 124 Batch   60/69   train_loss = 0.518
Epoch 124 Batch   62/69   train_loss = 0.483
Epoch 124 Batch   64/69   train_loss = 0.519
Epoch 124 Batch   66/69   train_loss = 0.535
Epoch 124 Batch   68/69   train_loss = 0.740
Epoch 125 Batch    1/69   train_loss = 0.598
Epoch 125 Batch    3/69   train_loss = 0.432
Epoch 125 Batch    5/69   train_loss = 0.647
Epoch 125 Batch    7/69   train_loss = 0.582
Epoch 125 Batch    9/69   train_loss = 0.527
Epoch 125 Batch   11/69   train_loss = 0.494
Epoch 125 Batch   13/69   train_loss = 0.543
Epoch 125 Batch   15/69   train_loss = 0.621
Epoch 125 Batch   17/69   train_loss = 0.587
Epoch 125 Batch   19/69   train_loss = 0.493
Epoch 125 Batch   21/69   train_loss = 0.532
Epoch 125 Batch   23/69   train_loss = 0.596
Epoch 125 Batch   25/69   train_loss = 0.671
Epoch 125 Batch   27/69   train_loss = 0.622
Epoch 125 Batch   29/69   train_loss = 0.608
Epoch 125 Batch   31/69   train_loss = 0.625
Epoch 125 Batch   33/69   train_loss = 0.604
Epoch 125 Batch   35/69   train_loss = 0.509
Epoch 125 Batch   37/69   train_loss = 0.476
Epoch 125 Batch   39/69   train_loss = 0.567
Epoch 125 Batch   41/69   train_loss = 0.649
Epoch 125 Batch   43/69   train_loss = 0.550
Epoch 125 Batch   45/69   train_loss = 0.566
Epoch 125 Batch   47/69   train_loss = 0.592
Epoch 125 Batch   49/69   train_loss = 0.528
Epoch 125 Batch   51/69   train_loss = 0.517
Epoch 125 Batch   53/69   train_loss = 0.559
Epoch 125 Batch   55/69   train_loss = 0.519
Epoch 125 Batch   57/69   train_loss = 0.468
Epoch 125 Batch   59/69   train_loss = 0.629
Epoch 125 Batch   61/69   train_loss = 0.527
Epoch 125 Batch   63/69   train_loss = 0.536
Epoch 125 Batch   65/69   train_loss = 0.528
Epoch 125 Batch   67/69   train_loss = 0.570
Epoch 126 Batch    0/69   train_loss = 0.565
Epoch 126 Batch    2/69   train_loss = 0.523
Epoch 126 Batch    4/69   train_loss = 0.548
Epoch 126 Batch    6/69   train_loss = 0.558
Epoch 126 Batch    8/69   train_loss = 0.612
Epoch 126 Batch   10/69   train_loss = 0.585
Epoch 126 Batch   12/69   train_loss = 0.588
Epoch 126 Batch   14/69   train_loss = 0.512
Epoch 126 Batch   16/69   train_loss = 0.515
Epoch 126 Batch   18/69   train_loss = 0.557
Epoch 126 Batch   20/69   train_loss = 0.504
Epoch 126 Batch   22/69   train_loss = 0.529
Epoch 126 Batch   24/69   train_loss = 0.646
Epoch 126 Batch   26/69   train_loss = 0.604
Epoch 126 Batch   28/69   train_loss = 0.597
Epoch 126 Batch   30/69   train_loss = 0.530
Epoch 126 Batch   32/69   train_loss = 0.543
Epoch 126 Batch   34/69   train_loss = 0.455
Epoch 126 Batch   36/69   train_loss = 0.618
Epoch 126 Batch   38/69   train_loss = 0.616
Epoch 126 Batch   40/69   train_loss = 0.591
Epoch 126 Batch   42/69   train_loss = 0.517
Epoch 126 Batch   44/69   train_loss = 0.509
Epoch 126 Batch   46/69   train_loss = 0.566
Epoch 126 Batch   48/69   train_loss = 0.557
Epoch 126 Batch   50/69   train_loss = 0.469
Epoch 126 Batch   52/69   train_loss = 0.564
Epoch 126 Batch   54/69   train_loss = 0.407
Epoch 126 Batch   56/69   train_loss = 0.520
Epoch 126 Batch   58/69   train_loss = 0.479
Epoch 126 Batch   60/69   train_loss = 0.527
Epoch 126 Batch   62/69   train_loss = 0.496
Epoch 126 Batch   64/69   train_loss = 0.531
Epoch 126 Batch   66/69   train_loss = 0.535
Epoch 126 Batch   68/69   train_loss = 0.723
Epoch 127 Batch    1/69   train_loss = 0.575
Epoch 127 Batch    3/69   train_loss = 0.410
Epoch 127 Batch    5/69   train_loss = 0.608
Epoch 127 Batch    7/69   train_loss = 0.559
Epoch 127 Batch    9/69   train_loss = 0.500
Epoch 127 Batch   11/69   train_loss = 0.474
Epoch 127 Batch   13/69   train_loss = 0.535
Epoch 127 Batch   15/69   train_loss = 0.591
Epoch 127 Batch   17/69   train_loss = 0.553
Epoch 127 Batch   19/69   train_loss = 0.465
Epoch 127 Batch   21/69   train_loss = 0.507
Epoch 127 Batch   23/69   train_loss = 0.579
Epoch 127 Batch   25/69   train_loss = 0.639
Epoch 127 Batch   27/69   train_loss = 0.569
Epoch 127 Batch   29/69   train_loss = 0.566
Epoch 127 Batch   31/69   train_loss = 0.587
Epoch 127 Batch   33/69   train_loss = 0.574
Epoch 127 Batch   35/69   train_loss = 0.467
Epoch 127 Batch   37/69   train_loss = 0.429
Epoch 127 Batch   39/69   train_loss = 0.507
Epoch 127 Batch   41/69   train_loss = 0.616
Epoch 127 Batch   43/69   train_loss = 0.537
Epoch 127 Batch   45/69   train_loss = 0.554
Epoch 127 Batch   47/69   train_loss = 0.552
Epoch 127 Batch   49/69   train_loss = 0.483
Epoch 127 Batch   51/69   train_loss = 0.491
Epoch 127 Batch   53/69   train_loss = 0.549
Epoch 127 Batch   55/69   train_loss = 0.533
Epoch 127 Batch   57/69   train_loss = 0.474
Epoch 127 Batch   59/69   train_loss = 0.611
Epoch 127 Batch   61/69   train_loss = 0.527
Epoch 127 Batch   63/69   train_loss = 0.531
Epoch 127 Batch   65/69   train_loss = 0.534
Epoch 127 Batch   67/69   train_loss = 0.587
Epoch 128 Batch    0/69   train_loss = 0.558
Epoch 128 Batch    2/69   train_loss = 0.521
Epoch 128 Batch    4/69   train_loss = 0.540
Epoch 128 Batch    6/69   train_loss = 0.549
Epoch 128 Batch    8/69   train_loss = 0.594
Epoch 128 Batch   10/69   train_loss = 0.558
Epoch 128 Batch   12/69   train_loss = 0.569
Epoch 128 Batch   14/69   train_loss = 0.504
Epoch 128 Batch   16/69   train_loss = 0.509
Epoch 128 Batch   18/69   train_loss = 0.549
Epoch 128 Batch   20/69   train_loss = 0.492
Epoch 128 Batch   22/69   train_loss = 0.499
Epoch 128 Batch   24/69   train_loss = 0.622
Epoch 128 Batch   26/69   train_loss = 0.584
Epoch 128 Batch   28/69   train_loss = 0.580
Epoch 128 Batch   30/69   train_loss = 0.499
Epoch 128 Batch   32/69   train_loss = 0.515
Epoch 128 Batch   34/69   train_loss = 0.419
Epoch 128 Batch   36/69   train_loss = 0.589
Epoch 128 Batch   38/69   train_loss = 0.574
Epoch 128 Batch   40/69   train_loss = 0.540
Epoch 128 Batch   42/69   train_loss = 0.476
Epoch 128 Batch   44/69   train_loss = 0.478
Epoch 128 Batch   46/69   train_loss = 0.555
Epoch 128 Batch   48/69   train_loss = 0.526
Epoch 128 Batch   50/69   train_loss = 0.428
Epoch 128 Batch   52/69   train_loss = 0.495
Epoch 128 Batch   54/69   train_loss = 0.357
Epoch 128 Batch   56/69   train_loss = 0.498
Epoch 128 Batch   58/69   train_loss = 0.469
Epoch 128 Batch   60/69   train_loss = 0.520
Epoch 128 Batch   62/69   train_loss = 0.475
Epoch 128 Batch   64/69   train_loss = 0.508
Epoch 128 Batch   66/69   train_loss = 0.508
Epoch 128 Batch   68/69   train_loss = 0.701
Epoch 129 Batch    1/69   train_loss = 0.579
Epoch 129 Batch    3/69   train_loss = 0.398
Epoch 129 Batch    5/69   train_loss = 0.603
Epoch 129 Batch    7/69   train_loss = 0.560
Epoch 129 Batch    9/69   train_loss = 0.505
Epoch 129 Batch   11/69   train_loss = 0.462
Epoch 129 Batch   13/69   train_loss = 0.509
Epoch 129 Batch   15/69   train_loss = 0.567
Epoch 129 Batch   17/69   train_loss = 0.535
Epoch 129 Batch   19/69   train_loss = 0.460
Epoch 129 Batch   21/69   train_loss = 0.497
Epoch 129 Batch   23/69   train_loss = 0.577
Epoch 129 Batch   25/69   train_loss = 0.617
Epoch 129 Batch   27/69   train_loss = 0.553
Epoch 129 Batch   29/69   train_loss = 0.556
Epoch 129 Batch   31/69   train_loss = 0.595
Epoch 129 Batch   33/69   train_loss = 0.569
Epoch 129 Batch   35/69   train_loss = 0.435
Epoch 129 Batch   37/69   train_loss = 0.393
Epoch 129 Batch   39/69   train_loss = 0.482
Epoch 129 Batch   41/69   train_loss = 0.593
Epoch 129 Batch   43/69   train_loss = 0.520
Epoch 129 Batch   45/69   train_loss = 0.528
Epoch 129 Batch   47/69   train_loss = 0.529
Epoch 129 Batch   49/69   train_loss = 0.450
Epoch 129 Batch   51/69   train_loss = 0.465
Epoch 129 Batch   53/69   train_loss = 0.518
Epoch 129 Batch   55/69   train_loss = 0.486
Epoch 129 Batch   57/69   train_loss = 0.431
Epoch 129 Batch   59/69   train_loss = 0.563
Epoch 129 Batch   61/69   train_loss = 0.500
Epoch 129 Batch   63/69   train_loss = 0.508
Epoch 129 Batch   65/69   train_loss = 0.500
Epoch 129 Batch   67/69   train_loss = 0.540
Epoch 130 Batch    0/69   train_loss = 0.536
Epoch 130 Batch    2/69   train_loss = 0.481
Epoch 130 Batch    4/69   train_loss = 0.512
Epoch 130 Batch    6/69   train_loss = 0.518
Epoch 130 Batch    8/69   train_loss = 0.566
Epoch 130 Batch   10/69   train_loss = 0.557
Epoch 130 Batch   12/69   train_loss = 0.563
Epoch 130 Batch   14/69   train_loss = 0.474
Epoch 130 Batch   16/69   train_loss = 0.467
Epoch 130 Batch   18/69   train_loss = 0.504
Epoch 130 Batch   20/69   train_loss = 0.459
Epoch 130 Batch   22/69   train_loss = 0.487
Epoch 130 Batch   24/69   train_loss = 0.615
Epoch 130 Batch   26/69   train_loss = 0.570
Epoch 130 Batch   28/69   train_loss = 0.551
Epoch 130 Batch   30/69   train_loss = 0.477
Epoch 130 Batch   32/69   train_loss = 0.502
Epoch 130 Batch   34/69   train_loss = 0.433
Epoch 130 Batch   36/69   train_loss = 0.584
Epoch 130 Batch   38/69   train_loss = 0.552
Epoch 130 Batch   40/69   train_loss = 0.506
Epoch 130 Batch   42/69   train_loss = 0.447
Epoch 130 Batch   44/69   train_loss = 0.461
Epoch 130 Batch   46/69   train_loss = 0.543
Epoch 130 Batch   48/69   train_loss = 0.509
Epoch 130 Batch   50/69   train_loss = 0.409
Epoch 130 Batch   52/69   train_loss = 0.465
Epoch 130 Batch   54/69   train_loss = 0.339
Epoch 130 Batch   56/69   train_loss = 0.492
Epoch 130 Batch   58/69   train_loss = 0.450
Epoch 130 Batch   60/69   train_loss = 0.485
Epoch 130 Batch   62/69   train_loss = 0.441
Epoch 130 Batch   64/69   train_loss = 0.459
Epoch 130 Batch   66/69   train_loss = 0.483
Epoch 130 Batch   68/69   train_loss = 0.680
Epoch 131 Batch    1/69   train_loss = 0.554
Epoch 131 Batch    3/69   train_loss = 0.378
Epoch 131 Batch    5/69   train_loss = 0.559
Epoch 131 Batch    7/69   train_loss = 0.517
Epoch 131 Batch    9/69   train_loss = 0.468
Epoch 131 Batch   11/69   train_loss = 0.431
Epoch 131 Batch   13/69   train_loss = 0.496
Epoch 131 Batch   15/69   train_loss = 0.537
Epoch 131 Batch   17/69   train_loss = 0.506
Epoch 131 Batch   19/69   train_loss = 0.423
Epoch 131 Batch   21/69   train_loss = 0.447
Epoch 131 Batch   23/69   train_loss = 0.538
Epoch 131 Batch   25/69   train_loss = 0.594
Epoch 131 Batch   27/69   train_loss = 0.534
Epoch 131 Batch   29/69   train_loss = 0.515
Epoch 131 Batch   31/69   train_loss = 0.533
Epoch 131 Batch   33/69   train_loss = 0.522
Epoch 131 Batch   35/69   train_loss = 0.419
Epoch 131 Batch   37/69   train_loss = 0.387
Epoch 131 Batch   39/69   train_loss = 0.456
Epoch 131 Batch   41/69   train_loss = 0.559
Epoch 131 Batch   43/69   train_loss = 0.483
Epoch 131 Batch   45/69   train_loss = 0.497
Epoch 131 Batch   47/69   train_loss = 0.520
Epoch 131 Batch   49/69   train_loss = 0.448
Epoch 131 Batch   51/69   train_loss = 0.450
Epoch 131 Batch   53/69   train_loss = 0.482
Epoch 131 Batch   55/69   train_loss = 0.452
Epoch 131 Batch   57/69   train_loss = 0.411
Epoch 131 Batch   59/69   train_loss = 0.564
Epoch 131 Batch   61/69   train_loss = 0.500
Epoch 131 Batch   63/69   train_loss = 0.491
Epoch 131 Batch   65/69   train_loss = 0.469
Epoch 131 Batch   67/69   train_loss = 0.506
Epoch 132 Batch    0/69   train_loss = 0.507
Epoch 132 Batch    2/69   train_loss = 0.465
Epoch 132 Batch    4/69   train_loss = 0.497
Epoch 132 Batch    6/69   train_loss = 0.505
Epoch 132 Batch    8/69   train_loss = 0.529
Epoch 132 Batch   10/69   train_loss = 0.517
Epoch 132 Batch   12/69   train_loss = 0.528
Epoch 132 Batch   14/69   train_loss = 0.449
Epoch 132 Batch   16/69   train_loss = 0.441
Epoch 132 Batch   18/69   train_loss = 0.473
Epoch 132 Batch   20/69   train_loss = 0.428
Epoch 132 Batch   22/69   train_loss = 0.444
Epoch 132 Batch   24/69   train_loss = 0.561
Epoch 132 Batch   26/69   train_loss = 0.532
Epoch 132 Batch   28/69   train_loss = 0.523
Epoch 132 Batch   30/69   train_loss = 0.452
Epoch 132 Batch   32/69   train_loss = 0.454
Epoch 132 Batch   34/69   train_loss = 0.378
Epoch 132 Batch   36/69   train_loss = 0.536
Epoch 132 Batch   38/69   train_loss = 0.526
Epoch 132 Batch   40/69   train_loss = 0.489
Epoch 132 Batch   42/69   train_loss = 0.427
Epoch 132 Batch   44/69   train_loss = 0.430
Epoch 132 Batch   46/69   train_loss = 0.491
Epoch 132 Batch   48/69   train_loss = 0.477
Epoch 132 Batch   50/69   train_loss = 0.394
Epoch 132 Batch   52/69   train_loss = 0.447
Epoch 132 Batch   54/69   train_loss = 0.312
Epoch 132 Batch   56/69   train_loss = 0.433
Epoch 132 Batch   58/69   train_loss = 0.404
Epoch 132 Batch   60/69   train_loss = 0.463
Epoch 132 Batch   62/69   train_loss = 0.442
Epoch 132 Batch   64/69   train_loss = 0.462
Epoch 132 Batch   66/69   train_loss = 0.459
Epoch 132 Batch   68/69   train_loss = 0.629
Epoch 133 Batch    1/69   train_loss = 0.507
Epoch 133 Batch    3/69   train_loss = 0.362
Epoch 133 Batch    5/69   train_loss = 0.563
Epoch 133 Batch    7/69   train_loss = 0.510
Epoch 133 Batch    9/69   train_loss = 0.454
Epoch 133 Batch   11/69   train_loss = 0.413
Epoch 133 Batch   13/69   train_loss = 0.467
Epoch 133 Batch   15/69   train_loss = 0.515
Epoch 133 Batch   17/69   train_loss = 0.488
Epoch 133 Batch   19/69   train_loss = 0.407
Epoch 133 Batch   21/69   train_loss = 0.429
Epoch 133 Batch   23/69   train_loss = 0.498
Epoch 133 Batch   25/69   train_loss = 0.560
Epoch 133 Batch   27/69   train_loss = 0.508
Epoch 133 Batch   29/69   train_loss = 0.489
Epoch 133 Batch   31/69   train_loss = 0.511
Epoch 133 Batch   33/69   train_loss = 0.496
Epoch 133 Batch   35/69   train_loss = 0.391
Epoch 133 Batch   37/69   train_loss = 0.353
Epoch 133 Batch   39/69   train_loss = 0.426
Epoch 133 Batch   41/69   train_loss = 0.530
Epoch 133 Batch   43/69   train_loss = 0.463
Epoch 133 Batch   45/69   train_loss = 0.469
Epoch 133 Batch   47/69   train_loss = 0.480
Epoch 133 Batch   49/69   train_loss = 0.404
Epoch 133 Batch   51/69   train_loss = 0.415
Epoch 133 Batch   53/69   train_loss = 0.453
Epoch 133 Batch   55/69   train_loss = 0.425
Epoch 133 Batch   57/69   train_loss = 0.370
Epoch 133 Batch   59/69   train_loss = 0.506
Epoch 133 Batch   61/69   train_loss = 0.448
Epoch 133 Batch   63/69   train_loss = 0.461
Epoch 133 Batch   65/69   train_loss = 0.467
Epoch 133 Batch   67/69   train_loss = 0.504
Epoch 134 Batch    0/69   train_loss = 0.481
Epoch 134 Batch    2/69   train_loss = 0.426
Epoch 134 Batch    4/69   train_loss = 0.464
Epoch 134 Batch    6/69   train_loss = 0.481
Epoch 134 Batch    8/69   train_loss = 0.539
Epoch 134 Batch   10/69   train_loss = 0.518
Epoch 134 Batch   12/69   train_loss = 0.515
Epoch 134 Batch   14/69   train_loss = 0.430
Epoch 134 Batch   16/69   train_loss = 0.418
Epoch 134 Batch   18/69   train_loss = 0.475
Epoch 134 Batch   20/69   train_loss = 0.416
Epoch 134 Batch   22/69   train_loss = 0.443
Epoch 134 Batch   24/69   train_loss = 0.530
Epoch 134 Batch   26/69   train_loss = 0.504
Epoch 134 Batch   28/69   train_loss = 0.496
Epoch 134 Batch   30/69   train_loss = 0.433
Epoch 134 Batch   32/69   train_loss = 0.438
Epoch 134 Batch   34/69   train_loss = 0.362
Epoch 134 Batch   36/69   train_loss = 0.506
Epoch 134 Batch   38/69   train_loss = 0.495
Epoch 134 Batch   40/69   train_loss = 0.458
Epoch 134 Batch   42/69   train_loss = 0.409
Epoch 134 Batch   44/69   train_loss = 0.420
Epoch 134 Batch   46/69   train_loss = 0.474
Epoch 134 Batch   48/69   train_loss = 0.449
Epoch 134 Batch   50/69   train_loss = 0.371
Epoch 134 Batch   52/69   train_loss = 0.422
Epoch 134 Batch   54/69   train_loss = 0.291
Epoch 134 Batch   56/69   train_loss = 0.410
Epoch 134 Batch   58/69   train_loss = 0.378
Epoch 134 Batch   60/69   train_loss = 0.423
Epoch 134 Batch   62/69   train_loss = 0.400
Epoch 134 Batch   64/69   train_loss = 0.417
Epoch 134 Batch   66/69   train_loss = 0.442
Epoch 134 Batch   68/69   train_loss = 0.615
Epoch 135 Batch    1/69   train_loss = 0.486
Epoch 135 Batch    3/69   train_loss = 0.334
Epoch 135 Batch    5/69   train_loss = 0.501
Epoch 135 Batch    7/69   train_loss = 0.467
Epoch 135 Batch    9/69   train_loss = 0.444
Epoch 135 Batch   11/69   train_loss = 0.415
Epoch 135 Batch   13/69   train_loss = 0.459
Epoch 135 Batch   15/69   train_loss = 0.491
Epoch 135 Batch   17/69   train_loss = 0.462
Epoch 135 Batch   19/69   train_loss = 0.387
Epoch 135 Batch   21/69   train_loss = 0.415
Epoch 135 Batch   23/69   train_loss = 0.496
Epoch 135 Batch   25/69   train_loss = 0.547
Epoch 135 Batch   27/69   train_loss = 0.470
Epoch 135 Batch   29/69   train_loss = 0.456
Epoch 135 Batch   31/69   train_loss = 0.491
Epoch 135 Batch   33/69   train_loss = 0.477
Epoch 135 Batch   35/69   train_loss = 0.375
Epoch 135 Batch   37/69   train_loss = 0.340
Epoch 135 Batch   39/69   train_loss = 0.392
Epoch 135 Batch   41/69   train_loss = 0.499
Epoch 135 Batch   43/69   train_loss = 0.437
Epoch 135 Batch   45/69   train_loss = 0.448
Epoch 135 Batch   47/69   train_loss = 0.459
Epoch 135 Batch   49/69   train_loss = 0.390
Epoch 135 Batch   51/69   train_loss = 0.407
Epoch 135 Batch   53/69   train_loss = 0.438
Epoch 135 Batch   55/69   train_loss = 0.414
Epoch 135 Batch   57/69   train_loss = 0.362
Epoch 135 Batch   59/69   train_loss = 0.484
Epoch 135 Batch   61/69   train_loss = 0.430
Epoch 135 Batch   63/69   train_loss = 0.435
Epoch 135 Batch   65/69   train_loss = 0.438
Epoch 135 Batch   67/69   train_loss = 0.483
Epoch 136 Batch    0/69   train_loss = 0.462
Epoch 136 Batch    2/69   train_loss = 0.414
Epoch 136 Batch    4/69   train_loss = 0.434
Epoch 136 Batch    6/69   train_loss = 0.439
Epoch 136 Batch    8/69   train_loss = 0.488
Epoch 136 Batch   10/69   train_loss = 0.479
Epoch 136 Batch   12/69   train_loss = 0.487
Epoch 136 Batch   14/69   train_loss = 0.428
Epoch 136 Batch   16/69   train_loss = 0.407
Epoch 136 Batch   18/69   train_loss = 0.441
Epoch 136 Batch   20/69   train_loss = 0.386
Epoch 136 Batch   22/69   train_loss = 0.413
Epoch 136 Batch   24/69   train_loss = 0.513
Epoch 136 Batch   26/69   train_loss = 0.498
Epoch 136 Batch   28/69   train_loss = 0.477
Epoch 136 Batch   30/69   train_loss = 0.397
Epoch 136 Batch   32/69   train_loss = 0.409
Epoch 136 Batch   34/69   train_loss = 0.337
Epoch 136 Batch   36/69   train_loss = 0.485
Epoch 136 Batch   38/69   train_loss = 0.467
Epoch 136 Batch   40/69   train_loss = 0.431
Epoch 136 Batch   42/69   train_loss = 0.382
Epoch 136 Batch   44/69   train_loss = 0.390
Epoch 136 Batch   46/69   train_loss = 0.450
Epoch 136 Batch   48/69   train_loss = 0.433
Epoch 136 Batch   50/69   train_loss = 0.352
Epoch 136 Batch   52/69   train_loss = 0.404
Epoch 136 Batch   54/69   train_loss = 0.283
Epoch 136 Batch   56/69   train_loss = 0.397
Epoch 136 Batch   58/69   train_loss = 0.359
Epoch 136 Batch   60/69   train_loss = 0.405
Epoch 136 Batch   62/69   train_loss = 0.375
Epoch 136 Batch   64/69   train_loss = 0.405
Epoch 136 Batch   66/69   train_loss = 0.431
Epoch 136 Batch   68/69   train_loss = 0.591
Epoch 137 Batch    1/69   train_loss = 0.470
Epoch 137 Batch    3/69   train_loss = 0.325
Epoch 137 Batch    5/69   train_loss = 0.495
Epoch 137 Batch    7/69   train_loss = 0.448
Epoch 137 Batch    9/69   train_loss = 0.403
Epoch 137 Batch   11/69   train_loss = 0.385
Epoch 137 Batch   13/69   train_loss = 0.434
Epoch 137 Batch   15/69   train_loss = 0.476
Epoch 137 Batch   17/69   train_loss = 0.456
Epoch 137 Batch   19/69   train_loss = 0.369
Epoch 137 Batch   21/69   train_loss = 0.388
Epoch 137 Batch   23/69   train_loss = 0.458
Epoch 137 Batch   25/69   train_loss = 0.527
Epoch 137 Batch   27/69   train_loss = 0.452
Epoch 137 Batch   29/69   train_loss = 0.453
Epoch 137 Batch   31/69   train_loss = 0.471
Epoch 137 Batch   33/69   train_loss = 0.445
Epoch 137 Batch   35/69   train_loss = 0.345
Epoch 137 Batch   37/69   train_loss = 0.311
Epoch 137 Batch   39/69   train_loss = 0.378
Epoch 137 Batch   41/69   train_loss = 0.472
Epoch 137 Batch   43/69   train_loss = 0.401
Epoch 137 Batch   45/69   train_loss = 0.414
Epoch 137 Batch   47/69   train_loss = 0.438
Epoch 137 Batch   49/69   train_loss = 0.366
Epoch 137 Batch   51/69   train_loss = 0.384
Epoch 137 Batch   53/69   train_loss = 0.409
Epoch 137 Batch   55/69   train_loss = 0.385
Epoch 137 Batch   57/69   train_loss = 0.342
Epoch 137 Batch   59/69   train_loss = 0.462
Epoch 137 Batch   61/69   train_loss = 0.403
Epoch 137 Batch   63/69   train_loss = 0.411
Epoch 137 Batch   65/69   train_loss = 0.406
Epoch 137 Batch   67/69   train_loss = 0.459
Epoch 138 Batch    0/69   train_loss = 0.442
Epoch 138 Batch    2/69   train_loss = 0.390
Epoch 138 Batch    4/69   train_loss = 0.417
Epoch 138 Batch    6/69   train_loss = 0.418
Epoch 138 Batch    8/69   train_loss = 0.465
Epoch 138 Batch   10/69   train_loss = 0.458
Epoch 138 Batch   12/69   train_loss = 0.456
Epoch 138 Batch   14/69   train_loss = 0.396
Epoch 138 Batch   16/69   train_loss = 0.392
Epoch 138 Batch   18/69   train_loss = 0.423
Epoch 138 Batch   20/69   train_loss = 0.373
Epoch 138 Batch   22/69   train_loss = 0.400
Epoch 138 Batch   24/69   train_loss = 0.488
Epoch 138 Batch   26/69   train_loss = 0.470
Epoch 138 Batch   28/69   train_loss = 0.462
Epoch 138 Batch   30/69   train_loss = 0.380
Epoch 138 Batch   32/69   train_loss = 0.391
Epoch 138 Batch   34/69   train_loss = 0.321
Epoch 138 Batch   36/69   train_loss = 0.449
Epoch 138 Batch   38/69   train_loss = 0.445
Epoch 138 Batch   40/69   train_loss = 0.406
Epoch 138 Batch   42/69   train_loss = 0.364
Epoch 138 Batch   44/69   train_loss = 0.369
Epoch 138 Batch   46/69   train_loss = 0.420
Epoch 138 Batch   48/69   train_loss = 0.406
Epoch 138 Batch   50/69   train_loss = 0.327
Epoch 138 Batch   52/69   train_loss = 0.387
Epoch 138 Batch   54/69   train_loss = 0.270
Epoch 138 Batch   56/69   train_loss = 0.381
Epoch 138 Batch   58/69   train_loss = 0.338
Epoch 138 Batch   60/69   train_loss = 0.372
Epoch 138 Batch   62/69   train_loss = 0.354
Epoch 138 Batch   64/69   train_loss = 0.380
Epoch 138 Batch   66/69   train_loss = 0.398
Epoch 138 Batch   68/69   train_loss = 0.564
Epoch 139 Batch    1/69   train_loss = 0.446
Epoch 139 Batch    3/69   train_loss = 0.307
Epoch 139 Batch    5/69   train_loss = 0.458
Epoch 139 Batch    7/69   train_loss = 0.432
Epoch 139 Batch    9/69   train_loss = 0.379
Epoch 139 Batch   11/69   train_loss = 0.361
Epoch 139 Batch   13/69   train_loss = 0.405
Epoch 139 Batch   15/69   train_loss = 0.447
Epoch 139 Batch   17/69   train_loss = 0.428
Epoch 139 Batch   19/69   train_loss = 0.347
Epoch 139 Batch   21/69   train_loss = 0.369
Epoch 139 Batch   23/69   train_loss = 0.440
Epoch 139 Batch   25/69   train_loss = 0.510
Epoch 139 Batch   27/69   train_loss = 0.433
Epoch 139 Batch   29/69   train_loss = 0.425
Epoch 139 Batch   31/69   train_loss = 0.457
Epoch 139 Batch   33/69   train_loss = 0.435
Epoch 139 Batch   35/69   train_loss = 0.329
Epoch 139 Batch   37/69   train_loss = 0.298
Epoch 139 Batch   39/69   train_loss = 0.353
Epoch 139 Batch   41/69   train_loss = 0.447
Epoch 139 Batch   43/69   train_loss = 0.380
Epoch 139 Batch   45/69   train_loss = 0.402
Epoch 139 Batch   47/69   train_loss = 0.417
Epoch 139 Batch   49/69   train_loss = 0.344
Epoch 139 Batch   51/69   train_loss = 0.362
Epoch 139 Batch   53/69   train_loss = 0.390
Epoch 139 Batch   55/69   train_loss = 0.372
Epoch 139 Batch   57/69   train_loss = 0.333
Epoch 139 Batch   59/69   train_loss = 0.442
Epoch 139 Batch   61/69   train_loss = 0.381
Epoch 139 Batch   63/69   train_loss = 0.386
Epoch 139 Batch   65/69   train_loss = 0.383
Epoch 139 Batch   67/69   train_loss = 0.435
Epoch 140 Batch    0/69   train_loss = 0.418
Epoch 140 Batch    2/69   train_loss = 0.362
Epoch 140 Batch    4/69   train_loss = 0.396
Epoch 140 Batch    6/69   train_loss = 0.390
Epoch 140 Batch    8/69   train_loss = 0.436
Epoch 140 Batch   10/69   train_loss = 0.419
Epoch 140 Batch   12/69   train_loss = 0.432
Epoch 140 Batch   14/69   train_loss = 0.371
Epoch 140 Batch   16/69   train_loss = 0.372
Epoch 140 Batch   18/69   train_loss = 0.407
Epoch 140 Batch   20/69   train_loss = 0.357
Epoch 140 Batch   22/69   train_loss = 0.371
Epoch 140 Batch   24/69   train_loss = 0.459
Epoch 140 Batch   26/69   train_loss = 0.440
Epoch 140 Batch   28/69   train_loss = 0.432
Epoch 140 Batch   30/69   train_loss = 0.358
Epoch 140 Batch   32/69   train_loss = 0.371
Epoch 140 Batch   34/69   train_loss = 0.304
Epoch 140 Batch   36/69   train_loss = 0.432
Epoch 140 Batch   38/69   train_loss = 0.429
Epoch 140 Batch   40/69   train_loss = 0.387
Epoch 140 Batch   42/69   train_loss = 0.341
Epoch 140 Batch   44/69   train_loss = 0.343
Epoch 140 Batch   46/69   train_loss = 0.409
Epoch 140 Batch   48/69   train_loss = 0.384
Epoch 140 Batch   50/69   train_loss = 0.308
Epoch 140 Batch   52/69   train_loss = 0.360
Epoch 140 Batch   54/69   train_loss = 0.253
Epoch 140 Batch   56/69   train_loss = 0.364
Epoch 140 Batch   58/69   train_loss = 0.327
Epoch 140 Batch   60/69   train_loss = 0.367
Epoch 140 Batch   62/69   train_loss = 0.339
Epoch 140 Batch   64/69   train_loss = 0.358
Epoch 140 Batch   66/69   train_loss = 0.365
Epoch 140 Batch   68/69   train_loss = 0.531
Epoch 141 Batch    1/69   train_loss = 0.425
Epoch 141 Batch    3/69   train_loss = 0.286
Epoch 141 Batch    5/69   train_loss = 0.435
Epoch 141 Batch    7/69   train_loss = 0.407
Epoch 141 Batch    9/69   train_loss = 0.355
Epoch 141 Batch   11/69   train_loss = 0.338
Epoch 141 Batch   13/69   train_loss = 0.384
Epoch 141 Batch   15/69   train_loss = 0.419
Epoch 141 Batch   17/69   train_loss = 0.407
Epoch 141 Batch   19/69   train_loss = 0.329
Epoch 141 Batch   21/69   train_loss = 0.345
Epoch 141 Batch   23/69   train_loss = 0.413
Epoch 141 Batch   25/69   train_loss = 0.480
Epoch 141 Batch   27/69   train_loss = 0.407
Epoch 141 Batch   29/69   train_loss = 0.405
Epoch 141 Batch   31/69   train_loss = 0.425
Epoch 141 Batch   33/69   train_loss = 0.407
Epoch 141 Batch   35/69   train_loss = 0.309
Epoch 141 Batch   37/69   train_loss = 0.272
Epoch 141 Batch   39/69   train_loss = 0.339
Epoch 141 Batch   41/69   train_loss = 0.433
Epoch 141 Batch   43/69   train_loss = 0.359
Epoch 141 Batch   45/69   train_loss = 0.381
Epoch 141 Batch   47/69   train_loss = 0.390
Epoch 141 Batch   49/69   train_loss = 0.327
Epoch 141 Batch   51/69   train_loss = 0.338
Epoch 141 Batch   53/69   train_loss = 0.366
Epoch 141 Batch   55/69   train_loss = 0.352
Epoch 141 Batch   57/69   train_loss = 0.317
Epoch 141 Batch   59/69   train_loss = 0.424
Epoch 141 Batch   61/69   train_loss = 0.376
Epoch 141 Batch   63/69   train_loss = 0.370
Epoch 141 Batch   65/69   train_loss = 0.369
Epoch 141 Batch   67/69   train_loss = 0.415
Epoch 142 Batch    0/69   train_loss = 0.400
Epoch 142 Batch    2/69   train_loss = 0.351
Epoch 142 Batch    4/69   train_loss = 0.384
Epoch 142 Batch    6/69   train_loss = 0.376
Epoch 142 Batch    8/69   train_loss = 0.421
Epoch 142 Batch   10/69   train_loss = 0.406
Epoch 142 Batch   12/69   train_loss = 0.414
Epoch 142 Batch   14/69   train_loss = 0.357
Epoch 142 Batch   16/69   train_loss = 0.351
Epoch 142 Batch   18/69   train_loss = 0.393
Epoch 142 Batch   20/69   train_loss = 0.340
Epoch 142 Batch   22/69   train_loss = 0.356
Epoch 142 Batch   24/69   train_loss = 0.437
Epoch 142 Batch   26/69   train_loss = 0.413
Epoch 142 Batch   28/69   train_loss = 0.401
Epoch 142 Batch   30/69   train_loss = 0.337
Epoch 142 Batch   32/69   train_loss = 0.363
Epoch 142 Batch   34/69   train_loss = 0.292
Epoch 142 Batch   36/69   train_loss = 0.410
Epoch 142 Batch   38/69   train_loss = 0.410
Epoch 142 Batch   40/69   train_loss = 0.368
Epoch 142 Batch   42/69   train_loss = 0.322
Epoch 142 Batch   44/69   train_loss = 0.323
Epoch 142 Batch   46/69   train_loss = 0.387
Epoch 142 Batch   48/69   train_loss = 0.374
Epoch 142 Batch   50/69   train_loss = 0.290
Epoch 142 Batch   52/69   train_loss = 0.329
Epoch 142 Batch   54/69   train_loss = 0.237
Epoch 142 Batch   56/69   train_loss = 0.342
Epoch 142 Batch   58/69   train_loss = 0.304
Epoch 142 Batch   60/69   train_loss = 0.343
Epoch 142 Batch   62/69   train_loss = 0.327
Epoch 142 Batch   64/69   train_loss = 0.340
Epoch 142 Batch   66/69   train_loss = 0.353
Epoch 142 Batch   68/69   train_loss = 0.514
Epoch 143 Batch    1/69   train_loss = 0.394
Epoch 143 Batch    3/69   train_loss = 0.275
Epoch 143 Batch    5/69   train_loss = 0.416
Epoch 143 Batch    7/69   train_loss = 0.399
Epoch 143 Batch    9/69   train_loss = 0.347
Epoch 143 Batch   11/69   train_loss = 0.328
Epoch 143 Batch   13/69   train_loss = 0.366
Epoch 143 Batch   15/69   train_loss = 0.404
Epoch 143 Batch   17/69   train_loss = 0.400
Epoch 143 Batch   19/69   train_loss = 0.321
Epoch 143 Batch   21/69   train_loss = 0.341
Epoch 143 Batch   23/69   train_loss = 0.410
Epoch 143 Batch   25/69   train_loss = 0.470
Epoch 143 Batch   27/69   train_loss = 0.398
Epoch 143 Batch   29/69   train_loss = 0.389
Epoch 143 Batch   31/69   train_loss = 0.409
Epoch 143 Batch   33/69   train_loss = 0.395
Epoch 143 Batch   35/69   train_loss = 0.296
Epoch 143 Batch   37/69   train_loss = 0.269
Epoch 143 Batch   39/69   train_loss = 0.324
Epoch 143 Batch   41/69   train_loss = 0.411
Epoch 143 Batch   43/69   train_loss = 0.346
Epoch 143 Batch   45/69   train_loss = 0.356
Epoch 143 Batch   47/69   train_loss = 0.377
Epoch 143 Batch   49/69   train_loss = 0.309
Epoch 143 Batch   51/69   train_loss = 0.330
Epoch 143 Batch   53/69   train_loss = 0.344
Epoch 143 Batch   55/69   train_loss = 0.331
Epoch 143 Batch   57/69   train_loss = 0.302
Epoch 143 Batch   59/69   train_loss = 0.401
Epoch 143 Batch   61/69   train_loss = 0.356
Epoch 143 Batch   63/69   train_loss = 0.361
Epoch 143 Batch   65/69   train_loss = 0.356
Epoch 143 Batch   67/69   train_loss = 0.404
Epoch 144 Batch    0/69   train_loss = 0.384
Epoch 144 Batch    2/69   train_loss = 0.324
Epoch 144 Batch    4/69   train_loss = 0.354
Epoch 144 Batch    6/69   train_loss = 0.365
Epoch 144 Batch    8/69   train_loss = 0.412
Epoch 144 Batch   10/69   train_loss = 0.394
Epoch 144 Batch   12/69   train_loss = 0.391
Epoch 144 Batch   14/69   train_loss = 0.329
Epoch 144 Batch   16/69   train_loss = 0.328
Epoch 144 Batch   18/69   train_loss = 0.367
Epoch 144 Batch   20/69   train_loss = 0.335
Epoch 144 Batch   22/69   train_loss = 0.352
Epoch 144 Batch   24/69   train_loss = 0.426
Epoch 144 Batch   26/69   train_loss = 0.398
Epoch 144 Batch   28/69   train_loss = 0.396
Epoch 144 Batch   30/69   train_loss = 0.338
Epoch 144 Batch   32/69   train_loss = 0.353
Epoch 144 Batch   34/69   train_loss = 0.277
Epoch 144 Batch   36/69   train_loss = 0.396
Epoch 144 Batch   38/69   train_loss = 0.399
Epoch 144 Batch   40/69   train_loss = 0.362
Epoch 144 Batch   42/69   train_loss = 0.308
Epoch 144 Batch   44/69   train_loss = 0.309
Epoch 144 Batch   46/69   train_loss = 0.361
Epoch 144 Batch   48/69   train_loss = 0.344
Epoch 144 Batch   50/69   train_loss = 0.288
Epoch 144 Batch   52/69   train_loss = 0.323
Epoch 144 Batch   54/69   train_loss = 0.223
Epoch 144 Batch   56/69   train_loss = 0.327
Epoch 144 Batch   58/69   train_loss = 0.292
Epoch 144 Batch   60/69   train_loss = 0.330
Epoch 144 Batch   62/69   train_loss = 0.308
Epoch 144 Batch   64/69   train_loss = 0.329
Epoch 144 Batch   66/69   train_loss = 0.334
Epoch 144 Batch   68/69   train_loss = 0.490
Epoch 145 Batch    1/69   train_loss = 0.372
Epoch 145 Batch    3/69   train_loss = 0.257
Epoch 145 Batch    5/69   train_loss = 0.410
Epoch 145 Batch    7/69   train_loss = 0.386
Epoch 145 Batch    9/69   train_loss = 0.335
Epoch 145 Batch   11/69   train_loss = 0.315
Epoch 145 Batch   13/69   train_loss = 0.351
Epoch 145 Batch   15/69   train_loss = 0.372
Epoch 145 Batch   17/69   train_loss = 0.371
Epoch 145 Batch   19/69   train_loss = 0.299
Epoch 145 Batch   21/69   train_loss = 0.322
Epoch 145 Batch   23/69   train_loss = 0.388
Epoch 145 Batch   25/69   train_loss = 0.453
Epoch 145 Batch   27/69   train_loss = 0.371
Epoch 145 Batch   29/69   train_loss = 0.364
Epoch 145 Batch   31/69   train_loss = 0.391
Epoch 145 Batch   33/69   train_loss = 0.394
Epoch 145 Batch   35/69   train_loss = 0.294
Epoch 145 Batch   37/69   train_loss = 0.252
Epoch 145 Batch   39/69   train_loss = 0.307
Epoch 145 Batch   41/69   train_loss = 0.417
Epoch 145 Batch   43/69   train_loss = 0.346
Epoch 145 Batch   45/69   train_loss = 0.365
Epoch 145 Batch   47/69   train_loss = 0.357
Epoch 145 Batch   49/69   train_loss = 0.293
Epoch 145 Batch   51/69   train_loss = 0.313
Epoch 145 Batch   53/69   train_loss = 0.336
Epoch 145 Batch   55/69   train_loss = 0.326
Epoch 145 Batch   57/69   train_loss = 0.280
Epoch 145 Batch   59/69   train_loss = 0.379
Epoch 145 Batch   61/69   train_loss = 0.336
Epoch 145 Batch   63/69   train_loss = 0.337
Epoch 145 Batch   65/69   train_loss = 0.336
Epoch 145 Batch   67/69   train_loss = 0.383
Epoch 146 Batch    0/69   train_loss = 0.368
Epoch 146 Batch    2/69   train_loss = 0.315
Epoch 146 Batch    4/69   train_loss = 0.342
Epoch 146 Batch    6/69   train_loss = 0.345
Epoch 146 Batch    8/69   train_loss = 0.402
Epoch 146 Batch   10/69   train_loss = 0.390
Epoch 146 Batch   12/69   train_loss = 0.383
Epoch 146 Batch   14/69   train_loss = 0.320
Epoch 146 Batch   16/69   train_loss = 0.308
Epoch 146 Batch   18/69   train_loss = 0.350
Epoch 146 Batch   20/69   train_loss = 0.301
Epoch 146 Batch   22/69   train_loss = 0.331
Epoch 146 Batch   24/69   train_loss = 0.413
Epoch 146 Batch   26/69   train_loss = 0.379
Epoch 146 Batch   28/69   train_loss = 0.381
Epoch 146 Batch   30/69   train_loss = 0.309
Epoch 146 Batch   32/69   train_loss = 0.331
Epoch 146 Batch   34/69   train_loss = 0.279
Epoch 146 Batch   36/69   train_loss = 0.394
Epoch 146 Batch   38/69   train_loss = 0.379
Epoch 146 Batch   40/69   train_loss = 0.343
Epoch 146 Batch   42/69   train_loss = 0.295
Epoch 146 Batch   44/69   train_loss = 0.307
Epoch 146 Batch   46/69   train_loss = 0.366
Epoch 146 Batch   48/69   train_loss = 0.342
Epoch 146 Batch   50/69   train_loss = 0.277
Epoch 146 Batch   52/69   train_loss = 0.311
Epoch 146 Batch   54/69   train_loss = 0.215
Epoch 146 Batch   56/69   train_loss = 0.329
Epoch 146 Batch   58/69   train_loss = 0.283
Epoch 146 Batch   60/69   train_loss = 0.317
Epoch 146 Batch   62/69   train_loss = 0.298
Epoch 146 Batch   64/69   train_loss = 0.310
Epoch 146 Batch   66/69   train_loss = 0.320
Epoch 146 Batch   68/69   train_loss = 0.485
Epoch 147 Batch    1/69   train_loss = 0.357
Epoch 147 Batch    3/69   train_loss = 0.245
Epoch 147 Batch    5/69   train_loss = 0.386
Epoch 147 Batch    7/69   train_loss = 0.362
Epoch 147 Batch    9/69   train_loss = 0.327
Epoch 147 Batch   11/69   train_loss = 0.303
Epoch 147 Batch   13/69   train_loss = 0.344
Epoch 147 Batch   15/69   train_loss = 0.364
Epoch 147 Batch   17/69   train_loss = 0.364
Epoch 147 Batch   19/69   train_loss = 0.290
Epoch 147 Batch   21/69   train_loss = 0.309
Epoch 147 Batch   23/69   train_loss = 0.375
Epoch 147 Batch   25/69   train_loss = 0.445
Epoch 147 Batch   27/69   train_loss = 0.364
Epoch 147 Batch   29/69   train_loss = 0.353
Epoch 147 Batch   31/69   train_loss = 0.366
Epoch 147 Batch   33/69   train_loss = 0.365
Epoch 147 Batch   35/69   train_loss = 0.274
Epoch 147 Batch   37/69   train_loss = 0.250
Epoch 147 Batch   39/69   train_loss = 0.293
Epoch 147 Batch   41/69   train_loss = 0.382
Epoch 147 Batch   43/69   train_loss = 0.309
Epoch 147 Batch   45/69   train_loss = 0.335
Epoch 147 Batch   47/69   train_loss = 0.349
Epoch 147 Batch   49/69   train_loss = 0.292
Epoch 147 Batch   51/69   train_loss = 0.317
Epoch 147 Batch   53/69   train_loss = 0.326
Epoch 147 Batch   55/69   train_loss = 0.312
Epoch 147 Batch   57/69   train_loss = 0.269
Epoch 147 Batch   59/69   train_loss = 0.380
Epoch 147 Batch   61/69   train_loss = 0.334
Epoch 147 Batch   63/69   train_loss = 0.324
Epoch 147 Batch   65/69   train_loss = 0.317
Epoch 147 Batch   67/69   train_loss = 0.371
Epoch 148 Batch    0/69   train_loss = 0.366
Epoch 148 Batch    2/69   train_loss = 0.306
Epoch 148 Batch    4/69   train_loss = 0.334
Epoch 148 Batch    6/69   train_loss = 0.332
Epoch 148 Batch    8/69   train_loss = 0.368
Epoch 148 Batch   10/69   train_loss = 0.355
Epoch 148 Batch   12/69   train_loss = 0.365
Epoch 148 Batch   14/69   train_loss = 0.324
Epoch 148 Batch   16/69   train_loss = 0.298
Epoch 148 Batch   18/69   train_loss = 0.340
Epoch 148 Batch   20/69   train_loss = 0.298
Epoch 148 Batch   22/69   train_loss = 0.318
Epoch 148 Batch   24/69   train_loss = 0.399
Epoch 148 Batch   26/69   train_loss = 0.381
Epoch 148 Batch   28/69   train_loss = 0.386
Epoch 148 Batch   30/69   train_loss = 0.318
Epoch 148 Batch   32/69   train_loss = 0.316
Epoch 148 Batch   34/69   train_loss = 0.261
Epoch 148 Batch   36/69   train_loss = 0.373
Epoch 148 Batch   38/69   train_loss = 0.383
Epoch 148 Batch   40/69   train_loss = 0.337
Epoch 148 Batch   42/69   train_loss = 0.293
Epoch 148 Batch   44/69   train_loss = 0.282
Epoch 148 Batch   46/69   train_loss = 0.324
Epoch 148 Batch   48/69   train_loss = 0.320
Epoch 148 Batch   50/69   train_loss = 0.265
Epoch 148 Batch   52/69   train_loss = 0.304
Epoch 148 Batch   54/69   train_loss = 0.210
Epoch 148 Batch   56/69   train_loss = 0.307
Epoch 148 Batch   58/69   train_loss = 0.262
Epoch 148 Batch   60/69   train_loss = 0.303
Epoch 148 Batch   62/69   train_loss = 0.285
Epoch 148 Batch   64/69   train_loss = 0.313
Epoch 148 Batch   66/69   train_loss = 0.313
Epoch 148 Batch   68/69   train_loss = 0.454
Epoch 149 Batch    1/69   train_loss = 0.335
Epoch 149 Batch    3/69   train_loss = 0.236
Epoch 149 Batch    5/69   train_loss = 0.393
Epoch 149 Batch    7/69   train_loss = 0.351
Epoch 149 Batch    9/69   train_loss = 0.305
Epoch 149 Batch   11/69   train_loss = 0.281
Epoch 149 Batch   13/69   train_loss = 0.324
Epoch 149 Batch   15/69   train_loss = 0.355
Epoch 149 Batch   17/69   train_loss = 0.358
Epoch 149 Batch   19/69   train_loss = 0.283
Epoch 149 Batch   21/69   train_loss = 0.292
Epoch 149 Batch   23/69   train_loss = 0.347
Epoch 149 Batch   25/69   train_loss = 0.419
Epoch 149 Batch   27/69   train_loss = 0.353
Epoch 149 Batch   29/69   train_loss = 0.354
Epoch 149 Batch   31/69   train_loss = 0.374
Epoch 149 Batch   33/69   train_loss = 0.362
Epoch 149 Batch   35/69   train_loss = 0.268
Epoch 149 Batch   37/69   train_loss = 0.237
Epoch 149 Batch   39/69   train_loss = 0.299
Epoch 149 Batch   41/69   train_loss = 0.406
Epoch 149 Batch   43/69   train_loss = 0.322
Epoch 149 Batch   45/69   train_loss = 0.333
Epoch 149 Batch   47/69   train_loss = 0.331
Epoch 149 Batch   49/69   train_loss = 0.270
Epoch 149 Batch   51/69   train_loss = 0.308
Epoch 149 Batch   53/69   train_loss = 0.323
Epoch 149 Batch   55/69   train_loss = 0.303
Epoch 149 Batch   57/69   train_loss = 0.258
Epoch 149 Batch   59/69   train_loss = 0.352
Epoch 149 Batch   61/69   train_loss = 0.306
Epoch 149 Batch   63/69   train_loss = 0.314
Epoch 149 Batch   65/69   train_loss = 0.309
Epoch 149 Batch   67/69   train_loss = 0.365
Model Trained and Saved
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Save-Parameters">Save Parameters<a class="anchor-link" href="#Save-Parameters">&#182;</a></h2><p>Save <code>seq_length</code> and <code>save_dir</code> for generating a new TV script.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[55]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Save parameters for checkpoint</span>
<span class="n">helper</span><span class="o">.</span><span class="n">save_params</span><span class="p">((</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">save_dir</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Checkpoint">Checkpoint<a class="anchor-link" href="#Checkpoint">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[56]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">_</span><span class="p">,</span> <span class="n">vocab_to_int</span><span class="p">,</span> <span class="n">int_to_vocab</span><span class="p">,</span> <span class="n">token_dict</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">seq_length</span><span class="p">,</span> <span class="n">load_dir</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_params</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implement-Generate-Functions">Implement Generate Functions<a class="anchor-link" href="#Implement-Generate-Functions">&#182;</a></h2><h3 id="Get-Tensors">Get Tensors<a class="anchor-link" href="#Get-Tensors">&#182;</a></h3><p>Get tensors from <code>loaded_graph</code> using the function <a href="https://www.tensorflow.org/api_docs/python/tf/Graph#get_tensor_by_name"><code>get_tensor_by_name()</code></a>.  Get the tensors using the following names:</p>
<ul>
<li>"input:0"</li>
<li>"initial_state:0"</li>
<li>"final_state:0"</li>
<li>"probs:0"</li>
</ul>
<p>Return the tensors in the following tuple <code>(InputTensor, InitialStateTensor, FinalStateTensor, ProbsTensor)</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[57]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_tensors</span><span class="p">(</span><span class="n">loaded_graph</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get input, initial state, final state, and probabilities tensor from &lt;loaded_graph&gt;</span>
<span class="sd">    :param loaded_graph: TensorFlow graph loaded from file</span>
<span class="sd">    :return: Tuple (InputTensor, InitialStateTensor, FinalStateTensor, ProbsTensor)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">input_</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s2">&quot;input:0&quot;</span><span class="p">)</span>
    <span class="n">initial_state</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s2">&quot;initial_state:0&quot;</span><span class="p">)</span>
    <span class="n">final_state</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s2">&quot;final_state:0&quot;</span><span class="p">)</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s2">&quot;probs:0&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">,</span> <span class="n">final_state</span><span class="p">,</span> <span class="n">probs</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_get_tensors</span><span class="p">(</span><span class="n">get_tensors</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Choose-Word">Choose Word<a class="anchor-link" href="#Choose-Word">&#182;</a></h3><p>Implement the <code>pick_word()</code> function to select the next word using <code>probabilities</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[58]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">pick_word</span><span class="p">(</span><span class="n">probabilities</span><span class="p">,</span> <span class="n">int_to_vocab</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Pick the next word in the generated text</span>
<span class="sd">    :param probabilities: Probabilites of the next word (a 1D numpy.array)</span>
<span class="sd">    :param int_to_vocab: Dictionary of word ids as the keys and words as the values</span>
<span class="sd">    :return: String of the predicted word</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Sort from least to most probable.  For all but the top n most likely words,</span>
<span class="sd">    set the probability to zero so that we only choose from the top n most likely words.</span>
<span class="sd">    </span>
<span class="sd">    Re-normalize so that the remaining top n probabilities sum to 1.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">top_n</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">p_argsort</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)</span>
    <span class="n">probabilities</span><span class="p">[</span><span class="n">p_argsort</span><span class="p">[:</span><span class="o">-</span><span class="n">top_n</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">probabilities</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)</span>
    <span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">int_to_vocab</span><span class="p">)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">int_to_vocab</span><span class="p">[</span><span class="n">c</span><span class="p">]</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_pick_word</span><span class="p">(</span><span class="n">pick_word</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Generate-TV-Script">Generate TV Script<a class="anchor-link" href="#Generate-TV-Script">&#182;</a></h2><p>This will generate the TV script for you.  Set <code>gen_length</code> to the length of TV script you want to generate.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[38]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">gen_length</span> <span class="o">=</span> <span class="mi">200</span>
<span class="c1"># homer_simpson, moe_szyslak, or Barney_Gumble</span>
<span class="n">prime_word</span> <span class="o">=</span> <span class="s1">&#39;moe_szyslak&#39;</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">loaded_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">loaded_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Load saved model</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="n">load_dir</span> <span class="o">+</span> <span class="s1">&#39;.meta&#39;</span><span class="p">)</span>
    <span class="n">loader</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">load_dir</span><span class="p">)</span>

    <span class="c1"># Get Tensors from loaded model</span>
    <span class="n">input_text</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">,</span> <span class="n">final_state</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">get_tensors</span><span class="p">(</span><span class="n">loaded_graph</span><span class="p">)</span>

    <span class="c1"># Sentences generation setup</span>
    <span class="n">gen_sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">prime_word</span> <span class="o">+</span> <span class="s1">&#39;:&#39;</span><span class="p">]</span>
    <span class="n">prev_state</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">initial_state</span><span class="p">,</span> <span class="p">{</span><span class="n">input_text</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">]])})</span>

    <span class="c1"># Generate sentences</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">gen_length</span><span class="p">):</span>
        <span class="c1"># Dynamic Input</span>
        <span class="n">dyn_input</span> <span class="o">=</span> <span class="p">[[</span><span class="n">vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">gen_sentences</span><span class="p">[</span><span class="o">-</span><span class="n">seq_length</span><span class="p">:]]]</span>
        <span class="n">dyn_seq_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dyn_input</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># Get Prediction</span>
        <span class="n">probabilities</span><span class="p">,</span> <span class="n">prev_state</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
            <span class="p">[</span><span class="n">probs</span><span class="p">,</span> <span class="n">final_state</span><span class="p">],</span>
            <span class="p">{</span><span class="n">input_text</span><span class="p">:</span> <span class="n">dyn_input</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">:</span> <span class="n">prev_state</span><span class="p">})</span>
        
        <span class="n">pred_word</span> <span class="o">=</span> <span class="n">pick_word</span><span class="p">(</span><span class="n">probabilities</span><span class="p">[</span><span class="n">dyn_seq_length</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">int_to_vocab</span><span class="p">)</span>

        <span class="n">gen_sentences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_word</span><span class="p">)</span>
    
    <span class="c1"># Remove tokens</span>
    <span class="n">tv_script</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">gen_sentences</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">token_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">ending</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span> <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;(&#39;</span><span class="p">,</span> <span class="s1">&#39;&quot;&#39;</span><span class="p">]</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span>
        <span class="n">tv_script</span> <span class="o">=</span> <span class="n">tv_script</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39; &#39;</span> <span class="o">+</span> <span class="n">token</span><span class="o">.</span><span class="n">lower</span><span class="p">(),</span> <span class="n">key</span><span class="p">)</span>
    <span class="n">tv_script</span> <span class="o">=</span> <span class="n">tv_script</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> &#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">tv_script</span> <span class="o">=</span> <span class="n">tv_script</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;( &#39;</span><span class="p">,</span> <span class="s1">&#39;(&#39;</span><span class="p">)</span>
        
    <span class="nb">print</span><span class="p">(</span><span class="n">tv_script</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>moe_szyslak: come up to the ground. ah, uh, thank he can&#39;t you know on alcohol my love of any way in by an idiot.
lenny_leonard:(sobs) moe, that&#39;s good. now it&#39;s me. your daughter is gonna say your name on the truck for some kind of bars.(laughs) hey, the way is the love. can admit the bar, as i&#39;ve just put there-- and your pants with it!
lenny_leonard: aw, no, i gotta do you i mean, huh?
moe_szyslak: just really just took my new life.
health_inspector: hey is gonna save every dangerous to another woman-- it was a beer.
moe_szyslak:(singing) now? what if they think..
ken: the most(quiet)
lenny_leonard: you gotta get out and they wanted it.
homer_simpson: oh, uh, you?
barney_gumble: sure homer.
homer_simpson:(to scream) just a chick? if dance for me like my blood type i&#39;ve can&#39;t get out with me?
homer_simpson:(sad
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="The-TV-Script-is-Nonsensical">The TV Script is Nonsensical<a class="anchor-link" href="#The-TV-Script-is-Nonsensical">&#182;</a></h1><p>It's ok if the TV script doesn't make any sense.  We trained on less than a megabyte of text.  In order to get good results, you'll have to use a smaller vocabulary or get more data.  Luckly there's more data!  As we mentioned in the begging of this project, this is a subset of <a href="https://www.kaggle.com/wcukierski/the-simpsons-by-the-data">another dataset</a>.  We didn't have you train on all the data, because that would take too long.  However, you are free to train your neural network on all the data.  After you complete the project, of course.</p>
<h1 id="Submitting-This-Project">Submitting This Project<a class="anchor-link" href="#Submitting-This-Project">&#182;</a></h1><p>When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as "dlnd_tv_script_generation.ipynb" and save it as a HTML file under "File" -&gt; "Download as". Include the "helper.py" and "problem_unittests.py" files in your submission.</p>

</div>
</div>
</div>
    </div>
  </div>
</body>

 


</html>
